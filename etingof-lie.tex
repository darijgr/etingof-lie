%\usepackage{bigfoot}
%\usepackage{fixltx2e}
%\renewcommand{\footnote}[1]{\footnotemark \footnotetext{#1}}
% This paper comes in two versions:
% The long version:
% \includecomment{verlong}
% \excludecomment{vershort}
% The short version:
% \excludecomment{verlong}
% \includecomment{vershort}

\documentclass
[numbers=enddot,12pt,final,onecolumn,german,notitlepage]{scrartcl}%
\usepackage[all,cmtip]{xy}
\usepackage{lscape}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{amsthm}
\usepackage{graphicx}%
\setcounter{MaxMatrixCols}{30}
%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{LastRevised=Sunday, March 11, 2012 12:38:15}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%BeginMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}
%EndMSIPreambleData
\newcommand{\Ker}{\operatorname*{Ker}}
\newcommand{\id}{\operatorname*{id}}
\newcommand{\inc}{\operatorname*{inc}}
\newcommand{\gr}{\operatorname*{gr}}
\newcommand{\Hom}{\operatorname*{Hom}}
\newcommand{\calA}{\mathcal A}
\newcommand{\arinj}{\ar@{_{(}->}}
\newcommand{\arsurj}{\ar@{->>}}
\newcommand{\arelem}{\ar@{|->}}
\newcommand{\fraka}{\mathfrak{a}}
\newcommand{\frakb}{\mathfrak{b}}
\newcommand{\frakc}{\mathfrak{c}}
\newcommand{\PBW}{\operatorname*{PBW}}
\newcommand{\xycs}{\xymatrixcolsep}
\newcommand{\xyrs}{\xymatrixrowsep}
\theoremstyle{definition}
\newtheorem{theo}{Theorem}
\newenvironment{theorem}[1][]
{\begin{theo}[#1]\begin{leftbar}}
{\end{leftbar}\end{theo}}
\newtheorem{lem}[theo]{Lemma}
\newenvironment{lemma}[1][]
{\begin{lem}[#1]\begin{leftbar}}
{\end{leftbar}\end{lem}}
\newtheorem{prop}[theo]{Proposition}
\newenvironment{proposition}[1][]
{\begin{prop}[#1]\begin{leftbar}}
{\end{leftbar}\end{prop}}
\newtheorem{exe}[theo]{Exercise}
\newenvironment{exercise}[1][]
{\begin{exe}[#1]\begin{leftbar}}
{\end{leftbar}\end{exe}}
\newtheorem{defi}[theo]{Definition}
\newenvironment{definition}[1][]
{\begin{defi}[#1]\begin{leftbar}}
{\end{leftbar}\end{defi}}
\newtheorem{remk}[theo]{Remark}
\newenvironment{remark}[1][]
{\begin{remk}[#1]\begin{leftbar}}
{\end{leftbar}\end{remk}}
\newtheorem{coro}[theo]{Corollary}
\newenvironment{corollary}[1][]
{\begin{coro}[#1]\begin{leftbar}}
{\end{leftbar}\end{coro}}
\newtheorem{conv}[theo]{Convention}
\newenvironment{Convention}[1][]
{\begin{conv}[#1]\begin{leftbar}}
{\end{leftbar}\end{conv}}
\newtheorem{warn}[theo]{Warning}
\newenvironment{Warning}[1][]
{\begin{warn}[#1]\begin{leftbar}}
{\end{leftbar}\end{warn}}
\voffset=-0.5cm
\hoffset=-0.7cm
\newenvironment{verlong}{}{}
\newenvironment{vershort}{}{}
\newenvironment{noncompile}{}{}
\excludecomment{verlong}
\includecomment{vershort}
\excludecomment{noncompile}
\setlength\textheight{24cm}
\setlength\textwidth{15.5cm}
\begin{document}

\title{18.747: Infinite-dimensional Lie algebras (Spring term 2012 at MIT)}
\author{Pavel Etingof\\Scribed by Darij Grinberg}
\date{Version 0.11 (\today) (not proofread!)}
\maketitle
\tableofcontents

\begin{noncompile}
\textbf{TO-DO\ LIST:}

[footnotes correct order]
\end{noncompile}

\subsection{Version notes}

These notes are mostly based on what is being said and written on the
blackboard in the lectures, and less so on Pavel Etingof's handwritten notes
posted on \newline\texttt{http://www-math.mit.edu/\symbol{126}etingof/} . At
the moment, they lag behind Etingof's handwritten notes, but are more
detailed. But Etingof's notes contain some remarks that are not in (and might
never be added to) these notes!

\subsection{Introduction}

Our main book is:

\begin{itemize}
\item V. G. Kac, A. K. Raina, \textit{(Bombay Lectures on) Highest Weight
Representations of Infinite Dimensional Lie Algebras}, World Scientific 1987.
\end{itemize}

Further recommended sources are:

\begin{itemize}
\item Victor G. Kac, \textit{Infinite dimensional Lie algebras}, Third
Edition, CUP 1995.

\item B. L. Feigin, A. Zelevinsky, \textit{Representations of contragredient
Lie algebras and the Kac-Macdonald identities}, a paper in: Representations of
Lie groups and Lie algebras (Budapest, 1971), pp. 25-77, Akad. Kiad\'{o},
Budapest, 1985.
\end{itemize}

The goal of this lecture is to discuss the structure and the representation
theory (mainly the latter) of the most important infinite-dimensional Lie
algebras. And we are also going to show some connections of this subject to
other fields of mathematics (such as conformal field theory, the theory of
integrable systems, and the theory of quantum groups).

Basic algebra will be used, but also occasionally some results from the
representation theory of finite-dimensional Lie algebras.

The biggest difference between the theory of finite-dimensional Lie algebras
and that of infinite-dimensional ones is that in the finite-dimensional case,
we have a complete picture -- we can classify simple Lie algebras, etc. --,
whereas in the infinite-dimensional one there are lots and lots of simple Lie
algebras and we have no real hope to classify them; what we can do is study
some very specific classes and families. The main classes of Lie algebras that
we will study in this course are:

\textbf{1.} The Heisenberg algebra (aka oscillator algebra).

\textbf{2.} The Virasoro algebra.

\textbf{3.} Kac-Moody algebras (this class contains semisimple Lie algebras
and also affine Lie algebras, which are central extensions of $\mathfrak{g}%
\left[  t,t^{-1}\right]  $ where $\mathfrak{g}$ is simple finite-dimensional).

\textbf{4.} The Lie algebra $\mathfrak{gl}_{\infty}$.

We will almost always work over $\mathbb{C}$ in this course. All algebras are
over $\mathbb{C}$ unless specified otherwise. Characteristic $p$ is too
complicated for us, although very interesting. Sometimes we will work over
$\mathbb{R}$, and occasionally even over rings (as auxiliary constructions
require this).

\section{The main examples}

\subsection{The Heisenberg algebra}

We start with the definition of the Heisenberg algebra:

\begin{definition}
\label{def.osc}The \textit{oscillator algebra} $\mathcal{A}$ is the Lie
algebra $\mathbb{C}\left[  t,t^{-1}\right]  \oplus\mathbb{C}$ with Lie bracket%
\[
\left[  \left(  f,\alpha\right)  ,\left(  g,\beta\right)  \right]  =\left(
0,\operatorname*{Res}\nolimits_{t=0}\left(  gdf\right)  \right)  .
\]
Remember that the residue of a Laurent polynomial (or Laurent series) is
defined by $\operatorname*{Res}\nolimits_{t=0}\left(  \left(  \sum
\limits_{i}a_{i}t^{i}\right)  dt\right)  =a_{-1}$.

This oscillator algebra $\mathcal{A}$ is also known as the \textit{Heisenberg
algebra}.
\end{definition}

Thus, $\mathcal{A}$ has a basis
\[
\left\{  a_{n}\ \mid\ n\in\mathbb{Z}\right\}  \cup\left\{  K\right\}  ,
\]
where $a_{n}=\left(  t^{n},0\right)  $ and $K=\left(  0,1\right)  $. The
bracket is given by%
\begin{align*}
\left[  a_{n},K\right]   &  =0\ \ \ \ \ \ \ \ \ \ \left(  \text{thus, }K\text{
is central}\right)  ;\\
\left[  a_{n},a_{m}\right]   &  =n\delta_{n,-m}K
\end{align*}
(in fact, $\left[  a_{n},a_{-n}\right]  =\operatorname*{Res}\nolimits_{t=0}%
\left(  t^{-n}dt^{n}\right)  K=\operatorname*{Res}\nolimits_{t=0}\left(
nt^{-1}dt\right)  K=nK$). Thus, $\mathcal{A}$ is a $1$-dimensional central
extension of the abelian Lie algebra $\mathbb{C}\left[  t,t^{-1}\right]  $;
this means that we have a short exact sequence%
\[
\xymatrix{
0 \ar[r] & \mathbb C K \ar[r] & \mathcal A \ar[r] & \mathbb C\left[t,t^{-1}\right] \ar[r] & 0
},
\]
where $\mathbb{C}K$ is contained in the center of $\mathcal{A}$ and where
$\mathbb{C}\left[  t,t^{-1}\right]  $ is an abelian Lie algebra.

Note that $\mathcal{A}$ is a $2$-nilpotent Lie algebra. Also note that the
center of $\mathcal{A}$ is spanned by $a_{0}$ and $K$.

\subsection{The Witt algebra}

The next introductory example will be the Lie algebra of vector fields:

\begin{definition}
The \textit{Witt algebra }$W$ is the Lie algebra of polynomial vector fields
on $\mathbb{C}^{\times}$. Here, "polynomial vector fields on $\mathbb{C}%
^{\times}$" means vector fields of the form $f\left(  t\right)  \dfrac{d}{dt}$
where $f\in\mathbb{C}\left[  t,t^{-1}\right]  $.

We are going to abbreviate $\dfrac{d}{dt}$ by $\partial$.

The Lie bracket on the Witt algebra is defined by%
\[
\left[  f\partial,g\partial\right]  =\left(  fg^{\prime}-gf^{\prime}\right)
\partial.
\]
(This is, of course, the usual Lie bracket of vector fields.)
\end{definition}

A basis of the Witt algebra is $\left\{  L_{n}\ \mid\ n\in\mathbb{Z}\right\}
$, where $L_{n}$ means $-t^{n+1}\dfrac{d}{dt}=-t^{n+1}\partial$. (Note that
some other references like to define $L_{n}$ as $t^{n+1}\partial$ instead,
thus getting a different sign in many formulas.) It is easy to see that the
Lie bracket of the Witt algebra is given on this basis by
\[
\left[  L_{n},L_{m}\right]  =\left(  n-m\right)  L_{n+m}%
\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}\text{ and }m\in
\mathbb{Z}.
\]


\subsection{A digression: Lie groups (and the absence thereof)}

Let us make some remarks about the relationship between Lie algebras and Lie
groups. In analysis and geometry, linearizations (tangent spaces etc.) usually
only give a crude approximation of non-linear things (manifolds etc.). This is
what makes the theory of Lie groups special: The linearization of a
finite-dimensional Lie group (i. e., its corresponding Lie algebra) carries
very much information about the Lie group. The relation between
finite-dimensional Lie groups and finite-dimensional Lie algebras is almost a
one-to-one correspondence (at least if we restrict ourselves to simply
connected Lie groups). This correspondence breaks down in the
infinite-dimensional case. There are lots of important infinite-dimensional
Lie groups, but their relation to Lie algebras is not as close as in the
finite-dimensional case anymore. One example for this is that there is no Lie
group corresponding to the Witt algebra $W$. There are a few things that come
close to such a Lie group:

We can consider the real subalgebra $W_{\mathbb{R}}$ of $W$, consisting of the
vector fields in $W$ which are tangent to $S^{1}$ (the unit circle in
$\mathbb{C}$). This is a real Lie algebra satisfying $W_{\mathbb{R}}%
\otimes_{\mathbb{R}}\mathbb{C}\cong W$ (thus, $W_{\mathbb{R}}$ is what is
called a \textit{real form} of $W$). And we can say that
$\widehat{W_{\mathbb{R}}}=\operatorname*{Lie}\left(  \operatorname*{Diff}%
S^{1}\right)  $ for some kind of completion $\widehat{W_{\mathbb{R}}}$ of
$W_{\mathbb{R}}$ (although $W_{\mathbb{R}}$ itself is not the Lie algebra of
any Lie group).\footnote{Here is how this completion $\widehat{W_{\mathbb{R}}%
}$ is defined exactly: Notice that%
\[
W_{\mathbb{R}}=\left\{  \varphi\left(  \theta\right)  \dfrac{d}{dt}\ \mid\
\begin{array}
[c]{c}%
\varphi\text{ is a trigonometric polynomial, i. e.,}\\
\varphi\left(  \theta\right)  =a_{0}+\sum\limits_{n}a_{n}\cos n\theta
+\sum\limits_{n}b_{n}\sin n\theta\\
\text{where both sums are finite}%
\end{array}
\right\}  .
\]
Now, define the completion $\widehat{W_{\mathbb{R}}}$ by%
\[
\widehat{W_{\mathbb{R}}}=\left\{  \varphi\left(  \theta\right)  \dfrac{d}%
{dt}\ \mid\
\begin{array}
[c]{c}%
\varphi\left(  \theta\right)  =a_{0}+\sum\limits_{n}a_{n}\cos n\theta
+\sum\limits_{n}b_{n}\sin n\theta\\
\text{where both sums are infinite sums with rapidly}\\
\text{decreasing coefficients}%
\end{array}
\right\}  .
\]
} Now if we take two one-parameter families%
\begin{align*}
g_{s}  &  \in\operatorname*{Diff}S^{1},\ \ \ \ \ \ \ \ \ \ g_{s}\mid
_{s=0}=\operatorname*{id},\ \ \ \ \ \ \ \ \ \ g_{s}^{\prime}\mid_{s=0}%
=\varphi;\\
h_{u}  &  \in\operatorname*{Diff}S^{1},\ \ \ \ \ \ \ \ \ \ h_{u}\mid
_{u=0}=\operatorname*{id},\ \ \ \ \ \ \ \ \ \ h_{u}^{\prime}\mid_{u=0}=\psi,
\end{align*}
then%
\begin{align*}
g_{s}\left(  \theta\right)   &  =\theta+s\varphi\left(  \theta\right)
+O\left(  s^{2}\right)  ;\\
h_{u}\left(  \theta\right)   &  =\theta+u\psi\left(  \theta\right)  +O\left(
t^{2}\right)  ;\\
g_{s}\circ h_{u}\circ g_{s}^{-1}\circ h_{u}^{-1}  &  =\theta+su\left(
\varphi\psi^{\prime}-\psi\varphi^{\prime}\right)  \left(  \theta\right)
+\left(  \text{cubic terms in }s\text{ and }u\text{ and higher}\right)  .
\end{align*}
So we get something like the standard Lie-group-Lie-algebra correspondence,
but only for the completion of the real part. For the complex one, some people
have done some work yielding something like Lie semigroups (the so-called
"semigroup of annuli" of G. Segal), but no Lie groups.

Anyway, this was a digression, just to show that we don't have Lie groups
corresponding to our Lie algebras. Still, this should not keep us from
heuristically thinking of Lie algebras as linearizations of Lie groups. We can
even formalize this heuristic, by using the purely algebraic notion of formal groups.

\subsection{The Witt algebra acts on the Heisenberg algebra by derivations}

Let's return to topic.

From now on, if $\mathfrak{g}$ is a Lie algebra, we will denote by
$\operatorname*{Der}\mathfrak{g}$ the Lie algebra of all derivations of
$\mathfrak{g}$.

\begin{lemma}
\label{lem.WtoDerA}There is a natural homomorphism $\eta:W\rightarrow
\operatorname*{Der}\mathcal{A}$ of Lie algebras given by
\[
\eta\left(  f\partial\right)  \left(  g,\alpha\right)  =\left(  fg^{\prime
},0\right)  .
\]

\end{lemma}

\textit{First proof of Lemma \ref{lem.WtoDerA}.} Direct calculation (exercise).

\textit{Second proof of Lemma \ref{lem.WtoDerA}.} The bracket $\left[
\cdot,\cdot\right]  $ in $\mathcal{A}$ was defined in an invariant way:%
\[
\left[  f,g\right]  =\operatorname*{Res}\nolimits_{t=0}\left(  gdf\right)
=\dfrac{1}{2\pi i}\oint\limits_{\left\vert z\right\vert =1}gdf
\]
is an integral of a $1$-form, thus invariant under diffeomorphisms, thus
invariant under "infinitesimal diffeomorphisms" such as the ones given by
elements of $W$. Thus, Lemma \ref{lem.WtoDerA} becomes obvious.

The first of these two proofs is obviously the more straightforward one (and
generalizes better to fields other than $\mathbb{C}$), but it does not offer
any explanation why Lemma \ref{lem.WtoDerA} is more than a mere coincidence.
Meanwhile, the second proof gives Lemma \ref{lem.WtoDerA} a philosophical
reason to be true.

\subsection{The Virasoro algebra}

In representation theory, one often doesn't encounter representation of $W$
directly, but instead representations of a $1$-dimensional central extension
of $W$ called the Virasoro algebra. I will now construct this extension and
show that it is the only one (up to isomorphism of extensions).

Let us recollect the theory of central extensions of Lie algebras (more
precisely, the $1$-dimensional ones):

\begin{definition}
\label{def.centex}If $L$ is a Lie algebra, then a $1$-dimensional central
extension of $L$ is a Lie algebra $\widehat{L}$ along with an exact sequence%
\begin{equation}
0\rightarrow\mathbb{C}\rightarrow\widehat{L}\rightarrow L\rightarrow0,
\label{def.2-cocyc.es}%
\end{equation}
where $\mathbb{C}$ is central in $\widehat{L}$. Since all exact sequences of
vector spaces split, we can pick a splitting of this exact sequence on the
level of vector spaces, and thus identify $\widehat{L}$ with $L\oplus
\mathbb{C}$ as a vector space (not as a Lie algebra). Upon this
identification, the Lie bracket of $\widehat{L}$ can be written as%
\begin{equation}
\left[  \left(  a,\alpha\right)  ,\left(  b,\beta\right)  \right]  =\left(
\left[  a,b\right]  ,\omega\left(  a,b\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for }a\in L\text{, }\alpha\in\mathbb{C}\text{, }b\in
L\text{, }\beta\in\mathbb{C}, \label{def.2-cocyc.form}%
\end{equation}
for some skew-symmetric bilinear form $\omega:L\times L\rightarrow\mathbb{C}$.
(We can also write this skew-symmetric bilinear form $\omega:L\times
L\rightarrow\mathbb{C}$ as a linear form $\wedge^{2}L\rightarrow\mathbb{C}$.)
But $\omega$ cannot be a completely arbitrary skew-symmetric bilinear form. It
needs to satisfy the so-called $2$\textit{-cocycle condition}%
\[
\omega\left(  \left[  a,b\right]  ,c\right)  +\omega\left(  \left[
b,c\right]  ,a\right)  +\omega\left(  \left[  c,a\right]  ,b\right)
=0\ \ \ \ \ \ \ \ \ \ \text{for all }a,b,c\in L.
\]
This condition comes from the requirement that the bracket in $\widehat{L}$
have to satisfy the Jacobi identity. The name "$2$-cocycle condition" comes
from Lie algebra cohomology, where this condition indeed characterizes $2$-cocycles.

Conversely, if $\omega$ is a $2$-cocycle (i. e., a skew-symmetric bilinear
form satisfying the $2$-cocycle condition), then we have a central extension
$\widehat{L}_{\omega}=L\oplus\mathbb{C}$ (whose Lie bracket is defined by
(\ref{def.2-cocyc.form})).

However, our assignment of the $2$-cocycle $\omega$ to the central extension
$\widehat{L}$ was not canonical, but depended on the splitting of the exact
sequence (\ref{def.2-cocyc.es}). If we change the splitting by some $\xi\in
L^{\ast}$, then $\omega$ is changed by $d\xi$:
\[
d\xi\left(  a,b\right)  =\xi\left(  \left[  a,b\right]  \right)
,\ \ \ \ \ \ \ \ \ \ \omega\mapsto\omega+d\xi.
\]
The $2$-cocycle $d\xi$ is called a $2$\textit{-coboundary}. As a conclusion,
$1$-dimensional central extensions of $L$ are parametrized up to isomorphism
by%
\[
\left(  2\text{-cocycles}\right)  \diagup\left(  2\text{-coboundaries}\right)
=H^{2}\left(  L\right)  .
\]
(Note that "up to isomorphism" means "up to isomorphism of extensions" here,
not "up to isomorphism of Lie algebras".) The vector space $H^{2}\left(
L\right)  $ is called the $2$\textit{-nd cohomology space} (or just the $2$-nd
cohomology) of the Lie algebra $L$.
\end{definition}

\begin{theorem}
\label{thm.H^2(W)}The space $H^{2}\left(  W\right)  $ is $1$-dimensional and
is spanned by the residue class of the $2$-cocycle $\omega$ given by%
\[
\omega\left(  L_{n},L_{m}\right)  =\dfrac{n^{3}-n}{6}\delta_{n,-m}%
\ \ \ \ \ \ \ \ \ \ \text{for all }n,m\in\mathbb{Z}.
\]

\end{theorem}

Note that in this theorem, we could have replaced the factor $\dfrac{n^{3}%
-n}{6}$ by $n^{3}-n$ (since the vector space spanned by a vector obviously
doesn't change if we rescale the vector by a scalar factor), or even by
$n^{3}$ (since the $2$-cocycle $\left(  L_{n},L_{m}\right)  \mapsto
n\delta_{n,-m}$ is a coboundary, and two $2$-cocycles which differ by a
coboundary give the same residue class in $H^{2}\left(  W\right)  $). But we
prefer $\dfrac{n^{3}-n}{6}$ since this is closer to how this class appears in
representation theory (and, also, comes up in the proof below).

\textit{Proof of Theorem \ref{thm.H^2(W)}.} First of all, it is easy to prove
by computation that the bilinear form $\omega:W\times W\rightarrow\mathbb{C}$
given by%
\[
\omega\left(  L_{n},L_{m}\right)  =\dfrac{n^{3}-n}{6}\delta_{n,-m}%
\ \ \ \ \ \ \ \ \ \ \text{for all }n,m\in\mathbb{Z}%
\]
is indeed a $2$-cocycle. Now, let us prove that every $2$-cocycle on $W$ is
congruent to a multiple of $\omega$ modulo the $2$-coboundaries.

Let $\beta$ be a $2$-cocycle on $W$. We must prove that $\beta$ is congruent
to a multiple of $\omega$ modulo the $2$-coboundaries.

Pick $\xi\in W^{\ast}$ such that $\xi\left(  L_{n}\right)  =\dfrac{1}{n}%
\beta\left(  L_{n},L_{0}\right)  $ for all $n\neq0$ (such a $\xi$ clearly
exists, but is not unique since we have complete freedom in choosing
$\xi\left(  L_{0}\right)  $). Let $\widetilde{\beta}$ be the $2$-cocycle
$\beta-d\xi$. Then,
\[
\widetilde{\beta}\left(  L_{n},L_{0}\right)  =\underbrace{\beta\left(
L_{n},L_{0}\right)  }_{\substack{=n\xi\left(  L_{n}\right)  \\\text{(since
}\xi\left(  L_{n}\right)  =\dfrac{1}{n}\beta\left(  L_{n},L_{0}\right)
\text{)}}}-\xi\left(  \underbrace{\left[  L_{n},L_{0}\right]  }_{=nL_{n}%
}\right)  =n\xi\left(  L_{n}\right)  -\xi\left(  nL_{n}\right)  =0
\]
for every $n\neq0$. Thus, by replacing $\beta$ by $\widetilde{\beta}$, we can
WLOG assume that $\beta\left(  L_{n},L_{0}\right)  =0$ for every $n\neq0$.
This clearly also holds for $n=0$ since $\beta$ is skew-symmetric. Hence,
$\beta\left(  X,L_{0}\right)  =0$ for every $X\in W$. Now, by the $2$-cocycle
condition, we have%
\[
\beta\left(  \left[  L_{0},L_{m}\right]  ,L_{n}\right)  +\beta\left(  \left[
L_{n},L_{0}\right]  ,L_{m}\right)  +\beta\left(  \left[  L_{m},L_{n}\right]
,L_{0}\right)  =0.
\]
Thus,%
\begin{align*}
0  &  =\beta\left(  \underbrace{\left[  L_{0},L_{m}\right]  }_{=-mL_{m}}%
,L_{n}\right)  +\beta\left(  \underbrace{\left[  L_{n},L_{0}\right]
}_{=nL_{n}},L_{m}\right)  +\underbrace{\beta\left(  \left[  L_{m}%
,L_{n}\right]  ,L_{0}\right)  }_{=0\text{ (since }\beta\left(  X,L_{0}\right)
=0\text{ for every }X\in W\text{)}}\\
&  =-m\beta\left(  L_{m},L_{n}\right)  +n\underbrace{\beta\left(  L_{n}%
,L_{m}\right)  }_{=-\beta\left(  L_{m},L_{n}\right)  }=-\left(  m+n\right)
\beta\left(  L_{m},L_{n}\right)  .
\end{align*}
Hence, for all $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ with $n+m\neq0$, we have
$\beta\left(  L_{m},L_{n}\right)  =0$. In other words, there exists some
sequence $\left(  b_{n}\right)  _{n\in\mathbb{Z}}\in\mathbb{C}^{\mathbb{Z}}$
such that
\begin{equation}
\beta\left(  L_{n},L_{m}\right)  =b_{n}\delta_{n,-m}%
\ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{Z}\text{ and }m\in\mathbb{Z}.
\label{thm.H^2(W).pf.2}%
\end{equation}
This sequence satisfies
\begin{equation}
b_{-n}=-b_{n}\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}.
\label{thm.H^2(W).pf.1}%
\end{equation}
(since $\beta$ is skew-symmetric and thus $\beta\left(  L_{n},L_{-n}\right)
=-\beta\left(  L_{-n},L_{n}\right)  $) and thus, in particular, $b_{0}=0$. We
will now try to get a recursive equation for this sequence.

Let $m$, $n$ and $p$ be three integers satisfying $m+n+p=0$. Then, the
$2$-cocycle condition yields%
\[
\beta\left(  \left[  L_{p},L_{n}\right]  ,L_{m}\right)  +\beta\left(  \left[
L_{m},L_{p}\right]  ,L_{n}\right)  +\beta\left(  \left[  L_{n},L_{m}\right]
,L_{p}\right)  =0.
\]
Due to%
\begin{align*}
\beta\left(  \underbrace{\left[  L_{p},L_{n}\right]  }_{=\left(  p-n\right)
L_{p+n}},L_{m}\right)   &  =\left(  p-n\right)  \underbrace{\beta\left(
L_{p+n},L_{m}\right)  }_{\substack{=-\beta\left(  L_{m},L_{p+n}\right)
\\\text{(since }\beta\text{ is skew-symmetric)}}}=-\left(  p-n\right)
\underbrace{\beta\left(  L_{m},L_{p+n}\right)  }_{\substack{=b_{m}%
\delta_{m,-\left(  p+n\right)  }\\\text{(by (\ref{thm.H^2(W).pf.2}))}}}\\
&  =-\left(  p-n\right)  b_{m}\underbrace{\delta_{m,-\left(  p+n\right)  }%
}_{\substack{=1\\\text{(since }m+n+p=0\text{)}}}=-\left(  p-n\right)  b_{m}%
\end{align*}
and the two cyclic permutations of this equality, this rewrites as%
\[
\left(  -\left(  p-n\right)  b_{m}\right)  +\left(  -\left(  m-p\right)
b_{n}\right)  +\left(  -\left(  n-m\right)  b_{p}\right)  =0.
\]
In other words,%
\begin{equation}
\left(  n-m\right)  b_{p}+\left(  m-p\right)  b_{n}+\left(  p-n\right)
b_{m}=0. \label{thm.H^2(W).pf.3}%
\end{equation}


Now define a form $\xi_{0}\in L^{\ast}$ by $\xi_{0}\left(  L_{0}\right)  =1$
and $\xi_{0}\left(  L_{i}\right)  =0$ for all $i\neq0$.

By replacing $\beta$ with $\beta-\dfrac{b_{1}}{2}d\xi_{0}$, we can assume WLOG
that $b_{1}=0$.

Now let $n\in\mathbb{Z}$ be arbitrary. Setting $m=1$ and $p=-\left(
n+1\right)  $ in (\ref{thm.H^2(W).pf.3}) (this is allowed since $1+n+\left(
-\left(  n+1\right)  \right)  =0$), we get%
\[
\left(  n-1\right)  b_{-\left(  n+1\right)  }+\left(  1-\left(  -\left(
n+1\right)  \right)  \right)  b_{n}+\left(  n-1\right)  b_{1}=0.
\]
Thus,%
\begin{align*}
0  &  =\left(  n-1\right)  \underbrace{b_{-\left(  n+1\right)  }}%
_{=-b_{n+1}\text{ (by (\ref{thm.H^2(W).pf.1}))}}+\underbrace{\left(  1-\left(
-\left(  n+1\right)  \right)  \right)  }_{=n+2}b_{n}+\left(  n-1\right)
\underbrace{b_{1}}_{=0}\\
&  =-\left(  n-1\right)  b_{n+1}+\left(  n+2\right)  b_{n},
\end{align*}
so that $\left(  n-1\right)  b_{n+1}=\left(  n+2\right)  b_{n}$. This
recurrence equation rewrites as $b_{n+1}=\dfrac{n+2}{n-1}b_{n}$ for $n\geq2$.
Thus, by induction we see that every $n\geq2$ satisfies%
\[
b_{n}=\dfrac{n+1}{n-2}\cdot\dfrac{n}{n-3}\cdot\dfrac{n-1}{n-4}\cdot
...\cdot\dfrac{4}{1}b_{2}=\dfrac{\left(  n+1\right)  \cdot n\cdot...\cdot
4}{\left(  n-2\right)  \cdot\left(  n-3\right)  \cdot...\cdot1}b_{2}%
=\dfrac{\left(  n+1\right)  \left(  n-1\right)  n}{6}b_{2}=\dfrac{n^{3}-n}%
{6}b_{2}.
\]
But $b_{n}=\dfrac{n^{3}-n}{6}b_{2}$ also holds for $n=1$ (since $b_{1}=0$ and
$\dfrac{1^{3}-1}{6}=0$) and for $n=0$ (since $b_{0}=0$ and $\dfrac{0^{3}-0}%
{6}=0$). Hence, $b_{n}=\dfrac{n^{3}-n}{6}b_{2}$ holds for every $n\geq0$. By
(\ref{thm.H^2(W).pf.1}), we conclude that $b_{n}=\dfrac{n^{3}-n}{6}b_{2}$
holds also for every $n\leq0$. Thus, every $n\in\mathbb{Z}$ satisfies
$b_{n}=\dfrac{n^{3}-n}{6}b_{2}$. From (\ref{thm.H^2(W).pf.2}), we thus see
that $\beta$ is a scalar multiple of $\omega$.

We thus have proven that every $2$-cocycle $\beta$ on $W$ is congruent to a
multiple of $\omega$ modulo the $2$-coboundaries. This yields that the space
$H^{2}\left(  W\right)  $ is \textit{at most }$1$-dimensional and is spanned
by the residue class of the $2$-cocycle $\omega$. In order to complete the
proof of Theorem \ref{thm.H^2(W)}, we have yet to prove that $H^{2}\left(
W\right)  $ is indeed $1$-dimensional (and not $0$-dimensional), i. e., that
the $2$-cocycle $\omega$ is \textit{not} a $2$-coboundary. But this is
easy\footnote{\textit{Proof.} Assume the contrary. Then, the $2$-cocycle
$\omega$ is a $2$-coboundary. This means that there exists a linear map
$\xi:W\rightarrow\mathbb{C}$ such that $\omega=d\xi$. Pick such a $\xi$. Then,%
\[
\omega\left(  L_{2},L_{-2}\right)  =\left(  d\xi\right)  \left(  L_{2}%
,L_{-2}\right)  =\xi\left(  \underbrace{\left[  L_{2},L_{-2}\right]
}_{=4L_{0}}\right)  =4\xi\left(  L_{0}\right)
\]
and%
\[
\omega\left(  L_{1},L_{-1}\right)  =\left(  d\xi\right)  \left(  L_{1}%
,L_{-1}\right)  =\xi\left(  \underbrace{\left[  L_{1},L_{-1}\right]
}_{=2L_{0}}\right)  =2\xi\left(  L_{0}\right)  .
\]
Hence,%
\[
2\underbrace{\omega\left(  L_{1},L_{-1}\right)  }_{=2\xi\left(  L_{0}\right)
}=4\xi\left(  L_{0}\right)  =\omega\left(  L_{2},L_{-2}\right)  .
\]
But this contradicts with the equalities $\omega\left(  L_{1},L_{-1}\right)
=0$ and $\omega\left(  L_{2},L_{-2}\right)  =6$ (which easily follow from the
definition of $\omega$). This contradiction shows that our assumption was
wrong, and thus the $2$-cocycle $\omega$ is not a $2$-coboundary, qed.}. The
proof of Theorem \ref{thm.H^2(W)} is thus complete.

The $2$-cocycle $\dfrac{1}{12}\omega$ (where $\omega$ is introduced in Theorem
\ref{thm.H^2(W)}) gives a central extension of the Witt algebra $W$: the
so-called Virasoro algebra. Let us recast the definition of this algebra in
elementary terms:

\begin{definition}
The \textit{Virasoro algebra} $\operatorname*{Vir}$ is defined as the vector
space $W\oplus\mathbb{C}$ with Lie bracket defined by%
\begin{align*}
\left[  L_{n},L_{m}\right]   &  =\left(  n-m\right)  L_{n+m}+\dfrac{n^{3}%
-n}{12}\delta_{n,-m}C;\\
\left[  L_{n},C\right]   &  =0,
\end{align*}
where $L_{n}$ denotes $\left(  L_{n},0\right)  $ for every $n\in\mathbb{Z}$,
and where $C$ denotes $\left(  0,1\right)  $. Note that $\left\{  L_{n}%
\ \mid\ n\in\mathbb{Z}\right\}  \cup\left\{  C\right\}  $ is a basis of
$\operatorname*{Vir}$.
\end{definition}

If we change the denominator $12$ to any other nonzero complex number, we get
a Lie algebra isomorphic to $\operatorname*{Vir}$ (it is just a rescaling of
$C$). It is easy to show that the Virasoro algebra is not isomorphic to the
Lie-algebraic direct sum $W\oplus\mathbb{C}$. Thus, $\operatorname*{Vir}$ is
the unique (up to Lie algebra isomorphism) nontrivial $1$-dimensional central
extension of $W$.

\subsection{Affine Lie algebras}

Now let us talk about affine Lie algebras:

\begin{definition}
\label{def.loop}Let $\mathfrak{g}$ be a Lie algebra with a symmetric bilinear
form $\left(  \cdot,\cdot\right)  $ invariant under the Lie bracket (this
means that $\left(  \left[  a,b\right]  ,c\right)  +\left(  b,\left[
a,c\right]  \right)  =0$ for all $a,b,c\in\mathfrak{g}$). The $\mathbb{C}$-Lie
algebra $\mathfrak{g}$ induces (by extension of scalars) a $\mathbb{C}\left[
t,t^{-1}\right]  $-Lie algebra $\mathbb{C}\left[  t,t^{-1}\right]
\otimes\mathfrak{g}=\left\{  \sum\limits_{i}a_{i}t^{i}\ \mid\ a_{i}%
\in\mathfrak{g}\right\}  $. This Lie algebra $\mathbb{C}\left[  t,t^{-1}%
\right]  \otimes\mathfrak{g}$, considered as a $\mathbb{C}$-Lie algebra, will
be called the \textit{loop algebra} of $\mathfrak{g}$, and denoted by
$\mathfrak{g}\left[  t,t^{-1}\right]  $.

Then, we can define a $2$-cocycle $\omega$ on the loop algebra $\mathfrak{g}%
\left[  t,t^{-1}\right]  $ by%
\begin{equation}
\omega\left(  f,g\right)  =\operatorname*{Res}\nolimits_{t=0}%
\underbrace{\left(  df,g\right)  }_{\text{scalar-valued }1\text{-form}}%
=\sum\limits_{i\in\mathbb{Z}}i\left(  f_{i},g_{-i}\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }f,g\in\mathfrak{g}\left[  t,t^{-1}%
\right]  \label{loop.w}%
\end{equation}
(where we write $f$ in the form $f=\sum\limits_{i\in\mathbb{Z}}f_{i}t^{i}$
with $f_{i}\in\mathfrak{g}$, and where we write $g$ in the form $g=\sum
\limits_{i\in\mathbb{Z}}g_{i}t^{i}$ with $g_{i}\in\mathfrak{g}$).

Proving that $\omega$ is a $2$-cocycle is an exercise. So we can define a
$1$-dimensional central extension $\mathfrak{g}\left[  t,t^{-1}\right]
_{\omega}=\mathfrak{g}\left[  t,t^{-1}\right]  \oplus\mathbb{C}$ with bracket
defined by $\omega$.

We are going to abbreviate $\mathfrak{g}\left[  t,t^{-1}\right]  _{\omega}$ by
$\widehat{\mathfrak{g}}_{\omega}$, or, more radically, by
$\widehat{\mathfrak{g}}$.
\end{definition}

The main example that we will care about is when $\mathfrak{g}$ is a simple
finite-dimensional Lie algebra and $\left(  \cdot,\cdot\right)  $ is the
unique (up to scalar) invariant symmetric bilinear form (i. e., a multiple of
the Killing form).

\begin{theorem}
\label{thm.H^2(gtt)}If $\mathfrak{g}$ is a simple finite-dimensional Lie
algebra, then $H^{2}\left(  \mathfrak{g}\left[  t,t^{-1}\right]  \right)  $ is
$1$-dimensional and spanned by the cocycle $\omega$ corresponding to $\left(
\cdot,\cdot\right)  $.
\end{theorem}

\begin{corollary}
\label{cor.g_w^hat}If $\mathfrak{g}$ is a simple finite-dimensional Lie
algebra, then the Lie algebra $\mathfrak{g}\left[  t,t^{-1}\right]  $ has a
unique (up to isomorphism of Lie algebras, not up to isomorphism of
extensions) nontrivial $1$-dimensional central extension
$\widehat{\mathfrak{g}}_{\omega}$.
\end{corollary}

\begin{definition}
\label{def.kac}The Lie algebra $\widehat{\mathfrak{g}}_{\omega}$ defined in
Corollary \ref{cor.g_w^hat} is called the \textit{affine Kac-Moody algebra}.
(Or, more precisely, the \textit{untwisted affine Kac-Moody algebra}.)
\end{definition}

In order to prepare for the proof of Theorem \ref{thm.H^2(gtt)}, we recollect
some facts from the cohomology of Lie algebras:

\begin{definition}
Let $\mathfrak{g}$ be a Lie algebra. Let $M$ be a $\mathfrak{g}$-module. We
define the \textit{semidirect product} $\mathfrak{g}\ltimes M$ to be the Lie
algebra which, as a vector space, is $\mathfrak{g}\oplus M$, but whose Lie
bracket is defined by%
\[
\left[  \left(  a,\alpha\right)  ,\left(  b,\beta\right)  \right]  =\left(
\left[  a,b\right]  ,a\circ\beta-b\circ\alpha\right)  .
\]
(The symbol $\circ$ means action here; i. e., a term like $c\circ m$ (with
$c\in\mathfrak{g}$ and $m\in M$) means the action of $c$ on $m$.) Thus, the
canonical injection $\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,$
$a\mapsto\left(  a,0\right)  $ is a Lie algebra homomorphism, and so is the
canonical projection $\mathfrak{g}\ltimes M\rightarrow\mathfrak{g},$ $\left(
a,\alpha\right)  \mapsto a$. Also, $M$ is embedded into $\mathfrak{g}\ltimes
M$ by the injection $M\rightarrow\mathfrak{g}\ltimes M,$ $\alpha\mapsto\left(
0,\alpha\right)  $; this makes $M$ an abelian Lie subalgebra of $\mathfrak{g}%
\ltimes M$.
\end{definition}

\begin{definition}
Let $\mathfrak{g}$ be a Lie algebra. Let $M$ be a $\mathfrak{g}$-module. A
$1$\textit{-cocycle} \textit{of }$\mathfrak{g}$\textit{ with coefficients in
}$M$ is a linear map $\eta:\mathfrak{g}\rightarrow M$ such that%
\[
\eta\left(  \left[  a,b\right]  \right)  =a\circ\eta\left(  b\right)
-b\circ\eta\left(  a\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }%
a\in\mathfrak{g}\text{ and }b\in\mathfrak{g}.
\]
(The symbol $\circ$ means action here; i. e., a term like $c\circ m$ (with
$c\in\mathfrak{g}$ and $m\in M$) means the action of $c$ on $m$.)

It is easy to see (and known) that $1$-cocycles of $\mathfrak{g}$ with
coefficients in $M$ are in bijection with Lie algebra homomorphisms
$\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M$. This bijection sends every
$1$-cocycle $\eta$ to the map $\mathfrak{g}\rightarrow\mathfrak{g}\ltimes M,$
$a\mapsto\left(  a,\eta\left(  a\right)  \right)  $.

A $1$\textit{-coboundary of }$\mathfrak{g}$ \textit{with coefficients in }$M$
means a linear map $\eta:\mathfrak{g}\rightarrow M$ which has the form
$a\mapsto a\circ m$ for some $m\in M$. Every $1$-coboundary of $\mathfrak{g}$
with coefficients in $M$ is a $1$-cocycle.

The space of $1$-cocycles of $\mathfrak{g}$ with coefficients in $M$ is
denoted by $Z^{1}\left(  \mathfrak{g},M\right)  $. The space of $1$%
-coboundaries of $\mathfrak{g}$ with coefficients in $M$ is denoted by
$B^{1}\left(  \mathfrak{g},M\right)  $. We have $B^{1}\left(  \mathfrak{g}%
,M\right)  \subseteq Z^{1}\left(  \mathfrak{g},M\right)  $. The quotient space
$Z^{1}\left(  \mathfrak{g},M\right)  \diagup B^{1}\left(  \mathfrak{g}%
,M\right)  $ is denoted by $H^{1}\left(  \mathfrak{g},M\right)  $ is called
the $1$\textit{-st cohomology space} of $\mathfrak{g}$\textit{ with
coefficients in }$M$.

Of course, these spaces $Z^{1}\left(  \mathfrak{g},M\right)  $, $B^{1}\left(
\mathfrak{g},M\right)  $ and $H^{1}\left(  \mathfrak{g},M\right)  $ are but
particular case of more general constructions $Z^{i}\left(  \mathfrak{g}%
,M\right)  $, $B^{i}\left(  \mathfrak{g},M\right)  $ and $H^{i}\left(
\mathfrak{g},M\right)  $ which are defined for every $i\in\mathbb{N}$. (In
particular, $H^{0}\left(  \mathfrak{g},M\right)  $ is the subspace $\left\{
m\in M\ \mid\ a\circ m=0\text{ for all }a\in\mathfrak{g}\right\}  $ of $M$,
and often denoted by $M^{\mathfrak{g}}$. The spaces $H^{i}\left(
\mathfrak{g},M\right)  $ (or, more precisely, the functors assigning these
spaces to every $\mathfrak{g}$-module $M$) can be understood as the so-called
derived functors of the functor $M\mapsto M^{\mathfrak{g}}$. However, we won't
use $H^{i}\left(  \mathfrak{g},M\right)  $ for any $i$ other than $1$ here.

We record a relation between $H^{1}\left(  \mathfrak{g},M\right)  $ and the
$\operatorname*{Ext}$ bifunctor:%
\[
H^{1}\left(  \mathfrak{g},M\right)  =\operatorname*{Ext}%
\nolimits_{\mathfrak{g}}^{1}\left(  \mathbb{C},M\right)  .
\]
More generally, $\operatorname*{Ext}\nolimits_{\mathfrak{g}}^{1}\left(
N,M\right)  =H^{1}\left(  \mathfrak{g},\operatorname*{Hom}%
\nolimits_{\mathbb{C}}\left(  N,M\right)  \right)  $ for any two
$\mathfrak{g}$-modules $N$ and $M$.
\end{definition}

\begin{theorem}
[Whitehead]\label{thm.white}If $\mathfrak{g}$ is a simple finite-dimensional
Lie algebra, and $M$ is a finite-dimensional $\mathfrak{g}$-module, then
$H^{1}\left(  \mathfrak{g},M\right)  =0$.
\end{theorem}

\textit{Proof of Theorem \ref{thm.white}.} Since $\mathfrak{g}$ is a simple
Lie algebra, Weyl's theorem says that finite-dimensional $\mathfrak{g}%
$-modules are completely reducible. Hence, if $N$ and $M$ are
finite-dimensional $\mathfrak{g}$-modules, we have $\operatorname*{Ext}%
\nolimits_{\mathfrak{g}}^{1}\left(  N,M\right)  =0$. In particular,
$\operatorname*{Ext}\nolimits_{\mathfrak{g}}^{1}\left(  \mathbb{C},M\right)
=0$. Since $H^{1}\left(  \mathfrak{g},M\right)  =\operatorname*{Ext}%
\nolimits_{\mathfrak{g}}^{1}\left(  \mathbb{C},M\right)  $, this yields
$H^{1}\left(  \mathfrak{g},M\right)  =0$. Theorem \ref{thm.white} is thus proven.

\begin{lemma}
\label{lem.Z^1}Let $\omega$ be a $2$-cocycle on a Lie algebra $\mathfrak{g}$.
Let $\mathfrak{g}_{0}\subseteq\mathfrak{g}$ be a Lie subalgebra, and
$M\subseteq\mathfrak{g}$ be a $\mathfrak{g}_{0}$-submodule. Then, $\omega
\mid_{\mathfrak{g}_{0}\times M}$, when considered as a map $\mathfrak{g}%
_{0}\rightarrow M^{\ast}$, belongs to $Z^{1}\left(  \mathfrak{g}_{0},M^{\ast
}\right)  $.
\end{lemma}

The proof of Lemma \ref{lem.Z^1} is left as an exercise (it is a
straightforward manipulation of formulas).

\textit{Proof of Theorem \ref{thm.H^2(gtt)}.} First notice that any
$a,b,c\in\mathfrak{g}$ satisfy%
\begin{equation}
\left(  \left[  a,b\right]  ,c\right)  =\left(  \left[  b,c\right]  ,a\right)
=\left(  \left[  c,a\right]  ,b\right)  \label{thm.H^2(gtt).pf.0}%
\end{equation}
\footnote{\textit{Proof.} First of all, any $a,b,c\in\mathfrak{g}$ satisfy%
\begin{align*}
\left(  \left[  a,b\right]  ,c\right)   &  =\left(  a,\left[  b,c\right]
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the form }\left(  \cdot
,\cdot\right)  \text{ is invariant}\right) \\
&  =\left(  \left[  b,c\right]  ,a\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since the form }\left(  \cdot,\cdot\right)  \text{ is symmetric}\right)
.
\end{align*}
Applying this to $b,c,a$ instead of $a,b,c$, we obtain $\left(  \left[
b,c\right]  ,a\right)  =\left(  \left[  c,a\right]  ,b\right)  $. Hence,
$\left(  \left[  a,b\right]  ,c\right)  =\left(  \left[  b,c\right]
,a\right)  =\left(  \left[  c,a\right]  ,b\right)  $, so that
(\ref{thm.H^2(gtt).pf.0}) is proven.}. Moreover,%
\begin{equation}
\text{there exist }a,b,c\in\mathfrak{g}\text{ such that }\left(  \left[
a,b\right]  ,c\right)  =\left(  \left[  b,c\right]  ,a\right)  =\left(
\left[  c,a\right]  ,b\right)  \neq0. \label{thm.H^2(gtt).pf.00}%
\end{equation}
\footnote{\textit{Proof.} Since $\mathfrak{g}$ is simple, we have $\left[
\mathfrak{g},\mathfrak{g}\right]  =\mathfrak{g}$ and thus $\left(  \left[
\mathfrak{g},\mathfrak{g}\right]  ,\mathfrak{g}\right)  =\left(
\mathfrak{g},\mathfrak{g}\right)  \neq0$ (since the form $\left(  \cdot
,\cdot\right)  $ is nondegenerate). Hence, there exist $a,b,c\in\mathfrak{g}$
such that $\left(  \left[  a,b\right]  ,c\right)  \neq0$. The rest is handled
by (\ref{thm.H^2(gtt).pf.0}).} This will be used later in our proof; but as
for now, forget about these $a,b,c$.

It is easy to see that the $2$-cocycle $\omega$ on $\mathfrak{g}\left[
t,t^{-1}\right]  $ defined by (\ref{loop.w}) is not a $2$%
-coboundary.\footnote{\textit{Proof.} Assume the contrary. Then, this
$2$-cocycle $\omega$ is a coboundary, i. e., there exists a linear map
$\xi:\mathfrak{g}\left[  t,t^{-1}\right]  \rightarrow\mathbb{C}$ such that
$\omega=d\xi$.
\par
Now, pick some $a\in\mathfrak{g}$ and $b\in\mathfrak{g}$ such that $\left(
a,b\right)  \neq0$ (this is possible since the form $\left(  \cdot
,\cdot\right)  $ is nondegenerate). Then,%
\[
\underbrace{\omega}_{=d\xi}\left(  at,bt^{-1}\right)  =\left(  d\xi\right)
\left(  at,bt^{-1}\right)  =\xi\left(  \underbrace{\left[  at,bt^{-1}\right]
}_{=\left[  a,b\right]  }\right)  =\xi\left(  \left[  a,b\right]  \right)
\]
and%
\[
\underbrace{\omega}_{=d\xi}\left(  a,b\right)  =\left(  d\xi\right)  \left(
a,b\right)  =\xi\left(  \left[  a,b\right]  \right)  ,
\]
so that $\omega\left(  at,bt^{-1}\right)  =\omega\left(  a,b\right)  $. But by
the definition of $\omega$, we easily see that $\omega\left(  at,bt^{-1}%
\right)  =1\underbrace{\left(  a,b\right)  }_{\neq0}\neq0$ and $\omega\left(
a,b\right)  =0\left(  a,b\right)  =0$, which yields a contradiction.}

Now let us consider the structure of $\mathfrak{g}\left[  t,t^{-1}\right]  $.
We have $\mathfrak{g}\left[  t,t^{-1}\right]  =\bigoplus\limits_{n\in
\mathbb{Z}}\mathfrak{g}t^{n}\supseteq\mathfrak{g}t^{0}=\mathfrak{g}$. This is,
actually, an inclusion of Lie algebras. So $\mathfrak{g}$ is a Lie subalgebra
of $\mathfrak{g}\left[  t,t^{-1}\right]  $, and $\mathfrak{g}t^{n}$ is a
$\mathfrak{g}$-submodule of $\mathfrak{g}\left[  t,t^{-1}\right]  $ isomorphic
to $\mathfrak{g}$ for every $n\in\mathbb{Z}$.

Let $\omega$ be an arbitrary $2$-cocycle on $\mathfrak{g}\left[
t,t^{-1}\right]  $ (not necessarily the one defined by (\ref{loop.w})).

Let $n\in\mathbb{Z}$. Then, $\omega\mid_{\mathfrak{g}\times\mathfrak{g}t^{n}}%
$, when considered as a map $\mathfrak{g}\rightarrow\left(  \mathfrak{g}%
t^{n}\right)  ^{\ast}$, belongs to $Z^{1}\left(  \mathfrak{g},\left(
\mathfrak{g}t^{n}\right)  ^{\ast}\right)  $ (by Lemma \ref{lem.Z^1}, applied
to $\mathfrak{g}$, $\mathfrak{g}t^{n}$ and $\mathfrak{g}\left[  t,t^{-1}%
\right]  $ instead of $\mathfrak{g}_{0}$, $M$ and $\mathfrak{g}$), i. e., is a
$1$-cocycle. But by Theorem \ref{thm.white}, we have $H^{1}\left(
\mathfrak{g},\left(  \mathfrak{g}t^{n}\right)  ^{\ast}\right)  =0$, so this
rewrites as $\omega\mid_{\mathfrak{g}\times\mathfrak{g}t^{n}}\in B^{1}\left(
\mathfrak{g},\left(  \mathfrak{g}t^{n}\right)  ^{\ast}\right)  $. In other
words, there exists some $\xi_{n}\in\left(  \mathfrak{g}t^{n}\right)  ^{\ast}$
such that $\omega\mid_{\mathfrak{g}\times\mathfrak{g}t^{n}}=d\xi_{n}$. Pick
such a $\xi_{n}$. Thus,%
\[
\omega\left(  a,bt^{n}\right)  =\underbrace{\left(  \omega\mid_{\mathfrak{g}%
\times\mathfrak{g}t^{n}}\right)  }_{=d\xi_{n}}\left(  a,bt^{n}\right)
=\left(  d\xi_{n}\right)  \left(  a,bt^{n}\right)  =\xi_{n}\left(  \left[
a,bt^{n}\right]  \right)  \ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in
\mathfrak{g}.
\]


Define a map $\xi:\mathfrak{g}\left[  t,t^{-1}\right]  \rightarrow\mathbb{C}$
by requiring that $\xi\mid_{\mathfrak{g}t^{n}}=\xi_{n}$ for every
$n\in\mathbb{Z}$.

Now, let $\widetilde{\omega}=\omega-d\xi$. Then,%
\[
\widetilde{\omega}\left(  x,y\right)  =\omega\left(  x,y\right)  -\xi\left(
\left[  x,y\right]  \right)  \ \ \ \ \ \ \ \ \ \ \text{for all }%
x,y\in\mathfrak{g}\left[  t,t^{-1}\right]  .
\]
Replace $\omega$ by $\widetilde{\omega}$ (this doesn't change the residue
class of $\omega$ in $H^{2}\left(  \mathfrak{g}\left[  t,t^{-1}\right]
\right)  $, since $\widetilde{\omega}$ differs from $\omega$ by a
$2$-coboundary). By doing this, we have reduced to a situation when
\[
\omega\left(  a,bt^{n}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
a,b\in\mathfrak{g}\text{ and }n\in\mathbb{Z}.
\]
\footnote{But all the $\xi$-freedom has been used up in this reduction - i.
e., if the new $\omega$ is nonzero, then the original $\omega$ was not a
$2$-coboundary. This gives us an alternative way of proving that the
$2$-cocycle $\omega$ on $\mathfrak{g}\left[  t,t^{-1}\right]  $ defined by
(\ref{loop.w}) is not a $2$-coboundary.} Since $\omega$ is antisymmetric, this
yields%
\begin{equation}
\omega\left(  bt^{n},a\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }%
a,b\in\mathfrak{g}\text{ and }n\in\mathbb{Z}. \label{thm.H^2(gtt).pf.1}%
\end{equation}


Now, fix some $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$. Since $\omega$ is a
$2$-cocycle, the $2$-cocycle condition yields%
\begin{align*}
0  &  =\omega\left(  \underbrace{\left[  a,bt^{n}\right]  }_{=\left[
a,b\right]  t^{n}},ct^{m}\right)  +\omega\left(  \underbrace{\left[
ct^{m},a\right]  }_{\substack{=\left[  c,a\right]  t^{m}\\=-\left[
a,c\right]  t^{m}}},bt^{n}\right)  +\underbrace{\omega\left(  \left[
bt^{n},ct^{m}\right]  ,a\right)  }_{\substack{=0\\\text{(by
(\ref{thm.H^2(gtt).pf.1}))}}}\\
&  =\omega\left(  \left[  a,b\right]  t^{n},ct^{m}\right)  +\omega\left(
bt^{n},\left[  a,c\right]  t^{m}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}a,b,c\in\mathfrak{g}\text{.}%
\end{align*}
In other words, the bilinear form on $\mathfrak{g}$ given by $\left(
b,c\right)  \mapsto\omega\left(  bt^{n},ct^{m}\right)  $ is $\mathfrak{g}%
$-invariant. But every $\mathfrak{g}$-invariant bilinear form on
$\mathfrak{g}$ must be a multiple of our bilinear form $\left(  \cdot
,\cdot\right)  $ (since $\mathfrak{g}$ is simple, and thus the space of all
$\mathfrak{g}$-invariant bilinear forms on $\mathfrak{g}$ is $1$%
-dimensional\footnote{and spanned by the Killing form}). Hence, there exists
some constant $\gamma_{n,m}\in\mathbb{C}$ such that
\begin{equation}
\omega\left(  bt^{n},ct^{m}\right)  =\gamma_{n,m}\cdot\left(  b,c\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }b,c\in\mathfrak{g}.
\label{thm.H^2(gtt).pf.2}%
\end{equation}
It is easy to see that%
\begin{equation}
\gamma_{n,m}=-\gamma_{m,n}\ \ \ \ \ \ \ \ \ \ \text{for all }n,m\in\mathbb{Z},
\label{thm.H^2(gtt).pf.3}%
\end{equation}
since the bilinear form $\omega$ is skew-symmetric whereas the bilinear form
$\left(  \cdot,\cdot\right)  $ is symmetric.

Now, for any $m\in\mathbb{Z}$, $n\in\mathbb{Z}$ and $p\in\mathbb{Z}$, the
$2$-cocycle condition yields%
\[
\omega\left(  \left[  at^{n},bt^{m}\right]  ,ct^{p}\right)  +\omega\left(
\left[  bt^{m},ct^{p}\right]  ,at^{n}\right)  +\omega\left(  \left[
ct^{p},at^{n}\right]  ,bt^{m}\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all
}a,b,c\in\mathfrak{g}.
\]
Due to%
\[
\omega\left(  \underbrace{\left[  at^{n},bt^{m}\right]  }_{=\left[
a,b\right]  t^{n+m}},ct^{p}\right)  =\omega\left(  \left[  a,b\right]
t^{n+m},ct^{p}\right)  =\gamma_{n+m,p}\cdot\left(  \left[  a,b\right]
,c\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{thm.H^2(gtt).pf.2}%
)}\right)
\]
and the two cyclic permutations of this identity, this rewrites as%
\[
\gamma_{n+m,p}\cdot\left(  \left[  a,b\right]  ,c\right)  +\gamma_{m+p,n}%
\cdot\left(  \left[  b,c\right]  ,a\right)  +\gamma_{p+n,m}\cdot\left(
\left[  c,a\right]  ,b\right)  =0.
\]
Since this holds for all $a,b,c\in\mathfrak{g}$, we can use
(\ref{thm.H^2(gtt).pf.00}) to transform this into%
\[
\gamma_{n+m,p}+\gamma_{m+p,n}+\gamma_{p+n,m}=0.
\]
Due to (\ref{thm.H^2(gtt).pf.3}), this rewrites as%
\[
\gamma_{n,m+p}+\gamma_{m,p+n}+\gamma_{p,m+n}=0.
\]
Denoting by $s$ the sum $m+n+p$, we can rewrite this as%
\[
\gamma_{n,s-n}+\gamma_{m,s-n}-\gamma_{m+n,s-m-n}=0.
\]
In other words, for fixed $s\in\mathbb{Z}$, the function $\mathbb{Z}%
\rightarrow\mathbb{C},$ $n\mapsto\gamma_{n,s-n}$ is additive. Hence,
$\gamma_{n,s-n}=n\gamma_{1,s-1}$ and $\gamma_{s-n,n}=\left(  s-n\right)
\gamma_{1,s-1}$ for every $n\in\mathbb{Z}$. Thus,
\begin{align*}
\left(  s-n\right)  \gamma_{1,s-1}  &  =\gamma_{s-n,n}=-\gamma_{n,s-n}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{thm.H^2(gtt).pf.3})}\right) \\
&  =-n\gamma_{1,s-1}\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}%
\end{align*}
Hence, $s\gamma_{1,s-1}=0$. Thus, for every $s\neq0$, we conclude that
$\gamma_{1,s-1}=0$ and hence $\gamma_{n,s-n}=n\underbrace{\gamma_{1,s-1}}%
_{=0}=0$ for every $n\in\mathbb{Z}$. In other words, $\gamma_{n,m}=0$ for
every $n\in\mathbb{N}$ and $m\in\mathbb{N}$ satisfying $n+m\neq0$.

What happens for $s=0$ ? For $s=0$, the equation $\gamma_{n,s-n}%
=n\gamma_{1,s-1}$ becomes $\gamma_{n,-n}=n\gamma_{1,-1}$.

Hence, the form $\omega$ must be a scalar multiple of the form which sends
every $\left(  f,g\right)  $ to $\operatorname*{Res}\nolimits_{t=0}%
\underbrace{\left(  df,g\right)  }_{\text{scalar-valued }1\text{-form}}%
=\sum\limits_{i\in\mathbb{Z}}i\left(  f_{i},g_{-i}\right)  $. We have thus
proven that every $2$-cocycle $\omega$ is a scalar multiple of the $2$-cocycle
$\omega$ defined by (\ref{loop.w}) modulo the $2$-coboundaries. Since we also
know that the $2$-cocycle $\omega$ defined by (\ref{loop.w}) is not a
$2$-coboundary, this yields that the space $H^{2}\left(  \mathfrak{g}\left[
t,t^{-1}\right]  \right)  $ is $1$-dimensional and spanned by the residue
class of the $2$-cocycle $\omega$ defined by (\ref{loop.w}). This proves
Theorem \ref{thm.H^2(gtt)}.

\section{Representation theory: generalities}

\subsection{Representation theory: general facts}

The first step in the representation theory of any objects (groups, algebras,
etc.) is usually proving some kind of Schur's lemma. There is one form of
Schur's lemma that holds almost tautologically: This is the form that claims
that every morphism between irreducible representations is either $0$ or an
isomorphism.\footnote{There are also variations on this assertion:
\par
\textbf{1)} Every morphism from an irreducible representation to a
representation is either $0$ or injective.
\par
\textbf{2)} Every morphism from a representation to an irreducible
representation is either $0$ or surjective.
\par
Both of these variations follow very easily from the definition of
"irreducible".} However, the more often used form of Schur's lemma is a bit
different: It claims that, over an algebraically closed field, every
endomorphism of a finite-dimensional irreducible representation is a scalar
multiple of the identity map. This is usually proven using eigenvalues, and
this proof depends on the fact that eigenvalues exist; this (in general)
requires the irreducible representation to be \textit{finite-dimensional}.
Hence, it should not come as a surprise that this latter form of Schur's lemma
does not generally hold for infinite-dimensional representations. This makes
this lemma not particularly useful in the case of infinite-dimensional Lie
algebras. But we still can show the following version of Schur's lemma over
$\mathbb{C}$:

\begin{lemma}
[Dixmier's Lemma]\label{lem.dix}Let $A$ be an algebra over $\mathbb{C}$, and
let $V$ be an irreducible $A$-module of countable dimension. Then, any
$A$-module homomorphism $\phi:V\rightarrow V$ is a scalar multiple of the identity.
\end{lemma}

\textit{Proof of Lemma \ref{lem.dix}.} Let $D=\operatorname*{End}%
\nolimits_{A}V$. Then, $D$ is a division algebra (in fact, the endomorphism
ring of an irreducible representation always is a division algebra).

For any nonzero $v\in V$, we have $Av=V$ (otherwise, $Av$ would be a nonzero
proper $A$-submodule of $V$, contradicting the fact that $V$ is irreducible
and thus does not have any such submodules). In other words, for any nonzero
$v\in V$, every element of $V$ can be written as $av$ for some $a\in A$. Thus,
for any nonzero $v\in V$, any element $\phi\in D$ is completely determined by
$\phi\left(  v\right)  $ (because $\phi\left(  av\right)  =a\phi\left(
v\right)  $ for every $a\in A$, so that the value $\phi\left(  v\right)  $
uniquely determines the value of $\phi\left(  av\right)  $ for every $a\in A$,
and thus (since we know that every element of $V$ can be written as $av$ for
some $a\in A$) every value of $\phi$ is uniquely determined). Thus, we have an
embedding of $D$ into $V$. Hence, $D$ is countably-dimensional (since $V$ is
countably-dimensional). But a countably-dimensional division algebra $D$ over
$\mathbb{C}$ must be $\mathbb{C}$ itself\footnote{\textit{Proof.} Indeed,
assume the contrary. So there exists some $\phi\in D$ not belonging to
$\mathbb{C}$. Then, $\phi$ is transcendental over $\mathbb{C}$, so that
$\mathbb{C}\left(  \phi\right)  \subseteq D$ is the field of rational
functions in one variable $\phi$ over $\mathbb{C}$. Now, $\mathbb{C}\left(
\phi\right)  $ contains the rational function $\dfrac{1}{\phi-\lambda}$ for
every $\lambda\in\mathbb{C}$, and these rational functions for varying
$\lambda$ are linearly independent. Since $\mathbb{C}$ is uncountable, we thus
have an uncountable linearly independent set of elements of $\mathbb{C}\left(
\phi\right)  $, contradicting the fact that $\mathbb{C}\left(  \phi\right)  $
is a subspace of the countably-dimensional space $D$, qed.}, so that
$D=\mathbb{C}$, and this is exactly what we wanted to show. Lemma
\ref{lem.dix} is proven.

Note that Lemma \ref{lem.dix} is a general fact, not particular to Lie
algebras; however, it is not as general as it seems: It really makes use of
the uncountability of $\mathbb{C}$, not just of the fact that $\mathbb{C}$ is
an algebraically closed field of characteristic $0$. It would be wrong if we
would replace $\mathbb{C}$ by (for instance) the algebraic closure of
$\mathbb{Q}$.

\begin{remark}
\label{rem.dix}Let $A$ be a countably-dimensional algebra over $\mathbb{C}$,
and let $V$ be an irreducible $A$-module. Then, $V$ itself is countably dimensional.
\end{remark}

\textit{Proof of Remark \ref{rem.dix}.} For any nonzero $v\in V$, we have
$Av=V$ (by the same argument as in the proof of Lemma \ref{lem.dix}), and thus
$\dim\left(  Av\right)  =\dim V$. Since $\dim\left(  Av\right)  \leq\dim A$,
we thus have $\dim V=\dim\left(  Av\right)  \leq\dim A$, so that $V$ has
countable dimension (since $A$ has countable dimension). This proves Remark
\ref{rem.dix}.

\begin{corollary}
\label{cor.dix2}Let $A$ be an algebra over $\mathbb{C}$, and let $V$ be an
irreducible $A$-module of countable dimension. Let $C$ be a central element of
$A$. Then, $C\mid_{V}$ is a scalar (i. e., a scalar multiple of the identity map).
\end{corollary}

\textit{Proof of Corollary \ref{cor.dix2}.} Since $C$ is central, the element
$C$ commutes with any element of $A$. Thus, $C\mid_{V}$ is an $A$-module
homomorphism, and hence (by Lemma \ref{lem.dix}, applied to $\phi=C\mid_{V}$)
a scalar multiple of the identity. This proves Corollary \ref{cor.dix2}.

\subsection{Representations of the Heisenberg algebra $\mathcal{A}$}

Consider the oscillator algebra (aka Heisenberg algebra) $\mathcal{A}%
=\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\right\rangle +\left\langle
K\right\rangle $. Recall that%
\begin{align*}
\left[  a_{i},a_{j}\right]   &  =i\delta_{i,-j}K\ \ \ \ \ \ \ \ \ \ \text{for
any }i,j\in\mathbb{Z};\\
\left[  K,a_{i}\right]   &  =0\ \ \ \ \ \ \ \ \ \ \text{for any }%
i\in\mathbb{Z}.
\end{align*}


Let us try to classify the irreducible $\mathcal{A}$-modules.

Let $V$ be an irreducible $\mathcal{A}$-module. Then, $V$ is
countably-dimensional (by Remark \ref{rem.dix}, since $U\left(  \mathcal{A}%
\right)  $ is countably-dimensional), so that by Corollary \ref{cor.dix2}, the
endomorphism $K\mid_{V}$ is a scalar (because $K$ is a central element of
$\mathcal{A}$ and thus also a central element of $U\left(  \mathcal{A}\right)
$).

If $K\mid_{V}=0$, then $V$ is a module over the Lie algebra $\mathcal{A}%
\diagup\mathbb{C}K=\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\right\rangle $.
But since $\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\right\rangle $ is an
abelian Lie algebra, irreducible modules over $\left\langle a_{i}\ \mid
\ i\in\mathbb{Z}\right\rangle $ are $1$-dimensional (again by Corollary
\ref{cor.dix2}), so that $V$ must be $1$-dimensional in this case. Thus, the
case when $K\mid_{V}=0$ is not an interesting case.

Now consider the case when $K\mid_{V}=k\neq0$. Then, we can WLOG assume that
$k=1$, because the Lie algebra $\mathcal{A}$ has an automorphism sending $K$
to $\lambda K$ for any arbitrary $\lambda\neq0$ (this automorphism is given by
$a_{i}\mapsto\lambda a_{i}$ for $i>0$, and $a_{i}\mapsto a_{i}$ for $i\leq0$).

We are thus interested in irreducible representations $V$ of $\mathcal{A}$
satisfying $K\mid_{V}=1$. These are in an obvious 1-to-1 correspondence with
irreducible representations of $U\left(  \mathcal{A}\right)  \diagup\left(
K-1\right)  $.

\begin{proposition}
\label{prop.K-1}We have an algebra isomorphism%
\[
\xi:U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)  \rightarrow
D\left(  x_{1},x_{2},x_{3},...\right)  \otimes\mathbb{C}\left[  x_{0}\right]
,
\]
where $D\left(  x_{1},x_{2},x_{3},...\right)  $ is the algebra of differential
operators in the variables $x_{1}$, $x_{2}$, $x_{3}$, $...$ with polynomial
coefficients. This isomorphism is given by%
\begin{align*}
\xi\left(  a_{-i}\right)   &  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{i}\right)   &  =i\dfrac{\partial}{\partial x_{i}}%
\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{0}\right)   &  =x_{0}.
\end{align*}

\end{proposition}

Note that we are sloppy with notation here: Since $\xi$ is a homomorphism from
$U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)  $ (rather than
$U\left(  \mathcal{A}\right)  $), we should write $\xi\left(  \overline
{a_{-i}}\right)  $ instead of $\xi\left(  a_{-i}\right)  $, etc.. We are using
the same letters to denote elements of $U\left(  \mathcal{A}\right)  $ and
their residue classes in $U\left(  \mathcal{A}\right)  \diagup\left(
K-1\right)  $, and are relying on context to keep them apart. We hope that the
reader will forgive us this abuse of notation.

\textit{Proof of Proposition \ref{prop.K-1}.} It is clear\footnote{from the
universal property of the universal enveloping algebra, and the universal
property of the quotient algebra} that there exists a unique algebra
homomorphism $\xi:U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)
\rightarrow D\left(  x_{1},x_{2},x_{3},...\right)  $ satisfying%
\begin{align*}
\xi\left(  a_{-i}\right)   &  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{i}\right)   &  =i\dfrac{\partial}{\partial x_{i}}%
\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1;\\
\xi\left(  a_{0}\right)   &  =x_{0}.
\end{align*}
It is also clear that this $\xi$ is surjective (since all the generators
$x_{i}$, $\dfrac{\partial}{\partial x_{i}}$ and $x_{0}$ of $D\left(
x_{1},x_{2},x_{3},...\right)  \otimes\mathbb{C}\left[  x_{0}\right]  $ are in
its image).

In the following, a map $\varphi:A\rightarrow\mathbb{N}$ (where $A$ is some
set) is said to be \textit{finitely supported} if all but finitely many $a\in
A$ satisfy $\varphi\left(  a\right)  =0$. Sequences (finite, infinite, or
two-sided infinite) are considered as maps (from finite sets, $\mathbb{N}$ or
$\mathbb{Z}$, or occasionally other sets). Thus, a sequence is finitely
supported if and only if all but finitely many of its elements are zero.

If $A$ is a set, then $\mathbb{N}_{\operatorname*{fin}}^{A}$ will denote the
set of all finitely supported maps $A\rightarrow\mathbb{N}$.

By the easy part of the Poincar\'{e}-Birkhoff-Witt theorem (this is the part
which states that the increasing monomials \textit{span} the universal
enveloping algebra\footnote{The hard part says that these increasing monomials
are linearly independent.}), the family\footnote{Here, $\overset{\rightarrow
}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}}$ denotes the product
$...a_{-2}^{n_{-2}}a_{-1}^{n_{-1}}a_{0}^{n_{0}}a_{1}^{n_{1}}a_{2}^{n_{2}}...$.
(This product is infinite, but still has a value since only finitely many
$n_{i}$ are nonzero.)}%
\[
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}}\cdot
K^{m}\right)  _{\left(  ...,n_{-2},n_{-1},n_{0},n_{1},n_{2},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}},\ m\in\mathbb{N}}%
\]
is a spanning set of the vector space $U\left(  \mathcal{A}\right)  $. Hence,
the family
\[
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}%
}\right)  _{\left(  ...,n_{-2},n_{-1},n_{0},n_{1},n_{2},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}}}%
\]
is a spanning set of $U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)
$, and since this family maps to a linearly independent set under $\xi$ (this
is very easy to see), it follows that $\xi$ is injective. Thus, $\xi$ is an
isomorphism, so that Proposition \ref{prop.K-1} is proven.

\begin{definition}
\label{def.A0}Define a vector subspace $\mathcal{A}_{0}$ of $\mathcal{A}$ by
$\mathcal{A}_{0}=\left\langle a_{i}\ \mid\ i\in\mathbb{Z}\diagdown\left\{
0\right\}  \right\rangle +\left\langle K\right\rangle $.
\end{definition}

\begin{proposition}
\label{prop.A0}This subspace $\mathcal{A}_{0}$ is a Lie subalgebra of
$\mathcal{A}$, and $\mathbb{C}a_{0}$ is also a Lie subalgebra of $\mathcal{A}%
$. We have $\mathcal{A}=\mathcal{A}_{0}\oplus\mathbb{C}a_{0}$ as Lie algebras.
Hence,%
\[
U\left(  \mathcal{A}\right)  \diagup\left(  K-1\right)  =U\left(
\mathcal{A}_{0}\oplus\mathbb{C}a_{0}\right)  \diagup\left(  K-1\right)
\cong\underbrace{\left(  U\left(  \mathcal{A}_{0}\right)  \diagup\left(
K-1\right)  \right)  }_{\cong D\left(  x_{1},x_{2},x_{3},...\right)  }%
\otimes\underbrace{\mathbb{C}\left[  a_{0}\right]  }_{\cong\mathbb{C}\left[
x_{0}\right]  }%
\]
(since $K\in\mathcal{A}_{0}$). Here, the isomorphism $U\left(  \mathcal{A}%
_{0}\right)  \diagup\left(  K-1\right)  \cong D\left(  x_{1},x_{2}%
,x_{3},...\right)  $ is defined as follows: In analogy to Proposition
\ref{prop.K-1}, we have an algebra isomorphism%
\[
\widetilde{\xi}:U\left(  \mathcal{A}_{0}\right)  \diagup\left(  K-1\right)
\rightarrow D\left(  x_{1},x_{2},x_{3},...\right)
\]
given by%
\begin{align*}
\widetilde{\xi}\left(  a_{-i}\right)   &  =x_{i}\ \ \ \ \ \ \ \ \ \ \text{for
}i\geq1;\\
\widetilde{\xi}\left(  a_{i}\right)   &  =i\dfrac{\partial}{\partial x_{i}%
}\ \ \ \ \ \ \ \ \ \ \text{for }i\geq1.
\end{align*}

\end{proposition}

The proof of Proposition \ref{prop.A0} is analogous to that of Proposition
\ref{prop.K-1} (where it is not completely straightforward).

\begin{corollary}
The Lie algebra $\mathcal{A}_{0}$ has a representation $F=\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  $ which is given by
\begin{align*}
a_{-i}  &  \mapsto x_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1;\\
a_{i}  &  \mapsto i\dfrac{\partial}{\partial x_{i}}%
\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1,\\
K  &  \mapsto1
\end{align*}
(where "$a_{i}\mapsto x_{-i}$" is just shorthand for "$a_{i}\mapsto\left(
\text{multiplication by }x_{i}\right)  $"). This is called the \textit{Fock
representation}. For every $\mu\in\mathbb{C}$, we can upgrade $F$ to a
representation $F_{\mu}$ of $\mathcal{A}$ by adding the condition that
$a_{0}\mid_{F_{\mu}}=\mu\cdot\operatorname*{id}$.
\end{corollary}

Let us now define some gradings to make these infinite-dimensional spaces more manageable:

First of all, let us grade $\mathcal{A}$ by $\mathcal{A}=\bigoplus
\limits_{n\in\mathbb{Z}}\mathcal{A}_{n}$, where $\mathcal{A}_{n}=\left\langle
a_{n}\right\rangle $ for $n\neq0$, and where $\mathcal{A}_{0}=\left\langle
a_{0},K\right\rangle $. This is a grading of a Lie algebra, i. e., we have
$\left[  \mathcal{A}_{n},\mathcal{A}_{m}\right]  \subseteq\mathcal{A}_{n+m}$
for all $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$.

We also grade the polynomial algebra $F$ by setting $\deg\left(  x_{i}\right)
=-i$ for each $i$. Thus, $F=\bigoplus\limits_{n\geq0}F\left[  -n\right]  $,
where $F\left[  -n\right]  $ is the space of polynomials of degree $-n$, where
the degree is our degree defined by $\deg\left(  x_{i}\right)  =-i$ (so that,
for instance, $x_{1}^{2}+x_{2}$ is homogeneous of degree $-2$). With this
grading, $\dim\left(  F\left[  -n\right]  \right)  $ is the number $p\left(
n\right)  $ of all partitions of $n$. Hence,%
\[
\sum\limits_{n\geq0}\dim\left(  F\left[  -n\right]  \right)  q^{n}%
=\sum\limits_{n\geq0}p\left(  n\right)  q^{n}=\dfrac{1}{\left(  1-q\right)
\left(  1-q^{2}\right)  \left(  1-q^{3}\right)  \cdots}=\dfrac{1}%
{\prod\limits_{i\geq1}\left(  1-q^{i}\right)  }%
\]
in the ring of power series $\mathbb{Z}\left[  \left[  q\right]  \right]  $.

The action of $\mathcal{A}$ on $F_{\mu}$ is now graded, i. e., it maps
$\mathcal{A}_{n}\otimes F_{\mu}\left[  m\right]  $ to $F_{\mu}\left[
n+m\right]  $. This makes $F_{\mu}$ into a $\mathbb{Z}$-graded $\mathcal{A}$-module.

\begin{Convention}
It is usual (for reasons to be explained later) to grade $F_{\mu}$ somewhat
differently from $F$: namely, it is usual to shift the grading for $F_{\mu}$
by $\dfrac{\mu^{2}}{2}$, so that $\deg1=-\dfrac{\mu^{2}}{2}$ in $F_{\mu}$, and
generally $F_{\mu}\left[  z\right]  =F\left[  \dfrac{\mu^{2}}{2}+z\right]  $
(as vector spaces) for every $z\in\mathbb{C}$. Of course, with this new
grading, $F_{\mu}$ still is a graded $\mathcal{A}$-module, although this is a
grading by complex numbers rather than integers (in general). (The advantage
of this grading is that we will eventually find an operator whose eigenspace
to the eigenvalue $n$ is $F_{\mu}\left[  n\right]  =F\left[  \dfrac{\mu^{2}%
}{2}+n\right]  $ for every $n\in\mathbb{C}$.)

With this grading, the equality $\sum\limits_{n\geq0}\dim\left(  F\left[
-n\right]  \right)  q^{n}=\dfrac{1}{\prod\limits_{i\geq1}\left(
1-q^{i}\right)  }$ rewrites as $\sum\limits_{n\in\mathbb{C}}\dim\left(
F_{\mu}\left[  -n\right]  \right)  q^{n+\dfrac{\mu^{2}}{2}}=\dfrac{q^{\mu^{2}%
}}{\prod\limits_{i\geq1}\left(  1-q^{i}\right)  }$, if we allow power series
with complex exponents. We define a "power series" $\operatorname*{ch}\left(
F_{\mu}\right)  $ by%
\[
\operatorname*{ch}\left(  F_{\mu}\right)  =\sum\limits_{n\in\mathbb{C}}%
\dim\left(  F_{\mu}\left[  -n\right]  \right)  q^{n+\dfrac{\mu^{2}}{2}}%
=\dfrac{q^{\mu^{2}}}{\prod\limits_{i\geq1}\left(  1-q^{i}\right)  }.
\]

\end{Convention}

\begin{proposition}
\label{prop.F.irrep}The representation $F$ is an irreducible representation of
$\mathcal{A}_{0}$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.F.irrep}.} \textbf{1)} The
representation $F$ is generated by $1$ as a $U\left(  \mathcal{A}_{0}\right)
$-module.\footnote{This is clear due to $\xi\left(  a_{-i}\right)  =x_{i}$ for
every $i\geq1$.} In other words, $F=U\left(  \mathcal{A}_{0}\right)  \cdot1$.

\textbf{2)} If $P\in F$ and $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}%
...x_{k}^{m_{k}}$ is a monomial in $P$ of degree $\deg P$, with $\alpha\neq0$,
then $\dfrac{1}{\alpha}\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac
{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}}{m_{k}%
!}P=1$\ \ \ \ \footnote{\textit{Proof.} When we apply the differential
operator $\dfrac{1}{\alpha}\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}%
\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}%
}{m_{k}!}$ to $P$, all monomials $\beta\cdot x_{1}^{n_{1}}x_{2}^{n_{2}%
}...x_{k}^{n_{k}}$ with at least one $n_{\ell}$ being smaller than the
corresponding $m_{\ell}$ are annihilated (because if $n_{\ell}<m_{\ell}$ for
some $\ell$, then $\dfrac{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac
{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac{\partial_{x_{k}}^{m_{k}}}{m_{k}%
!}\left(  \beta\cdot x_{1}^{n_{1}}x_{2}^{n_{2}}...x_{k}^{n_{k}}\right)  =0$).
Hence, the only monomials in $P$ which survive under this operator are
monomials of the form $\beta\cdot x_{1}^{n_{1}}x_{2}^{n_{2}}...x_{k}^{n_{k}}$
with each $n_{\ell}$ being $\geq$ to the corresponding $m_{\ell}$. But since
$m_{1}+m_{2}+...+m_{k}=\deg P$ (because $\alpha\cdot x_{1}^{m_{1}}x_{2}%
^{m_{2}}...x_{k}^{m_{k}}$ is a monomial of degree $\deg P$), the only such
monomial in $P$ is $\alpha\cdot x_{1}^{m_{1}}x_{2}^{m_{2}}...x_{k}^{m_{k}}$
(because for every other monomial of the form $\beta\cdot x_{1}^{n_{1}}%
x_{2}^{n_{2}}...x_{k}^{n_{k}}$ with each $n_{\ell}$ being $\geq$ to the
corresponding $m_{\ell}$, the sum $n_{1}+n_{2}+...+n_{k}$ must be greater than
$m_{1}+m_{2}+...+m_{k}=\deg P$, and thus such a monomial cannot occur in $P$).
Hence, the only monomial in $P$ which survives is the monomial $\alpha\cdot
x_{1}^{m_{1}}x_{2}^{m_{2}}...x_{k}^{m_{k}}$. This monomial clearly gets mapped
to $1$ by the differential operator $\dfrac{1}{\alpha}\dfrac{\partial_{x_{1}%
}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}!}...\dfrac
{\partial_{x_{k}}^{m_{k}}}{m_{k}!}$. Thus, $\dfrac{1}{\alpha}\dfrac
{\partial_{x_{1}}^{m_{1}}}{m_{1}!}\dfrac{\partial_{x_{2}}^{m_{2}}}{m_{2}%
!}...\dfrac{\partial_{x_{k}}^{m_{k}}}{m_{k}!}P=1$, qed.} and thus $1\in
U\left(  \mathcal{A}_{0}\right)  \cdot P$. Combined with \textbf{1)}, this
yields that for every nonzero $P\in F$, the representation $F$ is generated by
$P$ as a $U\left(  \mathcal{A}_{0}\right)  $-module (since $F=U\left(
\mathcal{A}_{0}\right)  \cdot\underbrace{1}_{\in U\left(  \mathcal{A}%
_{0}\right)  \cdot P}\subseteq U\left(  \mathcal{A}_{0}\right)  \cdot U\left(
\mathcal{A}_{0}\right)  \cdot P=U\left(  \mathcal{A}_{0}\right)  \cdot P$).
Consequently, $F$ is irreducible. Proposition \ref{prop.F.irrep} is proven.

\begin{proposition}
\label{prop.V=F}Let $V$ be an irreducible $\mathcal{A}_{0}$-module on which
$K$ acts as $1$. Assume that for any $v\in V$, the space $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \cdot v$ is finite-dimensional, and the $a_{i}$
with $i>0$ act on it by nilpotent operators. Then, $V\cong F$ as
$\mathcal{A}_{0}$-modules.
\end{proposition}

Before we prove this, a simple lemma:

\begin{lemma}
\label{lem.V=F}Let $V$ be an $\mathcal{A}_{0}$-module. Let $u\in V$ be such
that $a_{i}u=0$ for all $i>0$, and such that $Ku=u$. Then, there exists a
homomorphism $\eta:F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that
$\eta\left(  1\right)  =u$. (This homomorphism $\eta$ is unique, although we
won't need this.)
\end{lemma}

We give two proofs of this lemma. The first one is conceptual and gives us a
glimpse into the more general theory (it proceeds by constructing an
$\mathcal{A}_{0}$-module $\operatorname*{Ind}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$, which is an example
of what we will later call a Verma highest-weight module in Definition
\ref{def.verma}). The second one is down-to-earth and proceeds by direct
construction and computation.

\textit{First proof of Lemma \ref{lem.V=F}.} Define a vector subspace
$\mathcal{A}_{0}^{+}$ of $\mathcal{A}_{0}$ by $\mathcal{A}_{0}^{+}%
=\left\langle a_{i}\ \mid\ i\text{ positive integer}\right\rangle $. It is
clear that the direct sum $\mathbb{C}K\oplus\mathcal{A}_{0}^{+}$ is
well-defined and an abelian Lie subalgebra of $\mathcal{A}_{0}$. We can make
$\mathbb{C}$ into an $\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
$-module by setting%
\begin{align*}
K\lambda &  =\lambda\ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in
\mathbb{C};\\
a_{i}\lambda &  =0\ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in
\mathbb{C}\text{ and every positive integer }i.
\end{align*}
Now, consider the $\mathcal{A}_{0}$-module $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}=U\left(  \mathcal{A}_{0}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }\mathbb{C}$. Denote the element
$1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\in
U\left(  \mathcal{A}_{0}\right)  \otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }\mathbb{C}$ of this module by $1$.

We will now show the following important property of this module:
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{For any }\mathcal{A}_{0}\text{-module }T\text{, and any }t\in T\text{
satisfying }\left(  a_{i}t=0\text{ for all }i>0\right)  \text{ and
}Kt=t\text{,}\\
\text{there exists a homomorphism }\overline{\eta}_{T,t}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow T\text{ of }\mathcal{A}_{0}\text{-modules such that
}\overline{\eta}_{T,t}\left(  1\right)  =t
\end{array}
\right)  . \label{lem.V=F.pf.A1}%
\end{equation}
Once this is proven, we will (by considering $\overline{\eta}_{F,1}$) show
that $\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}}\mathbb{C}\cong F$, so this property will translate into the
assertion of Lemma \ref{lem.V=F}.

\textit{Proof of (\ref{lem.V=F.pf.A1}).} Let $\tau:\mathbb{C}\rightarrow T$ be
the map which sends every $\lambda\in\mathbb{C}$ to $\lambda t\in T$. Then,
$\tau$ is $\mathbb{C}$-linear and satisfies%
\[
\tau\underbrace{\left(  K\lambda\right)  }_{=\lambda}=\tau\left(
\lambda\right)  =\lambda\underbrace{t}_{=Kt}=\lambda\cdot Kt=K\cdot
\underbrace{\lambda t}_{=\tau\left(  \lambda\right)  }=K\cdot\tau\left(
\lambda\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in\mathbb{C}%
\]
and%
\begin{align*}
\tau\underbrace{\left(  a_{i}\lambda\right)  }_{=0}  &  =\tau\left(  0\right)
=0=\lambda\cdot\underbrace{0}_{=a_{i}t}=\lambda\cdot a_{i}t=a_{i}%
\cdot\underbrace{\lambda t}_{=\tau\left(  \lambda\right)  }=a_{i}\tau\left(
\lambda\right) \\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\lambda\in\mathbb{C}\text{ and every
positive integer }i\text{.}%
\end{align*}
Thus, $\tau$ is a $\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
$-module map. In other words, $\tau\in\operatorname*{Hom}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}\left(  \mathbb{C},\operatorname*{Res}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}T\right)  $.

By Frobenius reciprocity, we have%
\[
\operatorname*{Hom}\nolimits_{\mathcal{A}_{0}}\left(  \operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C},T\right)  \cong\operatorname*{Hom}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}\left(  \mathbb{C},\operatorname*{Res}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}T\right)  .
\]
The preimage of $\tau\in\operatorname*{Hom}\nolimits_{\mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}}\left(  \mathbb{C},\operatorname*{Res}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}T\right)  $
under this isomorphism is an $\mathcal{A}_{0}$-module map $\overline{\eta
}_{T,t}:\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}\rightarrow T$ such that
\begin{align*}
\overline{\eta}_{T,t}\underbrace{\left(  1\right)  }_{=1\otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1}  &  =\overline{\eta}%
_{T,t}\left(  1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
}1\right)  =1\underbrace{\tau\left(  1\right)  }_{=1t=t}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the proof of Frobenius reciprocity}%
\right) \\
&  =1t=t.
\end{align*}
Hence, there exists a homomorphism $\overline{\eta}_{T,t}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow T$ of $\mathcal{A}_{0}$-modules such that $\overline
{\eta}_{T,t}\left(  1\right)  =t$. This proves (\ref{lem.V=F.pf.A1}).

It is easy to see that the element $1\in F$ satisfies $\left(  a_{i}1=0\text{
for all }i>0\right)  $ and $K1=1$. Thus, (\ref{lem.V=F.pf.A1}) (applied to
$T=F$ and $t=1$) yields that there exists a homomorphism $\overline{\eta
}_{F,1}:\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}\rightarrow F$ of $\mathcal{A}_{0}$-modules such
that $\overline{\eta}_{F,1}\left(  1\right)  =1$. This homomorphism
$\overline{\eta}_{F,1}$ is clearly surjective, since
\begin{align*}
F  &  =U\left(  \mathcal{A}_{0}\right)  \cdot\underbrace{1}_{=\overline{\eta
}_{F,1}\left(  1\right)  }\ \ \ \ \ \ \ \ \ \ \left(  \text{as proven in the
proof of Proposition \ref{prop.F.irrep}}\right) \\
&  =U\left(  \mathcal{A}_{0}\right)  \cdot\overline{\eta}_{F,1}\left(
1\right)  =\overline{\eta}_{F,1}\left(  U\left(  \mathcal{A}_{0}\right)
\cdot1\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\overline{\eta}%
_{F,1}\text{ is an }\mathcal{A}_{0}\text{-module map}\right) \\
&  \subseteq\operatorname{Im}\overline{\eta}_{F,1}.
\end{align*}


Now we will prove that this homomorphism $\overline{\eta}_{F,1}$ is injective.

In the following, a map $\varphi:A\rightarrow\mathbb{N}$ (where $A$ is any
set) is said to be \textit{finitely supported} if all but finitely many $a\in
A$ satisfy $\varphi\left(  a\right)  =0$. Sequences (finite, infinite, or
two-sided infinite) are considered as maps (from finite sets, $\mathbb{N}$ or
$\mathbb{Z}$, or occasionally other sets). Thus, a sequence is finitely
supported if and only if all but finitely many of its elements are zero.

If $A$ is a set, then $\mathbb{N}_{\operatorname*{fin}}^{A}$ will denote the
set of all finitely supported maps $A\rightarrow\mathbb{N}$.

By the easy part of the Poincar\'{e}-Birkhoff-Witt theorem (this is the part
which states that the increasing monomials \textit{span} the universal
enveloping algebra), the family\footnote{Here, $\overset{\rightarrow
}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}$
denotes the product $...a_{-2}^{n_{-2}}a_{-1}^{n_{-1}}a_{1}^{n_{1}}%
a_{2}^{n_{2}}...$. (This product is infinite, but still has a value since only
finitely many $n_{i}$ are nonzero.)}%
\[
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\cdot K^{m}\right)  _{\left(  ...,n_{-2}%
,n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  },\ m\in\mathbb{N}}%
\]
is a spanning set of the vector space $U\left(  \mathcal{A}_{0}\right)  $.

Hence, the family%
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\cdot K^{m}\right)  \otimes
_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  },\ m\in\mathbb{N}}%
\]
is a spanning set of the vector space $U\left(  \mathcal{A}_{0}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }%
\mathbb{C}=\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}$.

Let us first notice that this family is redundant: Each of its elements is
contained in the smaller family%
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  }}.
\]
\footnote{This is because any sequence $\left(  ...,n_{-2},n_{-1},n_{1}%
,n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}%
\diagdown\left\{  0\right\}  }$ and any $m\in\mathbb{N}$ satisfy%
\begin{align*}
&  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\cdot K^{m}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown
\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }\underbrace{\left(  K^{m}1\right)
}_{\substack{=1\\\text{(by repeated application of }K1=1\text{)}%
}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }K^{m}\in U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  \right) \\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown
\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1.
\end{align*}
} Hence, this smaller family is also a spanning set of the vector space
$\operatorname*{Ind}\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}%
}^{\mathcal{A}_{0}}\mathbb{C}$.

This smaller family is still redundant: Every of its elements corresponding to
a sequence $\left(  ...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{  0\right\}  }$
satisfying $n_{1}+n_{2}+n_{3}+...>0$ is zero\footnote{\textit{Proof.} Let
$\left(  ...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{  0\right\}  }$ be a
sequence satisfying $n_{1}+n_{2}+n_{3}+...>0$. Then, the sequence $\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  $ is finitely supported (as it is an
element of $\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{
0\right\}  }$), so that only finitely many $n_{i}$ are nonzero.
\par
There exists some positive integer $\ell$ satisfying $n_{\ell}>0$ (since
$n_{1}+n_{2}+n_{3}+...>0$). Let $j$ be the greatest such $\ell$ (this is
well-defined, since only finitely many $n_{i}$ are nonzero).
\par
Since $j$ is the greatest positive integer $\ell$ satisfying $n_{\ell}>0$, it
is clear that $j$ is the greatest integer $\ell$ satisfying $n_{\ell}>0$. In
other words, $a_{j}^{n_{j}}$ is the rightmost factor in the product
$\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}}}a_{i}^{n_{i}}$ which is
not equal to $1$. Thus,%
\[
\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{  0\right\}
}}a_{i}^{n_{i}}=\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  \diagdown\left\{  j\right\}  }}a_{i}^{n_{i}}%
\cdot\underbrace{a_{j}^{n_{j}}}_{\substack{=a_{j}^{n_{j}-1}a_{j}\\\text{(since
}n_{j}>0\text{)}}}=\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  \diagdown\left\{  j\right\}  }}a_{i}^{n_{i}}\cdot
a_{j}^{n_{j}-1}a_{j},
\]
so that%
\begin{align*}
\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }1  &  =\left(  \overset{\rightarrow
}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{  0\right\}  \diagdown\left\{
j\right\}  }}a_{i}^{n_{i}}\cdot a_{j}^{n_{j}-1}a_{j}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\\
&  =\overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  \diagdown\left\{  j\right\}  }}a_{i}^{n_{i}}\cdot a_{j}^{n_{j}%
-1}\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)
}\underbrace{a_{j}1}_{\substack{=0\\\text{(since }j>0\text{, so that}%
\\a_{j}1=j\dfrac{\partial}{\partial x_{j}}1=0\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }a_{j}\in U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  \right) \\
&  =0.
\end{align*}
We have thus proven that every sequence $\left(  ...,n_{-2},n_{-1},n_{1}%
,n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}%
\diagdown\left\{  0\right\}  }$ satisfying $n_{1}+n_{2}+n_{3}+...>0$ satisfies
$\left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}\diagdown\left\{
0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }1=0$, qed.}, and zero elements in a spanning set
are automatically redundant. Hence, we can replace this smaller family by the
even smaller family%
\begin{align*}
&  \left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  }\text{; we do \textit{not} have
}n_{1}+n_{2}+n_{3}+...>0}\\
&  =\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(
\mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(
...,n_{-2},n_{-1},n_{1},n_{2},...\right)  \in\mathbb{N}_{\operatorname*{fin}%
}^{\mathbb{Z}\diagdown\left\{  0\right\}  }\text{; }n_{1}=n_{2}=n_{3}=...=0}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the condition }\left(  \text{we do \textit{not} have }n_{1}%
+n_{2}+n_{3}+...>0\right) \\
\text{is equivalent to the condition }\left(  n_{1}=n_{2}=n_{3}=...=0\right)
\\
\text{(because }n_{i}\in\mathbb{N}\text{ for all }i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  \text{)}%
\end{array}
\right)  ,
\end{align*}
and we still have a spanning set of the vector space $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$.

Clearly, sequences $\left(  ...,n_{-2},n_{-1},n_{1},n_{2},...\right)
\in\mathbb{N}_{\operatorname*{fin}}^{\mathbb{Z}\diagdown\left\{  0\right\}  }$
satisfying $n_{1}=n_{2}=n_{3}=...=0$ are in 1-to-1 correspondence with
sequences $\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$. Hence, we can
reindex the above family as follows:
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}.
\]
So we have proven that the family%
\[
\left(  \left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \otimes_{U\left(  \mathbb{C}%
K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}%
\]
is a spanning set of the vector space $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$.
But the map $\overline{\eta}_{F,1}$ sends this family to%
\begin{align*}
&  \left(  \overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow
}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
\right)  _{\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }}\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}x_{-i}^{n_{i}}\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}%
\end{align*}
\footnote{\textit{Proof.} Let $\left(  ...,n_{-2},n_{-1}\right)  \in
\mathbb{N}_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$ be
arbitrary. Then,%
\begin{align*}
&  \overline{\eta}_{F,1}\left(  \underbrace{\left(  \overset{\rightarrow
}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1}_{=\left(
\overset{\rightarrow}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}%
a_{i}^{n_{i}}\right)  \left(  1\otimes_{U\left(  \mathbb{C}K\oplus
\mathcal{A}_{0}^{+}\right)  }1\right)  }\right) \\
&  =\overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow}{\prod
\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \left(
1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
\right) \\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \overline{\eta}_{F,1}%
\underbrace{\left(  1\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}%
^{+}\right)  }1\right)  }_{=1}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\overline{\eta}_{F,1}\text{ is an }\mathcal{A}_{0}\text{-module map}\right)
\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  \underbrace{\overline{\eta
}_{F,1}\left(  1\right)  }_{=1}=\left(  \overset{\rightarrow}{\prod
\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)  1=\left(
\overset{\rightarrow}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }%
}x_{-i}^{n_{i}}\right)  1\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{because each }a_{i}\text{ with negative
}i\text{ acts on }F\text{ by multiplication with }x_{-i}\right) \\
&  =\overset{\rightarrow}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }%
}x_{-i}^{n_{i}}=\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }%
x_{-i}^{n_{i}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }F\text{ is
commutative}\right)  .
\end{align*}
Now forget that we fixed $\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$. We thus have shown
that every $\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }$ satisfies
$\overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow}{\prod
\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
=\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }x_{-i}^{n_{i}}$. Thus,%
\begin{align*}
&  \left(  \overline{\eta}_{F,1}\left(  \left(  \overset{\rightarrow
}{\prod\limits_{i\in\left\{  ...,-3,-2,-1\right\}  }}a_{i}^{n_{i}}\right)
\otimes_{U\left(  \mathbb{C}K\oplus\mathcal{A}_{0}^{+}\right)  }1\right)
\right)  _{\left(  ...,n_{-2},n_{-1}\right)  \in\mathbb{N}%
_{\operatorname*{fin}}^{\left\{  ...,-3,-2,-1\right\}  }}\\
&  =\left(  \overset{\rightarrow}{\prod\limits_{i\in\left\{
...,-3,-2,-1\right\}  }}x_{-i}^{n_{i}}\right)  _{\left(  ...,n_{-2}%
,n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }},
\end{align*}
qed.}. Since the family $\left(  \overset{\rightarrow}{\prod\limits_{i\in
\left\{  ...,-3,-2,-1\right\}  }}x_{-i}^{n_{i}}\right)  _{\left(
...,n_{-2},n_{-1}\right)  \in\mathbb{N}_{\operatorname*{fin}}^{\left\{
...,-3,-2,-1\right\}  }}$ is a basis of the vector space $F$ (in fact, this
family consists of all monomials of the polynomial ring $\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  =F$), we thus conclude that $\overline{\eta
}_{F,1}$ sends a spanning family of the vector space $\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}\mathbb{C}$
to a basis of the vector space $F$. Thus, $\overline{\eta}_{F,1}$ must be
injective\footnote{Here we are using the following trivial fact from linear
algebra: If a linear map $\varphi:V\rightarrow W$ sends a spanning family of
the vector space $V$ to a basis of the vector space $W$ (as families, not just
as sets), then this map $\varphi$ must be injective.}.

Altogether, we now know that $\overline{\eta}_{F,1}$ is a surjective and
injective $\mathcal{A}_{0}$-module map. Thus, $\overline{\eta}_{F,1}$ is an
isomorphism of $\mathcal{A}_{0}$-modules.

Now, apply (\ref{lem.V=F.pf.A1}) to $T=V$ and $t=u$. This yields that there
exists a homomorphism $\overline{\eta}_{V,u}:\operatorname*{Ind}%
\nolimits_{\mathbb{C}K\oplus\mathcal{A}_{0}^{+}}^{\mathcal{A}_{0}}%
\mathbb{C}\rightarrow V$ of $\mathcal{A}_{0}$-modules such that $\overline
{\eta}_{V,u}\left(  1\right)  =u$.

Now, the composition $\overline{\eta}_{V,u}\circ\overline{\eta}_{F,1}^{-1}$ is
a homomorphism $F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that
\[
\left(  \overline{\eta}_{V,u}\circ\overline{\eta}_{F,1}^{-1}\right)  \left(
1\right)  =\overline{\eta}_{V,u}\underbrace{\left(  \overline{\eta}_{F,1}%
^{-1}\left(  1\right)  \right)  }_{\substack{=1\\\text{(since }\overline{\eta
}_{F,1}\left(  1\right)  =1\text{)}}}=\overline{\eta}_{V,u}\left(  1\right)
=u.
\]
Thus, there exists a homomorphism $\eta:F\rightarrow V$ of $\mathcal{A}_{0}%
$-modules such that $\eta\left(  1\right)  =u$ (namely, $\eta=\overline{\eta
}_{V,u}\circ\overline{\eta}_{F,1}^{-1}$). This proves Lemma \ref{lem.V=F}.

\textit{Second proof of Lemma \ref{lem.V=F}.} Let $\eta$ be the map
$F\rightarrow V$ which sends every polynomial $P\in F=\mathbb{C}\left[
x_{1},x_{2},x_{3},...\right]  $ to $P\left(  a_{-1},a_{-2},a_{-3},...\right)
\cdot u\in V$.\ \ \ \ \footnote{Note that the term $P\left(  a_{-1}%
,a_{-2},a_{-3},...\right)  $ denotes the evaluation of the polynomial $P$ at
$\left(  x_{1},x_{2},x_{3},...\right)  =\left(  a_{-1},a_{-2},a_{-3}%
,...\right)  $. This evaluation is a well-defined element of $U\left(
\mathcal{A}_{0}\right)  $, since the elements $a_{-1}$, $a_{-2}$, $a_{-3}$,
$...$ of $U\left(  \mathcal{A}_{0}\right)  $ commute.} This map $\eta$ is
clearly $\mathbb{C}$-linear, and satisfies $\eta\left(  F\right)  \subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot u$. In order to prove that $\eta$ is an
$\mathcal{A}_{0}$-module homomorphism, we must prove that
\begin{equation}
\eta\left(  a_{i}P\right)  =a_{i}\eta\left(  P\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }i\in\mathbb{Z}\diagdown\left\{
0\right\}  \text{ and }P\in F \label{lem.V=F.pf.1}%
\end{equation}
and that%
\begin{equation}
\eta\left(  KP\right)  =K\eta\left(  P\right)  \ \ \ \ \ \ \ \ \ \ \text{for
every }P\in F. \label{lem.V=F.pf.2}%
\end{equation}


First we show that%
\begin{equation}
Kv=v\ \ \ \ \ \ \ \ \ \ \text{for every }v\in U\left(  \mathcal{A}_{0}\right)
\cdot u. \label{lem.V=F.pf.3}%
\end{equation}


\textit{Proof of (\ref{lem.V=F.pf.3}).} Since $K$ lies in the center of the
Lie algebra $\mathcal{A}_{0}$, it is clear that $K$ lies in the center of the
universal enveloping algebra $U\left(  \mathcal{A}_{0}\right)  $. Thus,
$Kx=xK$ for every $x\in U\left(  \mathcal{A}_{0}\right)  $.

Now let $v\in U\left(  \mathcal{A}_{0}\right)  \cdot u$. Then, there exists
some $x\in U\left(  \mathcal{A}_{0}\right)  $ such that $v=xu$. Thus,
$Kv=Kxu=x\underbrace{Ku}_{=u}=xu=v$. This proves (\ref{lem.V=F.pf.3}).

\textit{Proof of (\ref{lem.V=F.pf.2}).} Since $K$ acts as the identity on $F$,
we have $KP=P$ for every $P\in F$. Thus, for every $P\in F$, we have%
\[
\eta\left(  KP\right)  =\eta\left(  P\right)  =K\eta\left(  P\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since (\ref{lem.V=F.pf.3}) (applied to }v=\eta\left(  P\right)  \text{)
yields }K\eta\left(  P\right)  =\eta\left(  P\right) \\
\text{(because }\eta\left(  P\right)  \in\eta\left(  F\right)  \subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot u\text{)}%
\end{array}
\right)  .
\]
This proves (\ref{lem.V=F.pf.2}).

\textit{Proof of (\ref{lem.V=F.pf.1}).} Let $i\in\mathbb{Z}\diagdown\left\{
0\right\}  $. If $i<0$, then (\ref{lem.V=F.pf.1}) is pretty much obvious
(because in this case, $a_{i}$ acts as $x_{-i}$ on $F$, so that $a_{i}%
P=x_{-i}P$ and thus%
\[
\eta\left(  a_{i}P\right)  =\eta\left(  x_{-i}P\right)  =\left(
x_{-i}P\right)  \left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u=a_{i}%
\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u}_{=\eta\left(
P\right)  }=a_{i}\eta\left(  P\right)
\]
for every $P\in F$). Hence, from now on, we can WLOG assume that $i$ is not
$<0$. Assume this. Then, $i\geq0$, so that $i>0$ (since $i\in\mathbb{Z}%
\diagdown\left\{  0\right\}  $).

In order to prove the equality (\ref{lem.V=F.pf.1}) for all $P\in F$, it is
enough to prove it for the case when $P$ is a monomial of the form
$x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{m}}$ for some $m\in\mathbb{N}$ and some
$\left(  \ell_{1},\ell_{2},...,\ell_{m}\right)  \in\left\{  1,2,3,...\right\}
^{m}$.\ \ \ \ \footnote{This is because such monomials generate $F$ as a
$\mathbb{C}$-vector space, and because the equality (\ref{lem.V=F.pf.1}) is
linear in $P$.} In other words, in order to prove the equality
(\ref{lem.V=F.pf.1}), it is enough to prove that%
\begin{equation}
\eta\left(  a_{i}\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{m}}\right)
\right)  =a_{i}\eta\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{m}}\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }m\in\mathbb{N}\text{ and every }\left(
\ell_{1},\ell_{2},...,\ell_{m}\right)  \in\left\{  1,2,3,...\right\}  ^{m}.
\label{lem.V=F.pf.4}%
\end{equation}


Thus, let us now prove (\ref{lem.V=F.pf.4}). In fact, we are going to prove
(\ref{lem.V=F.pf.4}) by induction over $m$. The induction base is very easy
(using $a_{i}1=i\dfrac{\partial}{\partial x_{i}}1=0$ and $a_{i}u=0$) and thus
left to the reader. For the induction step, fix some positive $M\in\mathbb{N}%
$, and assume that (\ref{lem.V=F.pf.4}) is already proven for $m=M-1$. Our
task is now to prove (\ref{lem.V=F.pf.4}) for $m=M$.

So let $\left(  \ell_{1},\ell_{2},...,\ell_{M}\right)  \in\left\{
1,2,3,...\right\}  ^{M}$ be arbitrary. Denote by $Q$ the polynomial
$x_{\ell_{2}}x_{\ell_{3}}...x_{\ell_{M}}$. Then, $x_{\ell_{1}}Q=x_{\ell_{1}%
}x_{\ell_{2}}x_{\ell_{3}}...x_{\ell_{M}}=x_{\ell_{1}}x_{\ell_{2}}%
...x_{\ell_{M}}$.

Since (\ref{lem.V=F.pf.4}) is already proven for $m=M-1$, we can apply
(\ref{lem.V=F.pf.4}) to $M-1$ and $\left(  \ell_{2},\ell_{3},...,\ell
_{M}\right)  $ instead of $m$ and $\left(  \ell_{1},\ell_{2},...,\ell
_{m}\right)  $. We obtain $\eta\left(  a_{i}\left(  x_{\ell_{2}}x_{\ell_{3}%
}...x_{\ell_{M}}\right)  \right)  =a_{i}\eta$ $\left(  x_{\ell_{2}}x_{\ell
_{3}}...x_{\ell_{M}}\right)  $. Since $x_{\ell_{2}}x_{\ell_{3}}...x_{\ell_{M}%
}=Q$, this rewrites as $\eta\left(  a_{i}Q\right)  =a_{i}\eta\left(  Q\right)
$.

Since any $x,y\in U\left(  \mathcal{A}_{0}\right)  $ satisfy $xy=yx+\left[
x,y\right]  $ (by the definition of $U\left(  \mathcal{A}_{0}\right)  $), we
have%
\[
a_{i}a_{-\ell_{1}}=a_{-\ell_{1}}a_{i}+\underbrace{\left[  a_{i},a_{-\ell_{1}%
}\right]  }_{=i\delta_{i,-\left(  -\ell_{1}\right)  }K}=a_{-\ell_{1}}%
a_{i}+i\underbrace{\delta_{i,-\left(  -\ell_{1}\right)  }}_{=\delta
_{i,\ell_{1}}}K=a_{-\ell_{1}}a_{i}+i\delta_{i,\ell_{1}}K.
\]


On the other hand, by the definition of $\eta$, every $P\in F$ satisfies the
two equalities $\eta\left(  P\right)  =P\left(  a_{-1},a_{-2},a_{-3}%
,...\right)  \cdot u$ and%
\begin{align}
\eta\left(  x_{\ell_{1}}P\right)   &  =\underbrace{\left(  x_{\ell_{1}%
}P\right)  \left(  a_{-1},a_{-2},a_{-3},...\right)  }_{=a_{-\ell_{1}}\cdot
P\left(  a_{-1},a_{-2},a_{-3},...\right)  }\cdot u=a_{-\ell_{1}}%
\cdot\underbrace{P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot u}%
_{=\eta\left(  P\right)  }\nonumber\\
&  =a_{-\ell_{1}}\cdot\eta\left(  P\right)  . \label{lem.V=F.pf.5}%
\end{align}


Since $a_{i}$ acts on $F$ as $i\dfrac{\partial}{\partial x_{i}}$, we have
$a_{i}\left(  x_{\ell_{1}}Q\right)  =i\dfrac{\partial}{\partial x_{i}}\left(
x_{\ell_{1}}Q\right)  $ and $a_{i}Q=i\dfrac{\partial}{\partial x_{i}}Q$. Now,%
\begin{align*}
a_{i}\left(  \underbrace{x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}}}%
_{=x_{\ell_{1}}Q}\right)   &  =a_{i}\left(  x_{\ell_{1}}Q\right)
=i\dfrac{\partial}{\partial x_{i}}\left(  x_{\ell_{1}}Q\right)  =i\left(
\left(  \dfrac{\partial}{\partial x_{i}}x_{\ell_{1}}\right)  Q+x_{\ell_{1}%
}\left(  \dfrac{\partial}{\partial x_{i}}Q\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the Leibniz rule}\right) \\
&  =i\underbrace{\left(  \dfrac{\partial}{\partial x_{i}}x_{\ell_{1}}\right)
}_{=\delta_{i,\ell_{1}}}Q+x_{\ell_{1}}\cdot\underbrace{i\dfrac{\partial
}{\partial x_{i}}Q}_{=a_{i}Q}=i\delta_{i,\ell_{1}}Q+x_{\ell_{1}}\cdot
a_{i}Q=x_{\ell_{1}}\cdot a_{i}Q+i\delta_{i,\ell_{1}}Q,
\end{align*}
so that%
\begin{align*}
\eta\left(  a_{i}\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}}\right)
\right)   &  =\eta\left(  x_{\ell_{1}}\cdot a_{i}Q+i\delta_{i,\ell_{1}%
}Q\right)  =\underbrace{\eta\left(  x_{\ell_{1}}\cdot a_{i}Q\right)
}_{\substack{=a_{-\ell_{1}}\cdot\eta\left(  a_{i}Q\right)  \\\text{(by
(\ref{lem.V=F.pf.5}), applied to }P=a_{i}Q\text{)}}}+i\delta_{i,\ell_{1}}%
\eta\left(  Q\right) \\
&  =a_{-\ell_{1}}\cdot\underbrace{\eta\left(  a_{i}Q\right)  }_{=a_{i}%
\eta\left(  Q\right)  }+i\delta_{i,\ell_{1}}\eta\left(  Q\right)
=a_{-\ell_{1}}\cdot a_{i}\eta\left(  Q\right)  +i\delta_{i,\ell_{1}}%
\eta\left(  Q\right)  .
\end{align*}
Compared to%
\begin{align*}
a_{i}\eta\left(  \underbrace{x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}}%
}_{=x_{\ell_{1}}Q}\right)   &  =a_{i}\underbrace{\eta\left(  x_{\ell_{1}%
}Q\right)  }_{\substack{=a_{-\ell_{1}}\cdot\eta\left(  Q\right)  \\\text{(by
(\ref{lem.V=F.pf.5}), applied to }P=Q\text{)}}}=\underbrace{a_{i}a_{-\ell_{1}%
}}_{=a_{-\ell_{1}}a_{i}+i\delta_{i,\ell_{1}}K}\cdot\eta\left(  Q\right)
=\left(  a_{-\ell_{1}}a_{i}+i\delta_{i,\ell_{1}}K\right)  \cdot\eta\left(
Q\right) \\
&  =a_{-\ell_{1}}\cdot a_{i}\eta\left(  Q\right)  +i\delta_{i,\ell_{1}%
}\underbrace{K\eta\left(  Q\right)  }_{\substack{=\eta\left(  Q\right)
\\\text{(by (\ref{lem.V=F.pf.3}), applied to }v=\eta\left(  Q\right)
\\\text{(since }\eta\left(  Q\right)  \in\eta\left(  F\right)  \subseteq
U\left(  \mathcal{A}_{0}\right)  \cdot u\text{))}}}\\
&  =a_{-\ell_{1}}\cdot a_{i}\eta\left(  Q\right)  +i\delta_{i,\ell_{1}}%
\eta\left(  Q\right)  ,
\end{align*}
this yields $\eta\left(  a_{i}\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}%
}\right)  \right)  =a_{i}\eta\left(  x_{\ell_{1}}x_{\ell_{2}}...x_{\ell_{M}%
}\right)  $. Since we have proven this for every $\left(  \ell_{1},\ell
_{2},...,\ell_{M}\right)  \in\left\{  1,2,3,...\right\}  ^{M}$, we have thus
proven (\ref{lem.V=F.pf.4}) for $m=M$. This completes the induction step, and
thus the induction proof of (\ref{lem.V=F.pf.4}) is complete. As we have seen
above, this proves (\ref{lem.V=F.pf.1}).

From (\ref{lem.V=F.pf.1}) and (\ref{lem.V=F.pf.2}), it is clear that $\eta$ is
$\mathcal{A}_{0}$-linear (since $\mathcal{A}_{0}$ is spanned by the $a_{i}$
for $i\in\mathbb{Z}\diagdown\left\{  0\right\}  $ and $K$). Since $\eta\left(
1\right)  =u$ is obvious, this proves Lemma \ref{lem.V=F}.

\textit{Proof of Proposition \ref{prop.V=F}.} Pick some nonzero vector $v\in
V$. Let $W=\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \cdot v$. Then, by
the condition, we have $\dim W<\infty$, and $a_{i}:W\rightarrow W$ are
commuting nilpotent operators\footnote{Of course, when we write $a_{i}%
:W\rightarrow W$, we don't mean the elements $a_{i}$ of $\mathcal{A}_{0}$
themselves, but their actions on $W$.}. Hence, $\bigcap\limits_{i\geq
1}\operatorname*{Ker}a_{i}\neq0\ \ \ \ $\footnote{Here, we are using the
following linear-algebraic fact:
\par
If $T$ is a nonzero finite-dimensional vector space over an algebraically
closed field, and if $b_{1}$, $b_{2}$, $b_{3}$, $...$ are commuting linear
maps $T\rightarrow T$, then there exists a nonzero common eigenvector of
$b_{1}$, $b_{2}$, $b_{3}$, $...$. If $b_{1}$, $b_{2}$, $b_{3}$, $...$ are
nilpotent, this yields $\bigcap\limits_{i\geq1}\operatorname*{Ker}b_{i}\neq0$
(since any eigenvector of a nilpotent map must lie in its kernel).}. Hence,
there exists some nonzero $u\in\bigcap\limits_{i\geq1}\operatorname*{Ker}%
a_{i}$. Pick such a $u$. Then, $a_{i}u=0$ for all $i>0$, and $Ku=u$ (since $K$
acts as $1$ on $V$). Thus, there exists a homomorphism $\eta:F\rightarrow V$
of $\mathcal{A}_{0}$-modules such that $\eta\left(  1\right)  =u$ (by Lemma
\ref{lem.V=F}). Since both $F$ and $V$ are irreducible and $\eta\neq0$, this
yields that $\eta$ is an isomorphism. This proves Proposition \ref{prop.V=F}.

\begin{proposition}
\label{prop.V=F(X)U}Let $V$ be any $\mathcal{A}_{0}$-module having a locally
nilpotent action of $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $. (Here,
we say that the $\mathcal{A}_{0}$-module $V$ has a \textit{locally nilpotent
action of$\mathbb{\ }$}$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ if
for any $v\in V$, the space $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]
\cdot v$ is finite-dimensional, and the $a_{i}$ with $i>0$ act on it by
nilpotent operators.) Assume that $K$ acts as $1$ on $V$. Assume that for
every $v\in V$, there exists some $N\in\mathbb{N}$ such that for every $n\geq
N$, we have $a_{n}v=0$. Then, $V\cong F\otimes U$ as $\mathcal{A}_{0}$-modules
for some vector space $U$. (The vector space $U$ is not supposed to carry any
$\mathcal{A}_{0}$-module structure.)
\end{proposition}

\begin{remark}
From Proposition \ref{prop.V=F(X)U}, we cannot remove the condition that for
every $v\in V$, there exists some $N\in\mathbb{N}$ such that for every $n\geq
N$, we have $a_{n}v=0$. In fact, here is a counterexample of how Proposition
\ref{prop.V=F(X)U} can fail without this condition:

Let $V$ be the representation $\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]
\left[  y\right]  \diagup\left(  y^{2}\right)  $ of $\mathcal{A}_{0}$ given
by
\begin{align*}
a_{-i}  &  \mapsto x_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1;\\
a_{i}  &  \mapsto i\dfrac{\partial}{\partial x_{i}}%
+y\ \ \ \ \ \ \ \ \ \ \text{for every }i\geq1,\\
K  &  \mapsto1
\end{align*}
(where we are being sloppy and abbreviating the residue class $\overline{y}%
\in\mathbb{C}\left[  x_{1},x_{2},x_{3},...\right]  \left[  y\right]
\diagup\left(  y^{2}\right)  $ by $y$, and similarly all other residue
classes). We have an exact sequence%
\[%
%TCIMACRO{\TeXButton{x}{\xymatrix{
%0 \ar[r] & F \ar[r]^i & V \ar[r]^{\pi} & F \ar[r] & 0
%}}}%
%BeginExpansion
\xymatrix{
0 \ar[r] & F \ar[r]^i & V \ar[r]^{\pi} & F \ar[r] & 0
}%
%EndExpansion
\]
of $\mathcal{A}_{0}$-modules, where the map $i:F\rightarrow V$ is given by%
\[
i\left(  P\right)  =yP\ \ \ \ \ \ \ \ \ \ \text{for every }p\in F=\mathbb{C}%
\left[  x_{1},x_{2},x_{3},...\right]  ,
\]
and the map $\pi:V\rightarrow F$ is the canonical projection $V\rightarrow
V\diagup\left(  y\right)  \cong F$. Thus, $V$ is an extension of $F$ by $F$.
It is easily seen that $V$ has a locally nilpotent action of$\ \mathbb{C}%
\left[  a_{1},a_{2},a_{3},...\right]  $. But $V$ is not isomorphic to
$F\otimes U$ as $\mathcal{A}_{0}$-modules for any vector space $U$, since
there is a vector $v\in V$ satisfying $V=U\left(  \mathcal{A}_{0}\right)
\cdot v$ (for example, $v=1$), whereas there is no vector $v\in F\otimes U$
satisfying $F\otimes U=U\left(  \mathcal{A}_{0}\right)  \cdot v$ if $\dim
U>1$, and the case $\dim U\leq1$ is easily ruled out (in this case, $\dim U$
would have to be $1$, so that $U$ would be $\cong F$ and thus irreducible, and
thus the homomorphisms $i$ and $\pi$ would have to be isomorphisms, which is absurd).
\end{remark}

\textit{Proof of Proposition \ref{prop.V=F(X)U}.} Let $v\in V$ be arbitrary.
Let $I_{v}\subseteq\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ be the
annihilator of $v$. Then, the canonical $\mathbb{C}$-algebra map
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \rightarrow
\operatorname*{End}\left(  \mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]
\cdot v\right)  $ (this map comes from the action of the $\mathbb{C}$-algebra
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ on $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \cdot v$) gives rise to an \textit{injective}
map $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}%
\rightarrow\operatorname*{End}\left(  \mathbb{C}\left[  a_{1},a_{2}%
,a_{3},...\right]  \cdot v\right)  $. Since this map is injective, we have
$\dim\left(  \mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup
I_{v}\right)  \leq\dim\left(  \operatorname*{End}\left(  \mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \cdot v\right)  \right)  <\infty$ (since
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \cdot v$ is
finite-dimensional). In other words, the vector space $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$ is finite-dimensional.

Let $W$ be the $\mathcal{A}_{0}$-submodule of $V$ generated by $v$. In other
words, let $W=U\left(  \mathcal{A}_{0}\right)  \cdot v$. Then, $W$ is a
quotient of $U\left(  \mathcal{A}_{0}\right)  $ (as an $\mathcal{A}_{0}%
$-module). Since $K$ acts as $1$ on $W$, it follows that $W$ is a quotient of
$U\left(  \mathcal{A}_{0}\right)  \diagup\left(  K-1\right)  \cong D\left(
x_{1},x_{2},x_{3},...\right)  $. Since $I_{v}$ annihilates $v$, it follows
that $W$ is a quotient of $D\left(  x_{1},x_{2},...\right)  \diagup\left(
D\left(  x_{1},x_{2},...\right)  I_{v}\right)  $. Let us denote the
$\mathcal{A}_{0}$-module $D\left(  x_{1},x_{2},...\right)  \diagup\left(
D\left(  x_{1},x_{2},...\right)  I_{v}\right)  $ by $\widetilde{W}$.

We now will prove that $\widetilde{W}$ is a finite-length $\mathcal{A}_{0}%
$-module with all composition factors isomorphic to $F$.\ \ \ \ \footnote{We
can even prove that there are exactly $\dim\left(  \mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  \diagup I_{v}\right)  $ composition factors.}

Let $\mathfrak{i}$ be the ideal $\left(  a_{1},a_{2},a_{3},...\right)  $ of
the commutative algebra $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $.

Since $I_{v}$ is an ideal of the commutative algebra $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  $, the quotient $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  \diagup I_{v}$ is an algebra. For every
$q\in\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $, let $\overline{q}$ be
the projection of $q$ onto the quotient algebra $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  \diagup I_{v}$. Let also $\overline{\mathfrak{i}}$ be
the projection of the ideal $\mathfrak{i}$ onto the quotient algebra
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$. Clearly,
$\overline{\mathfrak{i}}=\left(  \overline{a_{1}},\overline{a_{2}}%
,\overline{a_{3}},...\right)  $.

For every $j>0$, there exists some $i\in\mathbb{N}$ such that $a_{j}^{i}v=0$
(since $V$ has a locally nilpotent action of $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  $). Hence, for every $j>0$, the element
$\overline{a_{j}}$ of $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup
I_{v}$ is nilpotent (because there exists some $i\in\mathbb{N}$ such that
$a_{j}^{i}v=0$, and thus this $i$ satisfies $a_{j}^{i}\in I_{v}$, so that
$\overline{a_{j}}^{i}=0$). Hence, the ideal $\overline{\mathfrak{i}}$ is
generated by nilpotent generators (since $\overline{\mathfrak{i}}=\left(
\overline{a_{1}},\overline{a_{2}},\overline{a_{3}},...\right)  $). Since we
also know that $\overline{\mathfrak{i}}$ is finitely generated (since
$\overline{\mathfrak{i}}$ is an ideal of the finite-dimensional algebra
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$), it follows
that $\overline{\mathfrak{i}}$ is generated by \textit{finitely many}
nilpotent generators. But if an ideal of a commutative ring is generated by
finitely many nilpotent generators, it must be nilpotent. Thus, $\overline
{\mathfrak{i}}$ is nilpotent. In other words, there exists some $M\in
\mathbb{N}$ such that $\overline{\mathfrak{i}}^{M}=0$. Consider this $M$.
Since $\overline{\mathfrak{i}}^{M}=0$, we have $\mathfrak{i}^{M}\subseteq
I_{v}$. Now, consider the decreasing sequence $\mathbb{C}\left[  a_{1}%
,a_{2},a_{3},...\right]  =\mathfrak{i}^{0}\supseteq\mathfrak{i}^{1}%
\supseteq...\supseteq\mathfrak{i}^{M}$ of subspaces of $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  $. By adding $I_{v}$ to each subspace, we can
make it into a sequence
\begin{equation}
\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  =\mathfrak{i}^{0}%
+I_{v}\supseteq\mathfrak{i}^{1}+I_{v}\supseteq...\supseteq\mathfrak{i}%
^{M}+I_{v}=I_{v} \label{prop.V=F(X)U.pf.1}%
\end{equation}
(where $\mathfrak{i}^{M}+I_{v}=I_{v}$ is because $\mathfrak{i}^{M}\subseteq
I_{v}$). We can now refine this sequence to a complete flag of vector
subspaces of $\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ lying between
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  $ and $I_{v}$ (since
$\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup I_{v}$ is
finite-dimensional). Let this flag be%
\[
\mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  =J_{0}\supseteq J_{1}%
\supseteq...\supseteq J_{N}=I_{v},
\]
with $\dim\left(  \mathbb{C}\left[  a_{1},a_{2},a_{3},...\right]  \diagup
J_{i}\right)  =i$ for every $i\in\left\{  0,1,...,N\right\}  $. Since this
flag is a refinement of the sequence (\ref{prop.V=F(X)U.pf.1}), there exists a
strictly increasing subsequence $\left(  j_{0},j_{1},...,j_{M}\right)  $ of
$\left(  0,1,...,N\right)  $ such that $J_{j_{k}}=\mathfrak{i}^{k}+I_{v}$ for
every $k\in\left\{  0,1,...,M\right\}  $. This quickly yields that%
\begin{equation}
\mathfrak{i}\cdot J_{i}\subseteq J_{i+1}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\left\{  0,1,...,N-1\right\}  \label{prop.V=F(X)U.pf.2}%
\end{equation}
(since $\mathfrak{i}\cdot\left(  \mathfrak{i}^{\ell}+I_{v}\right)
\subseteq\mathfrak{i}^{\ell+1}+I_{v}$ for every $\ell\in\mathbb{N}$).

For every $i\in\left\{  0,1,...,N\right\}  $, let $D_{i}=D\left(  x_{1}%
,x_{2},...\right)  \cdot J_{i}$. Then,%
\[
D_{0}=D\left(  x_{1},x_{2},...\right)  \cdot\underbrace{J_{0}}_{=\mathbb{C}%
\left[  a_{1},a_{2},a_{3},...\right]  }=D\left(  x_{1},x_{2},...\right)
\]
and%
\[
D_{N}=D\left(  x_{1},x_{2},...\right)  \cdot\underbrace{J_{N}}_{=I_{v}%
}=D\left(  x_{1},x_{2},...\right)  \cdot I_{v}.
\]
Hence, $D_{0}\diagup D_{N}=D\left(  x_{1},x_{2},...\right)  \diagup\left(
D\left(  x_{1},x_{2},...\right)  I_{v}\right)  =\widetilde{W}$.

Now, we are going to prove that%
\begin{equation}
D_{i}\diagup D_{i+1}\cong F\text{ or }D_{i}\diagup D_{i+1}%
=0\ \ \ \ \ \ \ \ \ \ \text{for every }i\in\left\{  0,1,...,N-1\right\}
\label{prop.V=F(X)U.pf.3}%
\end{equation}
(where $\cong$ means isomorphism of $\mathcal{A}_{0}$-modules).

\textit{Proof of (\ref{prop.V=F(X)U.pf.3}).} Let $i\in\left\{
0,1,...,N-1\right\}  $. Since $\dim\left(  \mathbb{C}\left[  a_{1},a_{2}%
,a_{3},...\right]  \diagup J_{i}\right)  =i$ and $\dim\left(  \mathbb{C}%
\left[  a_{1},a_{2},a_{3},...\right]  \diagup J_{i+1}\right)  =i+1$, there
exists some $u\in J_{i}$ such that $J_{i}=u+J_{i+1}$. Consider this $u$. By
abuse of notation, we also use the letter $u$ to denote the element $1\cdot
u\in D\left(  x_{1},x_{2},...\right)  \cdot J_{i}=D_{i}$. Then,
\begin{align*}
D_{i}  &  =D\left(  x_{1},x_{2},...\right)  \cdot\underbrace{J_{i}%
}_{=u+J_{i+1}}=D\left(  x_{1},x_{2},...\right)  \cdot\left(  u+J_{i+1}\right)
\\
&  =D\left(  x_{1},x_{2},...\right)  \cdot u+\underbrace{D\left(  x_{1}%
,x_{2},...\right)  \cdot J_{i+1}}_{=D_{i+1}}=D\left(  x_{1},x_{2},...\right)
\cdot u+D_{i+1}.
\end{align*}
Thus,
\[
D_{i}\diagup D_{i+1}=D\left(  x_{1},x_{2},...\right)  \cdot u^{\prime},
\]
where $u^{\prime}$ denotes the residue class of $u\in D_{i}$ modulo $D_{i+1}$.
For every $j>0$, we have $\underbrace{a_{j}}_{\in\mathfrak{i}}\underbrace{u}%
_{\in J_{i}}\in\mathfrak{i}\cdot J_{i}\subseteq J_{i+1}$ (by
(\ref{prop.V=F(X)U.pf.2})) and thus $a_{j}u\in D\left(  x_{1},x_{2}%
,...\right)  \cdot J_{i+1}=D_{i+1}$. In other words, for every $j>0$, we have
$a_{j}u^{\prime}=0$. Also, it is pretty clear that $Ku^{\prime}=u^{\prime}$.
Thus, Lemma \ref{lem.V=F} (applied to $D_{i}\diagup D_{i+1}$ and $u^{\prime}$
instead of $V$ and $u$) yields that there exists a homomorphism $\eta
:F\rightarrow D_{i}\diagup D_{i+1}$ of $\mathcal{A}_{0}$-modules such that
$\eta\left(  1\right)  =u^{\prime}$. This homomorphism $\eta$ must be
surjective\footnote{since its image is $\eta\left(  \underbrace{F}_{=D\left(
x_{1},x_{2},...\right)  \cdot1}\right)  =D\left(  x_{1},x_{2},...\right)
\cdot\underbrace{\eta\left(  1\right)  }_{=u^{\prime}}=D\left(  x_{1}%
,x_{2},...\right)  \cdot u^{\prime}=D_{i}\diagup D_{i+1}$}, and thus
$D_{i}\diagup D_{i+1}$ is a factor module of $F$. Since $F$ is irreducible,
this yields that $D_{i}\diagup D_{i+1}\cong F$ or $D_{i}\diagup D_{i+1}=0$.
This proves (\ref{prop.V=F(X)U.pf.3}).

Now, clearly, the $\mathcal{A}_{0}$-module $\widetilde{W}=D_{0}\diagup D_{N}$
is filtered by the $\mathcal{A}_{0}$-modules $D_{i}\diagup D_{N}$ for
$i\in\left\{  0,1,...,N\right\}  $. Due to (\ref{prop.V=F(X)U.pf.3}), the
subquotients of this filtration are all $\cong F$ or $=0$, so that
$\widetilde{W}$ is a finite-length $\mathcal{A}_{0}$-module with all
composition factors isomorphic to $F$ (since $F$ is irreducible).

Since $W$ is a quotient module of $\widetilde{W}$, this yields that $W$ must
also be a finite-length $\mathcal{A}_{0}$-module with all composition factors
isomorphic to $F$.

Now forget that we fixed $v$. We have thus shown that for every $v\in V$, the
$\mathcal{A}_{0}$-submodule $U\left(  \mathcal{A}_{0}\right)  \cdot v$ of $V$
(this submodule is what we called $W$) is a finite-length module with
composition factors isomorphic to $F$.

By the assumption (that for every $v\in V$, there exists some $N\in\mathbb{N}$
such that for every $n\geq N$, we have $a_{n}v=0$), we can define an action of
$E=\sum\limits_{i>0}a_{-i}a_{i}\in\widehat{\mathcal{A}}$ (the so-called
\textit{Euler field}) on $V$. Note that $E$ acts on $V$ in a locally finite
way (this means that for any $v\in V$, the space $\mathbb{C}\left[  E\right]
\cdot v$ is finite-dimensional)\footnote{\textit{Proof.} Notice that $E$ acts
on $F$ as $\sum\limits_{i>0}ix_{i}\dfrac{\partial}{\partial x_{i}}$, and thus
$E$ acts on $F$ in a locally finite way (since the differential operator
$\sum\limits_{i>0}ix_{i}\dfrac{\partial}{\partial x_{i}}$ preserves the
degrees of polynomials), and thus also on $V$ (because for every $v\in V$, the
$\mathcal{A}_{0}$-submodule $U\left(  \mathcal{A}_{0}\right)  \cdot v$ of $V$
is a finite-length module with composition factors isomorphic to $F$).}. Now,
let us notice that the eigenvalues of the map $E\mid_{V}:V\rightarrow V$ (this
is the action of $E$ on $V$) are nonnegative
integers.\footnote{\textit{Proof.} Let $\rho$ be an eigenvalue of $E\mid_{V}$.
Then, there exists some nonzero eigenvector $v\in V$ to the eigenvalue $\rho$.
Consider this $v$. Clearly, $\rho$ must thus also be an eigenvalue of
$E\mid_{U\left(  \mathcal{A}_{0}\right)  \cdot v}$ (because $v$ is a nonzero
eigenvector of $E\mid_{V}$ to the eigenvalue $\rho$ and lies in $U\left(
\mathcal{A}_{0}\right)  \cdot v$). But the eigenvalues of $E\mid_{U\left(
\mathcal{A}_{0}\right)  \cdot v}$ are nonnegative integers (since we know that
the $\mathcal{A}_{0}$-submodule $U\left(  \mathcal{A}_{0}\right)  \cdot v$ of
$V$ is a finite-length module with composition factors isomorphic to $F$, and
we can easily check that the eigenvalues of $E\mid_{F}$ are nonnegative
integers). Hence, $\rho$ is a nonnegative integer. We have thus shown that
every eigenvalue of $E\mid_{V}$ is a nonnegative integer, qed.} Hence, we can
write $V$ as $V=\bigoplus\limits_{j\geq0}V\left[  j\right]  $, where $V\left[
j\right]  $ is the generalized eigenspace of $E\mid_{V}$ with eigenvalue $j$
for every $j\in\mathbb{N}$.

If some $v\in V$ satisfies $a_{i}v=0$ for all $i>0$, then $Ev=0$ and thus
$v\in V\left[  0\right]  $.

Conversely, if $v\in V\left[  0\right]  $, then $a_{i}v=0$ for all
$i>0$.\ \ \ \ \footnote{\textit{Proof.} Let $v\in V\left[  0\right]  $.
Suppose that $a_{i}v=0$ holds for not all $i>0$. Let $k$ be the largest
integer such that there exist $k_{1},...,k_{m}$ with $\sum\limits_{j\geq
1}jk_{j}=k$ and $\prod\limits_{j\geq1}a_{j}^{k_{j}}v\neq0$. (Such a largest
$k$ exists since $V$ has a locally nilpotent action of $\mathbb{C}\left[
a_{1},a_{2},a_{3},...\right]  $.) Note that $k>0$, since otherwise $a_{i}v=0$
for all $i>0$.
\par
Then, $E\cdot\left(  \prod\limits_{j\geq1}a_{j}^{k_{j}}v\right)
=-k\prod\limits_{j\geq1}a_{j}^{k_{j}}v$ (this can be shown by a
straightforward induction using the fact that $a_{-i}a_{i}a_{j}=a_{j}%
a_{-i}a_{i}-i\delta_{i,j}a_{i}$ for any positive $i$ and $j$), and thus
$\prod\limits_{j\geq1}a_{j}^{k_{j}}v$ is a nonzero eigenvector of $E\mid_{V}$
with eigenvalue $-k$. This is a contradiction since the eigenvalues of
$E\mid_{V}$ are nonnegative integers. This contradiction shows that our
supposition that $a_{i}v=0$ holds for not all $i>0$ was wrong. Hence,
$a_{i}v=0$ for all $i>0$, qed.}

So we conclude that $V\left[  0\right]  =\operatorname*{Ker}E=\bigcap
\limits_{i\geq1}\operatorname*{Ker}a_{i}$.

Now, $F\otimes V\left[  0\right]  $ is an $\mathcal{A}_{0}$-module (where
$\mathcal{A}_{0}$ acts only on the $F$ tensorand, where $V\left[  0\right]  $
is considered just as a vector space). We will now construct an isomorphism
$F\otimes V\left[  0\right]  \rightarrow V$ of $\mathcal{A}_{0}$-modules. This
will prove Proposition \ref{prop.V=F(X)U}.

For every $v\in V\left[  0\right]  $, there exists a homomorphism $\eta
_{v}:F\rightarrow V$ of $\mathcal{A}_{0}$-modules such that $\eta_{v}\left(
1\right)  =v$ (according to Lemma \ref{lem.V=F}, applied to $v$ instead of $u$
(since $a_{i}v=0$ for all $i>0$ and $Kv=v$)). Consider these homomorphisms
$\eta_{v}$ for various $v$. Clearly, every $v\in V\left[  0\right]  $ and
$P\in F$ satisfy%
\begin{align*}
\eta_{v}\left(  P\right)   &  =\eta_{v}\left(  P\left(  a_{-1},a_{-2}%
,a_{-3},...\right)  \cdot1\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}P=P\left(  a_{-1},a_{-2},a_{-3},...\right)  \cdot1\right) \\
&  =P\left(  a_{-1},a_{-2},a_{-3},...\right)  \underbrace{\eta_{v}\left(
1\right)  }_{=v}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\eta_{v}\text{ is an
}\mathcal{A}_{0}\text{-module map}\right) \\
&  =P\left(  a_{-1},a_{-2},a_{-3},...\right)  v.
\end{align*}
Hence, we can define a $\mathbb{C}$-linear map $\rho:F\otimes V\left[
0\right]  \rightarrow V$ by%
\[
\rho\left(  P\otimes v\right)  =\eta_{v}\left(  P\right)  =P\left(
a_{-1},a_{-2},a_{-3},...\right)  v\ \ \ \ \ \ \ \ \ \ \text{for any }P\in
F\text{ and }v\in V\left[  0\right]  .
\]
This map $\rho$ is an $\mathcal{A}_{0}$-module map (because $\eta_{v}$ is an
$\mathcal{A}_{0}$-module map for every $v\in V\left[  0\right]  $).

The restriction of the map $\rho$ to the subspace $\mathbb{C}\cdot1\otimes
V\left[  0\right]  $ of $F\otimes V\left[  0\right]  $ is injective (since it
maps every $1\otimes v$ to $v$). Hence, the map $\rho$ is
injective\footnote{This follows from the following general
representation-theoretical fact (applied to $A=U\left(  \mathcal{A}%
_{0}\right)  $, $I=F$, $R=V\left[  0\right]  $, $S=V$, $i=1$ and $\phi=\rho$):
\par
Let $A$ be a $\mathbb{C}$-algebra. Let $I$ be an irreducible $A$-module, and
let $S$ be an $A$-module. Let $R$ be a vector space. Let $i\in I$ be nonzero.
Let $\phi:I\otimes R\rightarrow S$ be an $A$-module homomorphism such that the
restriction of $\phi$ to $\mathbb{C}i\otimes R$ is injective. Then, $\phi$ is
injective.}. Also, considering the quotient $\mathcal{A}_{0}$-module
$V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  $, we notice that
$E\mid_{V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  }$ has only
strictly positive eigenvalues (since $\rho\left(  F\otimes V\left[  0\right]
\right)  \supseteq V\left[  0\right]  $, so that all eigenvectors of
$E\mid_{V}$ to eigenvalue $0$ have been killed when factoring modulo
$\rho\left(  F\otimes V\left[  0\right]  \right)  $), and thus $V\diagup
\rho\left(  F\otimes V\left[  0\right]  \right)  =0$%
\ \ \ \ \footnote{\textit{Proof.} Assume the contrary. Then, $V\diagup
\rho\left(  F\otimes V\left[  0\right]  \right)  \neq0$. Thus, there exists
some nonzero $w\in V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  $.
Write $w$ as $\overline{v}$, where $v$ is an element of $V$ and $\overline{v}$
denotes the residue class of $v$ modulo $\rho\left(  F\otimes V\left[
0\right]  \right)  $. As we know, the $\mathcal{A}_{0}$-submodule $U\left(
\mathcal{A}_{0}\right)  \cdot v$ of $V$ is a finite-length module with
composition factors isomorphic to $F$. Thus, the $\mathcal{A}_{0}$-module
$U\left(  \mathcal{A}_{0}\right)  \cdot w$ (being a quotient module of
$U\left(  \mathcal{A}_{0}\right)  \cdot v$) must also be a finite-length
module with composition factors isomorphic to $F$. Hence, there exists a
submodule of $U\left(  \mathcal{A}_{0}\right)  \cdot w$ isomorphic to $F$
(since $w\neq0$ and thus $U\left(  \mathcal{A}_{0}\right)  \cdot w\neq0$).
This submodule contains a nonzero eigenvector of $E$ to eigenvalue $0$
(because $F$ contains a nonzero eigenvector of $E$ to eigenvalue $0$, namely
$1$). This is a contradiction to the fact that $E\mid_{V\diagup\rho\left(
F\otimes V\left[  0\right]  \right)  }$ has only strictly positive
eigenvalues. This contradiction shows that our assumption was wrong, so we do
have $V\diagup\rho\left(  F\otimes V\left[  0\right]  \right)  =0$, qed.}. In
other words, $V=\rho\left(  F\otimes V\left[  0\right]  \right)  $, so that
$\rho$ is surjective. Since $\rho$ is an injective and surjective
$\mathcal{A}_{0}$-module map, we conclude that $\rho$ is an $\mathcal{A}_{0}%
$-module isomorphism. Thus, $V\cong F\otimes V\left[  0\right]  $ as
$\mathcal{A}_{0}$-modules. This proves Proposition \ref{prop.V=F(X)U}.

\subsection{Some consequences of Poincar\'{e}-Birkhoff-Witt}

We will now spend some time with generalities on Lie algebras and their
universal enveloping algebras. These generalities will be applied later, and
while these applications could be substituted by concrete computations, it
appears to me that it is better for the sake of clarity to do them generally
in here.

\begin{proposition}
\label{prop.U(X)U}Let $k$ be a field. Let $\mathfrak{c}$ be a $k$-Lie algebra.
Let $\mathfrak{a}$ and $\mathfrak{b}$ be two Lie subalgebras of $\mathfrak{c}$
such that $\mathfrak{a}+\mathfrak{b}=\mathfrak{c}$. Notice that $\mathfrak{a}%
\cap\mathfrak{b}$ is also a Lie subalgebra of $\mathfrak{c}$.

Let $\rho:U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  \rightarrow U\left(
\mathfrak{c}\right)  $ be the $k$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\beta\right)  =\alpha\beta\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in
U\left(  \mathfrak{a}\right)  \text{ and }\beta\in U\left(  \mathfrak{b}%
\right)
\]
(this is clearly well-defined). Then, $\rho$ is an isomorphism of vector
spaces, of left $U\left(  \mathfrak{a}\right)  $-modules and of right
$U\left(  \mathfrak{b}\right)  $-modules.
\end{proposition}

\begin{corollary}
\label{cor.U(X)U}Let $k$ be a field. Let $\mathfrak{c}$ be a $k$-Lie algebra.
Let $\mathfrak{a}$ and $\mathfrak{b}$ be two Lie subalgebras of $\mathfrak{c}$
such that $\mathfrak{a}\oplus\mathfrak{b}=\mathfrak{c}$ (as vector spaces, not
necessarily as Lie algebras). Let $\rho:U\left(  \mathfrak{a}\right)
\otimes_{k}U\left(  \mathfrak{b}\right)  \rightarrow U\left(  \mathfrak{c}%
\right)  $ be the $k$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes\beta\right)  =\alpha\beta
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in U\left(  \mathfrak{a}\right)
\text{ and }\beta\in U\left(  \mathfrak{b}\right)
\]
(this is clearly well-defined). Then, $\rho$ is an isomorphism of filtered
vector spaces, of left $U\left(  \mathfrak{a}\right)  $-modules and of right
$U\left(  \mathfrak{b}\right)  $-modules.
\end{corollary}

We give two proofs of Proposition \ref{prop.U(X)U}. They are very similar
(both use the Poincar\'{e}-Birkhoff-Witt theorem, albeit different versions
thereof). The first is more conceptual (and more general), while the second is
more down-to-earth.

\textit{First proof of Proposition \ref{prop.U(X)U}.} For any Lie algebra
$\mathfrak{u}$, we have a $k$-algebra homomorphism $\operatorname*{PBW}%
\nolimits_{\mathfrak{u}}:S\left(  \mathfrak{u}\right)  \rightarrow
\operatorname*{gr}\left(  U\left(  \mathfrak{u}\right)  \right)  $ which sends
$u_{1}u_{2}...u_{\ell}$ to $\overline{u_{1}u_{2}...u_{\ell}}\in
\operatorname*{gr}\nolimits_{\ell}\left(  U\left(  \mathfrak{u}\right)
\right)  $ for every $\ell\in\mathbb{N}$ and every $u_{1},u_{2},...,u_{\ell
}\in\mathfrak{u}$. This homomorphism $\operatorname*{PBW}%
\nolimits_{\mathfrak{u}}$ is an isomorphism due to the
Poincar\'{e}-Birkhoff-Witt theorem.

\begin{verlong}
It is rather clear that $\operatorname*{gr}\left(  U\left(  \mathfrak{a}%
\right)  \right)  $ and $\operatorname*{gr}\left(  U\left(  \mathfrak{b}%
\right)  \right)  $ are $\operatorname*{gr}\left(  U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  \right)  $-modules (since $U\left(  \mathfrak{a}%
\right)  $ and $U\left(  \mathfrak{b}\right)  $ are filtered $U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  $-modules)
\end{verlong}

We can define a $k$-algebra homomorphism $f:\operatorname*{gr}\left(  U\left(
\mathfrak{a}\right)  \right)  \otimes_{\operatorname*{gr}\left(  U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \right)  }\operatorname*{gr}\left(
U\left(  \mathfrak{b}\right)  \right)  \rightarrow\operatorname*{gr}\left(
U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  \right)  $ by
\[
f\left(  \overline{u}\otimes_{\operatorname*{gr}\left(  U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \right)  }\overline{v}\right)
=\overline{u\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }v}%
\in\operatorname*{gr}\nolimits_{k+\ell}\left(  U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \right)
\]
for any $k\in\mathbb{N}$, any $\ell\in\mathbb{N}$, any $u\in U_{\leq k}\left(
\mathfrak{a}\right)  $ and $v\in U_{\leq\ell}\left(  \mathfrak{b}\right)  $.
This $f$ is easily seen to be well-defined. Moreover, $f$ is
surjective\footnote{To show this, either notice that the image of $f$ contains
a generating set of $\operatorname*{gr}\left(  U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \right)  $ (because the definition of $f$ easily rewrites
as
\par%
\[
f\left(  \overline{\alpha_{1}\alpha_{2}...\alpha_{k}}\otimes
_{\operatorname*{gr}\left(  U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
\right)  }\overline{\beta_{1}\beta_{2}...\beta_{\ell}}\right)  =\overline
{\alpha_{1}\alpha_{2}...\alpha_{k}\otimes_{U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }\beta_{1}\beta_{2}...\beta_{\ell}}\in
\operatorname*{gr}\nolimits_{k+\ell}\left(  U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \right)
\]
for any $k\in\mathbb{N}$, any $\ell\in\mathbb{N}$, any $\alpha_{1},\alpha
_{2},...,\alpha_{k}\in\mathfrak{a}$ and $\beta_{1},\beta_{2},...,\beta_{\ell
}\in\mathfrak{b}$), or prove the more general fact that for any $\mathbb{Z}%
_{+}$-filtered algebra $A$, any filtered right $A$-module $M$ and any filtered
left $A$-module $N$, the canonical map%
\begin{align*}
\operatorname*{gr}\left(  M\right)  \otimes_{\operatorname*{gr}\left(
A\right)  }\operatorname*{gr}\left(  N\right)   &  \rightarrow
\operatorname*{gr}\left(  M\otimes_{A}N\right)  ,\\
\overline{\mu}\otimes_{\operatorname*{gr}\left(  A\right)  }\overline{\nu}  &
\mapsto\overline{\mu\otimes_{A}\nu}\in\operatorname*{gr}\nolimits_{m+n}\left(
M\otimes_{A}N\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{for all }\mu\in
M_{m}\text{ and }\nu\in N_{n}\text{, for all }m,n\in\mathbb{N}\right)
\end{align*}
is well-defined and surjective (this is easy to prove).}.

It is easy to see that the isomorphisms $\operatorname*{PBW}%
\nolimits_{\mathfrak{a}}:S\left(  \mathfrak{a}\right)  \rightarrow
\operatorname*{gr}\left(  U\left(  \mathfrak{a}\right)  \right)  $,
$\operatorname*{PBW}\nolimits_{\mathfrak{b}}:S\left(  \mathfrak{b}\right)
\rightarrow\operatorname*{gr}\left(  U\left(  \mathfrak{b}\right)  \right)  $
and $\operatorname*{PBW}\nolimits_{\mathfrak{a}\cap\mathfrak{b}}:S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \rightarrow\operatorname*{gr}\left(
U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  \right)  $ are "compatible" with
each other in the sense that the diagrams%
\[%
%TCIMACRO{\TeXButton{X}{\xycs{12pc}
%\xymatrix{
%S\left(\fraka\right) \otimes S\left(\fraka\cap\frakb\right) \ar[r]^-{\text
%{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\fraka\right)}
%\ar[d]_{\PBW_{\fraka}\otimes\PBW_{\fraka\cap\frakb}}^{\cong} & S\left
%(\fraka\right) \ar[d]_{\PBW_{\fraka}}^{\cong} \\
%\gr\left(U\left(\fraka\right)\right) \otimes\gr\left(U\left(\fraka\cap
%\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
%\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\fraka\right)\right)}
%& \gr\left(U\left(\fraka\right)\right)
%}}}%
%BeginExpansion
\xycs{12pc}
\xymatrix{
S\left(\fraka\right) \otimes S\left(\fraka\cap\frakb\right) \ar[r]^-{\text
{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\fraka\right)}
\ar[d]_{\PBW_{\fraka}\otimes\PBW_{\fraka\cap\frakb}}^{\cong} & S\left
(\fraka\right) \ar[d]_{\PBW_{\fraka}}^{\cong} \\
\gr\left(U\left(\fraka\right)\right) \otimes\gr\left(U\left(\fraka\cap
\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\fraka\right)\right)}
& \gr\left(U\left(\fraka\right)\right)
}%
%EndExpansion
\]
and%
\[%
%TCIMACRO{\TeXButton{X}{\xycs{12pc}
%\xymatrix{
%S\left(\fraka\cap\frakb\right) \otimes S\left(\frakb\right) \ar[r]^-{\text
%{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\frakb\right)}
%\ar[d]_{\PBW_{\fraka\cap\frakb}\otimes\PBW_{\frakb}}^{\cong} & S\left
%(\frakb\right) \ar[d]_{\PBW_{\frakb}}^{\cong} \\
%\gr\left(U\left(\fraka\cap\frakb\right)\right) \otimes\gr\left(U\left
%(\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
%\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\frakb\right)\right)}
%& \gr\left(U\left(\frakb\right)\right)
%}}}%
%BeginExpansion
\xycs{12pc}
\xymatrix{
S\left(\fraka\cap\frakb\right) \otimes S\left(\frakb\right) \ar[r]^-{\text
{action of }S\left(\fraka\cap\frakb\right)\text{ on }S\left(\frakb\right)}
\ar[d]_{\PBW_{\fraka\cap\frakb}\otimes\PBW_{\frakb}}^{\cong} & S\left
(\frakb\right) \ar[d]_{\PBW_{\frakb}}^{\cong} \\
\gr\left(U\left(\fraka\cap\frakb\right)\right) \otimes\gr\left(U\left
(\frakb\right)\right) \ar[r]_-{\text{action of }\gr\left(U\left(\fraka
\cap\frakb\right)\right)\text{ on }\gr\left(U\left(\frakb\right)\right)}
& \gr\left(U\left(\frakb\right)\right)
}%
%EndExpansion
\]
commute\footnote{This is pretty easy to see from the definition of
$\operatorname*{PBW}\nolimits_{\mathfrak{u}}$.}. Hence, they give rise to an
isomorphism%
\begin{align*}
S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)   &  \rightarrow
\operatorname*{gr}\left(  U\left(  \mathfrak{a}\right)  \right)
\otimes_{\operatorname*{gr}\left(  U\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  \right)  }\operatorname*{gr}\left(  U\left(  \mathfrak{b}\right)
\right)  ,\\
\alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }\beta &
\mapsto\left(  \operatorname*{PBW}\nolimits_{\mathfrak{a}}\alpha\right)
\otimes_{\operatorname*{gr}\left(  U\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  \right)  }\left(  \operatorname*{PBW}\nolimits_{\mathfrak{b}}%
\beta\right)  .
\end{align*}
Denote this isomorphism by $\left(  \operatorname*{PBW}\nolimits_{\mathfrak{a}%
}\right)  \otimes_{\operatorname*{PBW}\nolimits_{\mathfrak{a}\cap\mathfrak{b}%
}}\left(  \operatorname*{PBW}\nolimits_{\mathfrak{b}}\right)  $.

Finally, let $\sigma:S\left(  \mathfrak{a}\right)  \otimes_{S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)
\rightarrow S\left(  \mathfrak{c}\right)  $ be the vector space homomorphism
defined by%
\[
\sigma\left(  \alpha\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\beta\right)  =\alpha\beta\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in
S\left(  \mathfrak{a}\right)  \text{ and }\beta\in S\left(  \mathfrak{b}%
\right)  .
\]
This $\sigma$ is rather obviously an algebra homomorphism. Now, it is easy to
see that $\sigma$ is an algebra isomorphism\footnote{\textit{Proof.} Since
every subspace of a vector space has a complementary subspace, we can find a
subspace $\mathfrak{d}$ of $\mathfrak{a}$ such that $\mathfrak{a}%
=\mathfrak{d}\oplus\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $. Consider
such a $\mathfrak{d}$.
\par
Since $\mathfrak{a}=\mathfrak{d}\oplus\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  =\mathfrak{d}+\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $, the
fact that $\mathfrak{c}=\mathfrak{a}+\mathfrak{b}$ rewrites as $\mathfrak{c}%
=\mathfrak{d}+\underbrace{\left(  \mathfrak{a}\cap\mathfrak{b}\right)
+\mathfrak{b}}_{\substack{=\mathfrak{b}\\\text{(since }\mathfrak{a}%
\cap\mathfrak{b}\subseteq\mathfrak{b}\text{)}}}=\mathfrak{d}+\mathfrak{b}$.
Combined with $\underbrace{\mathfrak{d}}_{\substack{=\mathfrak{d}%
\cap\mathfrak{a}\\\text{(since }\mathfrak{d}\subseteq\mathfrak{a}\text{)}%
}}\cap\mathfrak{b}\subseteq\mathfrak{d}\cap\mathfrak{a}\cap\mathfrak{b}=0$
(since $\mathfrak{d}\oplus\left(  \mathfrak{a}\cap\mathfrak{b}\right)  $ is a
direct sum), this yields $\mathfrak{c}=\mathfrak{d}\oplus\mathfrak{b}$.
\par
Recall a known fact from multilinear algebra: Any two vector spaces $U$ and
$V$ satisfy $S\left(  U\oplus V\right)  \cong S\left(  U\right)  \otimes
_{k}S\left(  V\right)  $ by the canonical algebra isomorphism. Hence,
$S\left(  \mathfrak{d}\oplus\mathfrak{b}\right)  \cong S\left(  \mathfrak{d}%
\right)  \otimes_{k}S\left(  \mathfrak{b}\right)  $.
\par
But $\mathfrak{a}=\left(  \mathfrak{a}\cap\mathfrak{b}\right)  \oplus
\mathfrak{d}$ yields $S\left(  \mathfrak{a}\right)  =S\left(  \mathfrak{d}%
\oplus\left(  \mathfrak{a}\cap\mathfrak{b}\right)  \right)  \cong S\left(
\mathfrak{d}\right)  \otimes_{k}S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
$ (by the above-quoted known fact). Hence,%
\begin{align*}
S\left(  \mathfrak{a}\right)  \otimes_{S\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)   &  \cong\left(  S\left(
\mathfrak{d}\right)  \otimes_{k}S\left(  \mathfrak{a}\cap\mathfrak{b}\right)
\right)  \otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }S\left(
\mathfrak{b}\right) \\
&  \cong S\left(  \mathfrak{d}\right)  \otimes_{k}\underbrace{\left(  S\left(
\mathfrak{a}\cap\mathfrak{b}\right)  \otimes_{S\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  }S\left(  \mathfrak{b}\right)  \right)  }_{=S\left(
\mathfrak{b}\right)  }=S\left(  \mathfrak{d}\right)  \otimes_{k}S\left(
\mathfrak{b}\right)  \cong S\left(  \underbrace{\mathfrak{d}\oplus
\mathfrak{b}}_{=\mathfrak{c}}\right)  =S\left(  \mathfrak{c}\right)  .
\end{align*}
Thus we have constructed an algebra isomorphism $S\left(  \mathfrak{a}\right)
\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }S\left(
\mathfrak{b}\right)  \rightarrow S\left(  \mathfrak{c}\right)  $. If we track
down what happens to elements of $\mathfrak{d}$, $\mathfrak{a}\cap
\mathfrak{b}$ and $\mathfrak{b}$ under this isomorphism, we notice that they
just get sent to themselves, so this isomorphism must coincide with $\sigma$
(since two algebra homomorphisms coinciding on a set generators of algebra
must be equal). Thus, $\sigma$ is an algebra isomorphism, qed.}.

Now, it is easy to see (by elementwise checking) that the diagram%
\[%
%TCIMACRO{\TeXButton{X}{\xymatrixcolsep{11pc}
%\xymatrix{
%\gr\left(U\left(\fraka\right)\right) \otimes_{\gr\left(U\left(\fraka\cap
%\frakb\right)\right)} \gr\left(U\left(\frakb\right)\right) \ar[d]^{f}
%& S\left(\fraka\right) \otimes_{S\left(\fraka\cap\frakb\right)} S\left
%(\frakb\right) \ar[l]_-{\left(\PBW_{\fraka}\right) \otimes_{\PBW_{\fraka
%\cap\frakb}} \left(\PBW_{\frakb}\right)}^{\cong} \ar[d]_{\cong}^{\sigma} \\
%\gr\left(U\left(\fraka\right) \otimes_{U\left(\fraka\cap\frakb\right)}
%U\left(\frakb\right)\right) \ar[dr]_{\gr\rho} & S\left(\frakc\right
%) \ar[d]^{\PBW_{\frakc}}_{\cong} \\
%& \gr\left(U\left(\frakc\right)\right)
%}}}%
%BeginExpansion
\xymatrixcolsep{11pc}
\xymatrix{
\gr\left(U\left(\fraka\right)\right) \otimes_{\gr\left(U\left(\fraka\cap
\frakb\right)\right)} \gr\left(U\left(\frakb\right)\right) \ar[d]^{f}
& S\left(\fraka\right) \otimes_{S\left(\fraka\cap\frakb\right)} S\left
(\frakb\right) \ar[l]_-{\left(\PBW_{\fraka}\right) \otimes_{\PBW_{\fraka
\cap\frakb}} \left(\PBW_{\frakb}\right)}^{\cong} \ar[d]_{\cong}^{\sigma} \\
\gr\left(U\left(\fraka\right) \otimes_{U\left(\fraka\cap\frakb\right)}
U\left(\frakb\right)\right) \ar[dr]_{\gr\rho} & S\left(\frakc\right
) \ar[d]^{\PBW_{\frakc}}_{\cong} \\
& \gr\left(U\left(\frakc\right)\right)
}%
%EndExpansion
\]
is commutative.\footnote{In fact, if we follow the pure tensor $\alpha
_{1}\alpha_{2}...\alpha_{k}\otimes_{S\left(  \mathfrak{a}\cap\mathfrak{b}%
\right)  }\beta_{1}\beta_{2}...\beta_{\ell}$ (with $k\in\mathbb{N}$, $\ell
\in\mathbb{N}$, $\alpha_{1},\alpha_{2},...,\alpha_{k}\in\mathfrak{a}$ and
$\beta_{1},\beta_{2},...,\beta_{\ell}\in\mathfrak{b}$) through this diagram,
we get $\overline{\alpha_{1}\alpha_{2}...\alpha_{k}\beta_{1}\beta_{2}%
...\beta_{\ell}}\in\operatorname*{gr}\nolimits_{k+\ell}\left(  \mathfrak{c}%
\right)  $ both ways.} Hence, $\left(  \operatorname*{gr}\rho\right)  \circ f$
is an isomorphism, so that $f$ is injective. Since $f$ is also surjective,
this yields that $f$ is an isomorphism. Thus, $\operatorname*{gr}\rho$ is an
isomorphism (since $\left(  \operatorname*{gr}\rho\right)  \circ f$ is an
isomorphism). Since $\rho$ is a filtered map and $\operatorname*{gr}\rho$ is
an isomorphism, it follows that $\rho$ is an isomorphism of filtered vector
spaces. Hence, $\rho$ is an isomorphism of filtered vector spaces, of left
$U\left(  \mathfrak{a}\right)  $-modules and of right $U\left(  \mathfrak{b}%
\right)  $-modules (since it is clear that $\rho$ is a homomorphism of
$U\left(  \mathfrak{a}\right)  $-left modules and of $U\left(  \mathfrak{b}%
\right)  $-right modules). This proves Proposition \ref{prop.U(X)U}.

\textit{Second proof of Proposition \ref{prop.U(X)U}.} Let $\left(
z_{i}\right)  _{i\in I}$ be a basis of the $k$-vector space $\mathfrak{a}%
\cap\mathfrak{b}$. We extend this basis to a basis $\left(  z_{i}\right)
_{i\in I}\cup\left(  x_{j}\right)  _{j\in J}$ of the $k$-vector space
$\mathfrak{a}$ and to a basis $\left(  z_{i}\right)  _{i\in I}\cup\left(
y_{k}\right)  _{k\in K}$ of the $k$-vector space $\mathfrak{b}$. Then,
$\left(  z_{i}\right)  _{i\in I}\cup\left(  x_{j}\right)  _{j\in J}\cup\left(
y_{k}\right)  _{k\in K}$ is a basis of the $k$-vector space $\mathfrak{b}$. We
endow this basis with a total ordering in such a way that every $x_{j}$ is
smaller than every $z_{i}$, and that every $z_{i}$ is smaller than every
$y_{k}$. By the Poincar\'{e}-Birkhoff-Witt theorem, we have a basis of
$U\left(  \mathfrak{c}\right)  $ consisting of increasing products of elements
of the basis $\left(  z_{i}\right)  _{i\in I}\cup\left(  x_{j}\right)  _{j\in
J}\cup\left(  y_{k}\right)  _{k\in K}$. On the other hand, again by the
Poincar\'{e}-Birkhoff-Witt theorem, we have a basis of $U\left(
\mathfrak{a}\right)  $ consisting of increasing products of elements of the
basis $\left(  z_{i}\right)  _{i\in I}\cup\left(  x_{j}\right)  _{j\in J}$.
Note that the $z_{i}$ accumulate at the right end of these products, while the
$x_{j}$ accumulate at the left end (because we defined the total ordering in
such a way that every $x_{j}$ is smaller than every $z_{i}$). Hence, $U\left(
\mathfrak{a}\right)  $ is a free right $U\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  $-module, with a basis (over $U\left(  \mathfrak{a}%
\cap\mathfrak{b}\right)  $, not over $k$) consisting of increasing products of
elements of the basis $\left(  x_{j}\right)  _{j\in J}$. Combined with the
fact that $U\left(  \mathfrak{b}\right)  $ is a free $k$-vector space with a
basis consisting of increasing products of elements of the basis $\left(
x_{j}\right)  _{j\in J}\cup\left(  y_{k}\right)  _{k\in K}$ (again by
Poincar\'{e}-Birkhoff-Witt), this yields that $U\left(  \mathfrak{a}\right)
\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  $ is a free $k$-vector space with a basis consisting of
tensors of the form%
\begin{align*}
&  \left(  \text{increasing product of elements of the basis }\left(
x_{j}\right)  _{j\in J}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\left(  \text{increasing product of elements of the basis }\left(
x_{j}\right)  _{j\in J}\cup\left(  y_{k}\right)  _{k\in K}\right)  .
\end{align*}
The map $\rho$ clearly maps such terms bijectively into increasing products of
elements of the basis $\left(  z_{i}\right)  _{i\in I}\cup\left(
x_{j}\right)  _{j\in J}\cup\left(  y_{k}\right)  _{k\in K}$. Hence, $\rho$
maps a basis of $U\left(  \mathfrak{a}\right)  \otimes_{U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  $
bijectively to a basis of $U\left(  \mathfrak{c}\right)  $. Thus, $\rho$ is an
isomorphism of vector spaces. Moreover, since both of our bases were
filtered\footnote{A basis $\mathcal{B}$ of a filtered vector space $V$ is said
to be \textit{filtered} if for every $n\in\mathbb{N}$, the subfamily of
$\mathcal{B}$ consisting of those elements of $\mathcal{B}$ lying in the
$n$-th filtration of $V$ is a basis of the $n$-th filtration of $V$.}, and
$\rho$ respects this filtration on the bases, we can even conclude that $\rho$
is an isomorphism of filtered vector spaces. Since it is clear that $\rho$ is
a homomorphism of $U\left(  \mathfrak{a}\right)  $-left modules and of
$U\left(  \mathfrak{b}\right)  $-right modules, it follows that $\rho$ is an
isomorphism of filtered vector spaces, of left $U\left(  \mathfrak{a}\right)
$-modules and of right $U\left(  \mathfrak{b}\right)  $-modules. This proves
Proposition \ref{prop.U(X)U}.

\textit{Proof of Corollary \ref{cor.U(X)U}.} Corollary \ref{cor.U(X)U}
immediately follows from Proposition \ref{prop.U(X)U} (since $\mathfrak{a}%
\oplus\mathfrak{b}=\mathfrak{c}$ yields $\mathfrak{a}\cap\mathfrak{b}=0$, thus
$U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  =U\left(  0\right)  =k$).

\begin{remark}
\label{rmk.U(X)U}While we have required $k$ to be a field in Proposition
\ref{prop.U(X)U} and Corollary \ref{cor.U(X)U}, these two results hold in more
general situations as well. For instance, Proposition \ref{prop.U(X)U} holds
whenever $k$ is a commutative ring, as long as $\mathfrak{a}$, $\mathfrak{b}$
and $\mathfrak{a}\cap\mathfrak{b}$ are free $k$-modules, and $\mathfrak{a}%
\cap\mathfrak{b}$ is a direct summand of $\mathfrak{a}$ as a $k$-module. In
fact, the first proof of Proposition \ref{prop.U(X)U} works in this situation
(because the Poincar\'{e}-Birkhoff-Witt theorem holds for free modules). In a
more restrictive situation (namely, when $\mathfrak{a}\cap\mathfrak{b}$ is a
free $k$-module, and a direct summand of each of $\mathfrak{a}$ and
$\mathfrak{b}$, with the other two summands also being free), the second proof
of Proposition \ref{prop.U(X)U} works as well. As for Corollary
\ref{cor.U(X)U}, it holds whenever $k$ is a commutative ring, as long as
$\mathfrak{a}$ and $\mathfrak{b}$ are free $k$-modules.

This generality is more than enough for most applications of Proposition
\ref{prop.U(X)U} and Corollary \ref{cor.U(X)U}. Yet we can go even further
using the appropriate generalizations of the Poincar\'{e}-Birkhoff-Witt
theorem (for these, see, e. g., P. J. Higgins, \textit{Baer Invariants and the
Birkhoff-Witt theorem}, J. of Alg. 11, pp. 469-482, (1969)).
\end{remark}

\subsection{Representations of $\mathbb{Z}$-graded Lie algebras}

Let us show some general results about representations of $\mathbb{Z}$-graded
Lie algebras -- particularly of \textit{nondegenerate} $\mathbb{Z}$-graded Lie
algebras. This is a notion that encompasses many of the concrete Lie algebras
that we want to study (among others, $\mathcal{A}$, $\mathcal{A}_{0}$, $W$ and
$\operatorname*{Vir}$), and thus by proving the properties of nondegenerate
$\mathbb{Z}$-graded Lie algebras now we can avoid proving them separately in
many different cases.

\begin{definition}
\label{def.gradLie}A $\mathbb{Z}$\textit{-graded Lie algebra} is a Lie algebra
$\mathfrak{g}$ with a decomposition $\mathfrak{g}=\bigoplus\limits_{n\in
\mathbb{Z}}\mathfrak{g}_{n}$ (as a vector space) such that $\left[
\mathfrak{g}_{n},\mathfrak{g}_{m}\right]  \subseteq\mathfrak{g}_{n+m}$ for all
$n,m\in\mathbb{Z}$.
\end{definition}

Note that if $\mathfrak{g}=\bigoplus\limits_{n\in\mathbb{Z}}\mathfrak{g}_{n}$
is a $\mathbb{Z}$-graded Lie algebra, then $\bigoplus\limits_{n<0}%
\mathfrak{g}_{n}$, $\mathfrak{g}_{0}$ and $\bigoplus\limits_{n>0}%
\mathfrak{g}_{n}$ are Lie subalgebras of $\mathfrak{g}$.

\begin{definition}
\label{def.gradLienondeg}A $\mathbb{Z}$-graded Lie algebra $\mathfrak{g}%
=\bigoplus\limits_{n\in\mathbb{Z}}\mathfrak{g}_{n}$ is said to be
\textit{nondegenerate} if

\textbf{(1)} the vector space $\mathfrak{g}_{n}$ is finite-dimensional for
every $n\in\mathbb{Z}$;

\textbf{(2)} the Lie algebra $\mathfrak{g}_{0}$ is abelian;

\textbf{(3)} for every positive integer $n$, for generic $\lambda
\in\mathfrak{g}_{0}^{\ast}$, the bilinear form $\mathfrak{g}_{n}%
\times\mathfrak{g}_{-n}\rightarrow\mathbb{C},\ \left(  a, b\right)
\mapsto\lambda\left(  \left[  a,b\right]  \right)  $ is nondegenerate.
("Generic $\lambda$" means that "$\lambda$ lying in some dense open subset of
$\mathfrak{g}_{0}^{\ast}$ with respect to the Zariski topology".)
\end{definition}

Note that condition \textbf{(3)} in Definition \ref{def.gradLienondeg} implies
that $\dim\left(  \mathfrak{g}_{n}\right)  =\dim\left(  \mathfrak{g}%
_{-n}\right)  $ for all $n\in\mathbb{Z}$.

Here are some examples:

\begin{proposition}
The Lie algebras $\mathcal{A}$, $\mathcal{A}_{0}$, $W$ and
$\operatorname*{Vir}$ are nondegenerate (with the usual gradings).
\end{proposition}

\begin{proposition}
\label{prop.grad.g}Let $\mathfrak{g}$ be a finite-dimensional simple Lie
algebra. The following is a reasonable (although non-canonical) way to define
a grading on $\mathfrak{g}$:

Using a Cartan subalgebra and the roots of $\mathfrak{g}$, we can present the
Lie algebra $\mathfrak{g}$ as a Lie algebra with generators $e_{1}$, $e_{2}$,
$...$, $e_{m}$, $f_{1}$, $f_{2}$, $...$, $f_{m}$, $h_{1}$, $h_{2}$, $...$,
$h_{m}$ (the so-called Chevalley generators) and some relations (the Serre
relations). Then, we can define a grading on $\mathfrak{g}$ by setting
$\deg\left(  e_{i}\right)  =1$, $\deg\left(  f_{i}\right)  =-1$ and
$\deg\left(  h_{i}\right)  =0$ and continuing this grading in such a way that
$\mathfrak{g}$ becomes a graded Lie algebra. This grading is non-canonical,
but it makes $\mathfrak{g}$ into a nondegenerate graded Lie algebra.
\end{proposition}

\begin{proposition}
If $\mathfrak{g}$ is a simple Lie algebra, then the loop algebra
$\mathfrak{g}\left[  t,t^{-1}\right]  $ and the affine Kac-Moody algebra
$\widehat{\mathfrak{g}}=\mathfrak{g}\left[  t,t^{-1}\right]  \oplus
\mathbb{C}K$ can be graded as follows:

Fix Chevalley generators for $\mathfrak{g}$ and grade $\mathfrak{g}$ as in
Proposition \ref{prop.grad.g}. Now let $\theta$ be the maximal root of
$\mathfrak{g}$, i. e., the highest weight of the adjoint representation of
$\mathfrak{g}$. Let $e_{\theta}$ and $f_{\theta}$ be the root elements
corresponding to $\theta$. The \textit{Coxeter number} of $\mathfrak{g}$ is
defined as $\deg\left(  e_{\theta}\right)  +1$, and denoted by $h$. Now let us
grade $\widehat{\mathfrak{g}}$ by setting $\deg K=0$ and $\deg\left(
at^{m}\right)  =\deg a+mh$ for every homogeneous $a\in\mathfrak{g}$ and every
$m\in\mathbb{Z}$. This grading satisfies $\deg t=m$, $\deg\left(  f_{\theta
}t\right)  =1$ and $\deg\left(  e_{\theta}t^{-1}\right)  =-1$. It is easy to
see that the elements of $\widehat{\mathfrak{g}}$ of positive degree span
$\mathfrak{n}_{+}\oplus t\mathfrak{g}\left[  t\right]  $. The graded Lie
algebra $\widehat{\mathfrak{g}}$ is nondegenerate. The loop algebra
$\mathfrak{g}\left[  t,t^{-1}\right]  $, however, is not (with the grading
defined in the same way).
\end{proposition}

If $\mathfrak{g}$ is a $\mathbb{Z}$-graded Lie algebra, we can write%
\[
\mathfrak{g}=\bigoplus\limits_{n\in\mathbb{Z}}\mathfrak{g}_{n}=\bigoplus
\limits_{n<0}\mathfrak{g}_{n}\oplus\mathfrak{g}_{0}\oplus\bigoplus
\limits_{n>0}\mathfrak{g}_{n}.
\]
We denote $\bigoplus\limits_{n<0}\mathfrak{g}_{n}$ by $\mathfrak{n}_{-}$ and
we denote $\bigoplus\limits_{n>0}\mathfrak{g}_{n}$ by $\mathfrak{n}_{+}$. We
also denote $\mathfrak{g}_{0}$ by $\mathfrak{h}$. Then, $\mathfrak{n}_{-}$,
$\mathfrak{n}_{+}$ and $\mathfrak{h}$ are Lie subalgebras of $\mathfrak{g}$,
and the above decomposition rewrites as $\mathfrak{g}=\mathfrak{n}_{-}%
\oplus\mathfrak{h}\oplus\mathfrak{n}_{+}$ (but this is, of course, not a
decomposition of Lie algebras). This is called the \textit{triangular
decomposition} of $\mathfrak{g}$.

In the following, $\mathfrak{g}$ will be a $\mathbb{Z}$-graded Lie algebra
(not necessarily nondegenerate), and we will work with the notations
introduced above.

\begin{definition}
\label{def.verma}Let $\lambda\in\mathfrak{h}^{\ast}$.

Let $\mathbb{C}_{\lambda}$ denote the $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{+}\right)  $-module which, as a $\mathbb{C}$-vector space, is
the free vector space with basis $\left(  v_{\lambda}^{+}\right)  $ (thus, a
$1$-dimensional vector space), and whose $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{+}\right)  $-action is given by%
\begin{align*}
hv_{\lambda}^{+}  &  =\lambda\left(  h\right)  v_{\lambda}^{+}%
\ \ \ \ \ \ \ \ \ \ \text{for every }h\in\mathfrak{h};\\
\mathfrak{n}_{+}v_{\lambda}^{+}  &  =0.
\end{align*}


The \textit{Verma highest-weight module }$M_{\lambda}^{+}$ \textit{of
}$\left(  \mathfrak{g},\lambda\right)  $ is defined by%
\[
M_{\lambda}^{+}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{\lambda}.
\]
The element $1\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
}v_{\lambda}^{+}$ of $M_{\lambda}^{+}$ will still be denoted by $v_{\lambda
}^{+}$ by abuse of notation. Since $U\left(  \mathfrak{g}\right)  $ and
$\mathbb{C}_{\lambda}$ are graded $U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  $-modules, their tensor product $U\left(  \mathfrak{g}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}%
_{\lambda}=M_{\lambda}^{+}$ becomes graded as well.

Let $\mathbb{C}_{\lambda}$ denote the $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{-}\right)  $-module which, as a $\mathbb{C}$-vector space, is
the free vector space with basis $\left(  v_{\lambda}^{-}\right)  $ (thus, a
$1$-dimensional vector space), and whose $\left(  \mathfrak{h}\oplus
\mathfrak{n}_{-}\right)  $-action is given by%
\begin{align*}
hv_{\lambda}^{-}  &  =\lambda\left(  h\right)  v_{\lambda}^{-}%
\ \ \ \ \ \ \ \ \ \ \text{for every }h\in\mathfrak{h};\\
\mathfrak{n}_{-}v_{\lambda}^{-}  &  =0.
\end{align*}
(Note that we denote this $\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)
$-module by $\mathbb{C}_{\lambda}$, although we already have denoted an
$\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  $-module by $\mathbb{C}%
_{\lambda}$. This is ambiguous, but misunderstandings are unlikely to occur
since these modules are modules over different Lie algebras, and their
restrictions to $\mathfrak{h}$ are identical.)

The \textit{Verma lowest-weight module }$M_{\lambda}^{-}$ \textit{of }$\left(
\mathfrak{g},\lambda\right)  $ is defined by%
\[
M_{\lambda}^{-}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}_{\lambda}.
\]
The element $1\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)
}v_{\lambda}^{-}$ of $M_{\lambda}^{-}$ will still be denoted by $v_{\lambda
}^{-}$ by abuse of notation. Since $U\left(  \mathfrak{g}\right)  $ and
$\mathbb{C}_{\lambda}$ are graded $U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{-}\right)  $-modules, their tensor product $U\left(  \mathfrak{g}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}%
_{\lambda}=M_{\lambda}^{-}$ becomes graded as well.
\end{definition}

We notice some easy facts about these modules:

\begin{proposition}
\label{prop.verma1}Let $\lambda\in\mathfrak{h}^{\ast}$.

\textbf{(a)} As a graded $\mathfrak{n}_{-}$-module, $M_{\lambda}^{+}=U\left(
\mathfrak{n}_{-}\right)  v_{\lambda}^{+}$; more precisely, there exists a
graded $\mathfrak{n}_{-}$-module isomorphism $U\left(  \mathfrak{n}%
_{-}\right)  \otimes\mathbb{C}_{\lambda}\rightarrow M_{\lambda}^{+}$ which
sends every $x\otimes t\in U\left(  \mathfrak{n}_{-}\right)  \otimes
\mathbb{C}_{\lambda}$ to $xtv_{\lambda}^{+}$. The Verma module $M_{\lambda
}^{+}$ is concentrated in nonpositive degrees:%
\[
M_{\lambda}^{+}=\bigoplus\limits_{n\geq0}M_{\lambda}^{+}\left[  -n\right]
;\ \ \ \ \ \ \ \ \ \ M_{\lambda}^{+}\left[  -n\right]  =U\left(
\mathfrak{n}_{-}\right)  \left[  -n\right]  v_{\lambda}^{+}%
\ \ \ \ \ \ \ \ \ \ \text{for every }n\geq0.
\]
Also, if $\dim\mathfrak{g}_{j}<\infty$ for all $j\leq-1$, we have%
\[
\sum\limits_{n\geq0}\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)
q^{n}=\dfrac{1}{\prod\limits_{j\leq-1}\left(  1-q^{-j}\right)  ^{\dim
\mathfrak{g}_{j}}}.
\]


\textbf{(b)} As a graded $\mathfrak{n}_{+}$-module, $M_{\lambda}^{-}=U\left(
\mathfrak{n}_{+}\right)  v_{\lambda}^{-}$; more precisely, there exists a
graded $\mathfrak{n}_{+}$-module isomorphism $U\left(  \mathfrak{n}%
_{+}\right)  \otimes\mathbb{C}_{\lambda}\rightarrow M_{\lambda}^{-}$ which
sends every $x\otimes t\in U\left(  \mathfrak{n}_{+}\right)  \otimes
\mathbb{C}_{\lambda}$ to $xtv_{\lambda}^{-}$. The Verma module $M_{\lambda
}^{-}$ is concentrated in nonnegative degrees:%
\[
M_{\lambda}^{-}=\bigoplus\limits_{n\geq0}M_{\lambda}^{-}\left[  n\right]
;\ \ \ \ \ \ \ \ \ \ M_{\lambda}^{-}\left[  n\right]  =U\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  v_{\lambda}^{-}\ \ \ \ \ \ \ \ \ \ \text{for
every }n\geq0.
\]
Also, if $\dim\mathfrak{g}_{j}<\infty$ for all $j\geq1$, we have%
\[
\sum\limits_{n\geq0}\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)
q^{n}=\dfrac{1}{\prod\limits_{j\geq1}\left(  1-q^{j}\right)  ^{\dim
\mathfrak{g}_{j}}}.
\]

\end{proposition}

\textit{Proof of Proposition \ref{prop.verma1}.} \textbf{(a)} Let
$\rho:U\left(  \mathfrak{n}_{-}\right)  \otimes_{\mathbb{C}}U\left(
\mathfrak{h}\oplus\mathfrak{n}_{+}\right)  \rightarrow U\left(  \mathfrak{g}%
\right)  $ be the $\mathbb{C}$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes\beta\right)  =\alpha\beta
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in U\left(  \mathfrak{n}_{-}\right)
\text{ and }\beta\in U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
\]
(this is clearly well-defined). By Corollary \ref{cor.U(X)U} (applied to
$\mathfrak{a}=\mathfrak{n}_{-}$, $\mathfrak{b}=\mathfrak{h}\oplus
\mathfrak{n}_{+}$ and $\mathfrak{c}=\mathfrak{g}$), this $\rho$ is an
isomorphism of filtered\footnote{Filtered by the usual filtration on the
universal enveloping algebra of a Lie algebra. This filtration does not take
into account the grading on $\mathfrak{n}_{-}$, $\mathfrak{h}\oplus
\mathfrak{n}_{+}$ and $\mathfrak{g}$.} vector spaces, of left $U\left(
\mathfrak{n}_{-}\right)  $-modules and of right $U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  $-modules. Also, it is a graded linear
map\footnote{Here we \textit{do} take into account the grading on
$\mathfrak{n}_{-}$, $\mathfrak{h}\oplus\mathfrak{n}_{+}$ and $\mathfrak{g}$.}
(this is clear from its definition), and thus an isomorphism of graded vector
spaces (because if a vector space isomorphism of graded vector spaces is a
graded linear map, then it must be an isomorphism of graded vector
spaces\footnote{If you are wondering why this statement is more than a
blatantly obvious tautology, let me add some clarifications:
\par
A \textit{graded linear map} is a morphism in the category of graded vector
spaces. What I am stating here is that if a vector space isomorphism between
graded vector spaces is at the same time a morphism in the category of graded
vector spaces, then it must be an \textit{isomorphism} in the category of
graded vector spaces. This is very easy to show, but not a self-evident
tautology. In fact, the analogous assertion about filtered vector spaces (i.
e., the assertion that if a vector space isomorphism between filtered vector
spaces is at the same time a morphism in the category of filtered vector
spaces, then it must be an \textit{isomorphism} in the category of filtered
vector spaces) is wrong.}. Altogether, $\rho$ is an isomorphism of graded
filtered vector spaces, of left $U\left(  \mathfrak{n}_{-}\right)  $-modules
and of right $U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  $-modules.
Hence,%
\begin{align*}
M_{\lambda}^{+}  &  =\underbrace{U\left(  \mathfrak{g}\right)  }%
_{\substack{\cong U\left(  \mathfrak{n}_{-}\right)  \otimes_{\mathbb{C}%
}U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  \\\text{(by the
isomorphism }\rho\text{)}}}\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  }\mathbb{C}_{\lambda}\cong\left(  U\left(  \mathfrak{n}%
_{-}\right)  \otimes_{\mathbb{C}}U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  \right)  \otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  }\mathbb{C}_{\lambda}\\
&  \cong U\left(  \mathfrak{n}_{-}\right)  \otimes_{\mathbb{C}}%
\underbrace{\left(  U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}%
_{\lambda}\right)  }_{\cong\mathbb{C}_{\lambda}}\cong U\left(  \mathfrak{n}%
_{-}\right)  \otimes\mathbb{C}_{\lambda}\ \ \ \ \ \ \ \ \ \ \text{as graded
}U\left(  \mathfrak{n}_{-}\right)  \text{-modules.}%
\end{align*}
This gives us a graded $\mathfrak{n}_{-}$-module isomorphism $U\left(
\mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}\rightarrow M_{\lambda
}^{+}$ which is easily seen to send every $x\otimes t\in U\left(
\mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}$ to $xtv_{\lambda}^{+}$.
Hence, $M_{\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)  v_{\lambda}^{+}$.
Since $\mathfrak{n}_{-}$ is concentrated in negative degrees, it is clear that
$U\left(  \mathfrak{n}_{-}\right)  $ is concentrated in nonpositive degrees.
Hence, $U\left(  \mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}$ is
concentrated in nonpositive degrees, and thus the same holds for $M_{\lambda
}^{+}$ (since $M_{\lambda}^{+}\cong U\left(  \mathfrak{n}_{-}\right)
\otimes\mathbb{C}_{\lambda}$ as graded $U\left(  \mathfrak{n}_{-}\right)
$-modules). In other words, $M_{\lambda}^{+}=\bigoplus\limits_{n\geq
0}M_{\lambda}^{+}\left[  -n\right]  $.

Since the isomorphism $U\left(  \mathfrak{n}_{-}\right)  \otimes
\mathbb{C}_{\lambda}\rightarrow M_{\lambda}^{+}$ which sends every $x\otimes
t\in U\left(  \mathfrak{n}_{-}\right)  \otimes\mathbb{C}_{\lambda}$ to
$xtv_{\lambda}^{+}$ is graded, it sends $U\left(  \mathfrak{n}_{-}\right)
\left[  -n\right]  \otimes\mathbb{C}_{\lambda}=\left(  U\left(  \mathfrak{n}%
_{-}\right)  \otimes\mathbb{C}_{\lambda}\right)  \left[  -n\right]  $ to
$M_{\lambda}^{+}\left[  -n\right]  $ for every $n\geq0$. Thus, $M_{\lambda
}^{+}\left[  -n\right]  =U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]
v_{\lambda}^{+}$ for every $n\geq0$. Hence,
\begin{align*}
\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)   &  =\dim\left(
U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  v_{\lambda}^{+}\right)
=\dim\left(  U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \right)
=\dim\left(  S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because }U\left(  \mathfrak{n}_{-}\right)  \cong S\left(  \mathfrak{n}%
_{-}\right)  \text{ as graded vector spaces}\\
\text{(by the Poincar\'{e}-Birkhoff-Witt theorem)}%
\end{array}
\right)
\end{align*}
for every $n\geq0$. This easily yields that if $\dim\mathfrak{g}_{j}<\infty$
for all $j\leq-1$, then%
\[
\sum\limits_{n\geq0}\dim\left(  M_{\lambda}^{+}\left[  -n\right]  \right)
q^{n}=\dfrac{1}{\prod\limits_{j\leq-1}\left(  1-q^{-j}\right)  ^{\dim\left(
\left(  \mathfrak{n}_{-}\right)  _{j}\right)  }}=\dfrac{1}{\prod
\limits_{j\leq-1}\left(  1-q^{-j}\right)  ^{\dim\mathfrak{g}_{j}}}.
\]
This proves Proposition \ref{prop.verma1} \textbf{(a)}.

\textbf{(b)} The proof of part \textbf{(b)} is analogous to that of
\textbf{(a)}.

This proves Proposition \ref{prop.verma1}.

\subsection{The invariant bilinear form on Verma modules}

\begin{proposition}
\label{prop.invform}\textbf{(a)} There exists a unique $\mathfrak{g}%
$-invariant bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  =1$ (where we denote this bilinear form by $\left(  \cdot
,\cdot\right)  $).

\textbf{(b)} This form has degree $0$. (This means that if we consider this
bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ as
a linear map $M_{\lambda}^{+}\otimes M_{-\lambda}^{-}\rightarrow\mathbb{C}$,
then it is a graded map, where $M_{\lambda}^{+}\otimes M_{-\lambda}^{-}$ is
graded as a tensor product of graded vector spaces, and $\mathbb{C}$ is
concentrated in degree $0$.)

\textbf{(c)} Every $\mathfrak{g}$-invariant bilinear form $M_{\lambda}%
^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ is a scalar multiple of this
form $\left(  \cdot,\cdot\right)  $.
\end{proposition}

\begin{remark}
\label{rmk.invform.1}Proposition \ref{prop.invform} still holds when the
ground field $\mathbb{C}$ is replaced by a commutative ring $k$, as long as
some rather weak conditions hold (for instance, it is enough that
$\mathfrak{n}_{-}$, $\mathfrak{n}_{+}$ and $\mathfrak{h}$ are free $k$-modules).
\end{remark}

To prove Proposition \ref{prop.invform}, we recall two facts about modules
over Lie algebras:

\begin{lemma}
\label{lem.pushpull}Let $\mathfrak{a}$ be a Lie algebra, and let
$\mathfrak{b}$ be a Lie subalgebra of $\mathfrak{a}$. Let $V$ be a
$\mathfrak{b}$-module, and $W$ be an $\mathfrak{a}$-module. Then, $\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\cong\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $ as $\mathfrak{a}$-modules (where the $W$ on the right
hand side is to be understood as $\operatorname*{Res}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}W$). More precisely, there exists a canonical $\mathfrak{a}%
$-module isomorphism $\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}V\right)  \otimes W\rightarrow\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  $ which maps
$\left(  1\otimes_{U\left(  \mathfrak{b}\right)  }v\right)  \otimes w$ to
$1\otimes_{U\left(  \mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all
$v\in V$ and $w\in W$.
\end{lemma}

\begin{lemma}
\label{lem.IndRes}Let $\mathfrak{c}$ be a Lie algebra. Let $\mathfrak{a}$ and
$\mathfrak{b}$ be two Lie subalgebras of $\mathfrak{c}$ such that
$\mathfrak{a}+\mathfrak{b}=\mathfrak{c}$. Notice that $\mathfrak{a}%
\cap\mathfrak{b}$ is also a Lie subalgebra of $\mathfrak{c}$. Let $N$ be a
$\mathfrak{b}$-module. Then, $\operatorname*{Ind}\nolimits_{\mathfrak{a}%
\cap\mathfrak{b}}^{\mathfrak{a}}\left(  \operatorname*{Res}%
\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{b}}N\right)
\cong\operatorname*{Res}\nolimits_{\mathfrak{a}}^{\mathfrak{c}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{c}}N\right)  $ as
$\mathfrak{a}$-modules.
\end{lemma}

We will give two proofs of Lemma \ref{lem.pushpull}: one which is direct and
uses Hopf algebras; the other which is more elementary but less direct.

\textit{First proof of Lemma \ref{lem.pushpull}.} Remember that $U\left(
\mathfrak{a}\right)  $ is a Hopf algebra (a cocommutative one, actually; but
we won't use this). Let us denote its antipode by $S$ and use sumfree Sweedler notation.

Recalling that $\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}%
}V=U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{b}\right)  }V$
and $\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  =U\left(  \mathfrak{a}\right)  \otimes_{U\left(
\mathfrak{b}\right)  }\left(  V\otimes W\right)  $, we define a $\mathbb{C}%
$-linear map $\phi:\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}V\right)  \otimes W\rightarrow\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  $ by
$\left(  \alpha\otimes_{U\left(  \mathfrak{b}\right)  }v\right)  \otimes
w\mapsto\alpha_{\left(  1\right)  }\otimes_{U\left(  \mathfrak{b}\right)
}\left(  v\otimes S\left(  \alpha_{\left(  2\right)  }\right)  w\right)  $.
This map is easily checked to be well-defined and $\mathfrak{a}$-linear. Also,
we define a $\mathbb{C}$-linear map $\psi:\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)
\rightarrow\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}%
}V\right)  \otimes W$ by $\alpha\otimes_{U\left(  \mathfrak{b}\right)
}\left(  v\otimes w\right)  \mapsto\left(  \alpha_{\left(  1\right)  }%
\otimes_{U\left(  \mathfrak{b}\right)  }v\right)  \otimes\alpha_{\left(
2\right)  }w$. This map is easily checked to be well-defined. It is also easy
to see that $\phi\circ\psi=\operatorname*{id}$ and $\psi\circ\phi
=\operatorname*{id}$. Hence, $\phi$ and $\psi$ are mutually inverse
isomorphisms between the $\mathfrak{a}$-modules $\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W$ and
$\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $. This proves that $\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W\cong%
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $ as $\mathfrak{a}$-modules. Moreover, the isomorphism $\phi:\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\rightarrow\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $ is canonical and maps $\left(  1\otimes_{U\left(
\mathfrak{b}\right)  }v\right)  \otimes w$ to $1\otimes_{U\left(
\mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all $v\in V$ and $w\in
W$. In other words, Lemma \ref{lem.pushpull} is proven.

\textit{Second proof of Lemma \ref{lem.pushpull}.} For every $\mathfrak{a}%
$-module $Y$, we have%
\begin{align*}
&  \operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W,Y\right) \\
&  =\left(  \underbrace{\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)
\otimes W,Y\right)  }_{\cong\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}%
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
}\right)  ^{\mathfrak{a}}\\
&  \cong\left(  \operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}%
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
\right)  ^{\mathfrak{a}}=\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}%
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{b}}\left(
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right) \\
&  =\left(  \underbrace{\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(
V,\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  W,Y\right)  \right)
}_{\cong\operatorname*{Hom}\nolimits_{\mathbb{C}}\left(  V\otimes W,Y\right)
}\right)  ^{\mathfrak{b}}\cong\left(  \operatorname*{Hom}\nolimits_{\mathbb{C}%
}\left(  V\otimes W,Y\right)  \right)  ^{\mathfrak{b}}\\
&  =\operatorname*{Hom}\nolimits_{\mathfrak{b}}\left(  V\otimes W,Y\right)
\cong\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  ,Y\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right)  .
\end{align*}
Since this isomorphism is canonical, it gives us a natural isomorphism between
the functors $\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W,-\right)  $ and $\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  ,-\right)  $. By Yoneda's lemma, this yields that $\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\cong\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $ as $\mathfrak{a}$-modules. It is also rather clear that
the $\mathfrak{a}$-module isomorphism $\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W\rightarrow
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $ we have just obtained is canonical.

In order to check that this isomorphism maps $\left(  1\otimes_{U\left(
\mathfrak{b}\right)  }v\right)  \otimes w$ to $1\otimes_{U\left(
\mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all $v\in V$ and $w\in
W$, we must retrace the proof of Yoneda's lemma. This proof proceeds by
evaluating the natural isomorphism $\operatorname*{Hom}\nolimits_{\mathfrak{a}%
}\left(  \left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}%
}V\right)  \otimes W,-\right)  \rightarrow\operatorname*{Hom}%
\nolimits_{\mathfrak{a}}\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}\left(  V\otimes W\right)  ,-\right)  $ at the object
$\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  $, thus obtaining an isomorphism%
\[
\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(  \left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes W,\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  \right)
\rightarrow\operatorname*{Hom}\nolimits_{\mathfrak{a}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes
W\right)  ,\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  \right)  ,
\]
and taking the preimage of $\operatorname*{id}\in\operatorname*{Hom}%
\nolimits_{\mathfrak{a}}\left(  \operatorname*{Ind}\nolimits_{\mathfrak{b}%
}^{\mathfrak{a}}\left(  V\otimes W\right)  ,\operatorname*{Ind}%
\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(  V\otimes W\right)  \right)  $
under this isomorphism. This preimage is our isomorphism $\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}V\right)  \otimes
W\rightarrow\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{a}}\left(
V\otimes W\right)  $. Checking that this maps $\left(  1\otimes_{U\left(
\mathfrak{b}\right)  }v\right)  \otimes w$ to $1\otimes_{U\left(
\mathfrak{b}\right)  }\left(  v\otimes w\right)  $ for all $v\in V$ and $w\in
W$ is a matter of routine now, and left to the reader. Lemma
\ref{lem.pushpull} is thus proven.

\textit{Proof of Lemma \ref{lem.IndRes}.} Let $\rho:U\left(  \mathfrak{a}%
\right)  \otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)  }U\left(
\mathfrak{b}\right)  \rightarrow U\left(  \mathfrak{c}\right)  $ be the
$\mathbb{C}$-vector space homomorphism defined by%
\[
\rho\left(  \alpha\otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}\beta\right)  =\alpha\beta\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha\in
U\left(  \mathfrak{a}\right)  \text{ and }\beta\in U\left(  \mathfrak{b}%
\right)
\]
(this is clearly well-defined). By Proposition \ref{prop.U(X)U}, this map
$\rho$ is an isomorphism of left $U\left(  \mathfrak{a}\right)  $-modules and
of right $U\left(  \mathfrak{b}\right)  $-modules. Hence, $U\left(
\mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}\cap\mathfrak{b}\right)
}U\left(  \mathfrak{b}\right)  \cong U\left(  \mathfrak{c}\right)  $ as left
$U\left(  \mathfrak{a}\right)  $-modules and simultaneously right $U\left(
\mathfrak{b}\right)  $-modules. Now,%
\begin{align*}
\operatorname*{Ind}\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{a}%
}\underbrace{\left(  \operatorname*{Res}\nolimits_{\mathfrak{a}\cap
\mathfrak{b}}^{\mathfrak{b}}N\right)  }_{=N\text{ (as a left }U\left(
\mathfrak{b}\right)  \text{-module)}}  &  =\operatorname*{Ind}%
\nolimits_{\mathfrak{a}\cap\mathfrak{b}}^{\mathfrak{a}}\underbrace{N}_{\cong
U\left(  \mathfrak{b}\right)  \otimes_{U\left(  \mathfrak{b}\right)  }N}\cong
U\left(  \mathfrak{a}\right)  \otimes_{U\left(  \mathfrak{a}\cap
\mathfrak{b}\right)  }\left(  U\left(  \mathfrak{b}\right)  \otimes_{U\left(
\mathfrak{b}\right)  }N\right) \\
&  \cong\underbrace{\left(  U\left(  \mathfrak{a}\right)  \otimes_{U\left(
\mathfrak{a}\cap\mathfrak{b}\right)  }U\left(  \mathfrak{b}\right)  \right)
}_{\cong U\left(  \mathfrak{c}\right)  }\otimes_{U\left(  \mathfrak{b}\right)
}N\cong U\left(  \mathfrak{c}\right)  \otimes_{U\left(  \mathfrak{b}\right)
}N=\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{c}}N\\
&  \cong\operatorname*{Res}\nolimits_{\mathfrak{a}}^{\mathfrak{c}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{b}}^{\mathfrak{c}}N\right)
\ \ \ \ \ \ \ \ \ \ \text{as }\mathfrak{a}\text{-modules.}%
\end{align*}
This proves Lemma \ref{lem.IndRes}.

\textit{Proof of Proposition \ref{prop.invform}.} We have $M_{\lambda}%
^{+}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{\lambda}=\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\mathbb{C}%
_{\lambda}$. Thus,%
\begin{align*}
&  \operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+}\otimes
M_{-\lambda}^{-},\mathbb{C}\right) \\
&  =\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  \underbrace{\left(
\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}^{\mathfrak{g}}\mathbb{C}_{\lambda}\right)  \otimes M_{-\lambda}^{-}%
}_{\substack{\cong\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus
\mathfrak{n}_{+}}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes
M_{-\lambda}^{-}\right)  \\\text{(by Lemma \ref{lem.pushpull})}}%
},\mathbb{C}\right)  \cong\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes M_{-\lambda}^{-}\right)
,\mathbb{C}\right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}\left(  \mathbb{C}_{\lambda}\otimes\underbrace{M_{-\lambda}^{-}%
}_{\substack{=U\left(  \mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}_{-\lambda}\\=\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\mathbb{C}%
_{-\lambda}}},\mathbb{C}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
Frobenius reciprocity}\right) \\
&  =\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(
\underbrace{\mathbb{C}_{\lambda}\otimes\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\mathbb{C}%
_{-\lambda}\right)  }_{\substack{\cong\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\left(
\mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right)  \\\text{(by Lemma
\ref{lem.pushpull})}}},\mathbb{C}\right)  \cong\operatorname*{Hom}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\left(
\mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right)  ,\mathbb{C}\right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}%
}\left(  \operatorname*{Ind}\nolimits_{\mathfrak{h}}^{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}\left(  \mathbb{C}_{\lambda}\otimes\mathbb{C}%
_{-\lambda}\right)  ,\mathbb{C}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since Lemma \ref{lem.IndRes} (applied to }\mathfrak{c}=\mathfrak{g}%
\text{, }\mathfrak{a}=\mathfrak{h}\oplus\mathfrak{n}_{+}\text{, }%
\mathfrak{b}=\mathfrak{h}\oplus\mathfrak{n}_{-}\text{ and }N=\mathbb{C}%
_{\lambda}\otimes\mathbb{C}_{-\lambda}\text{)}\\
\text{yields }\operatorname*{Ind}\nolimits_{\mathfrak{h}}^{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}\left(  \operatorname*{Res}\nolimits_{\mathfrak{h}%
}^{\mathfrak{h}\oplus\mathfrak{n}_{-}}N\right)  \cong\operatorname*{Res}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\left(
\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}%
}^{\mathfrak{g}}N\right)  \text{, which rewrites as}\\
\operatorname*{Ind}\nolimits_{\mathfrak{h}}^{\mathfrak{h}\oplus\mathfrak{n}%
_{+}}\left(  \mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right)
\cong\operatorname*{Ind}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}%
}^{\mathfrak{g}}\left(  \mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda
}\right)  \text{ (since we are suppressing the}\\
\operatorname*{Res}\text{ functors), so that }\operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{-}}^{\mathfrak{g}}\left(
\mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right)  \cong%
\operatorname*{Ind}\nolimits_{\mathfrak{h}}^{\mathfrak{h}\oplus\mathfrak{n}%
_{+}}\left(  \mathbb{C}_{\lambda}\otimes\mathbb{C}_{-\lambda}\right) \\
\text{ (as }\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)
\text{-modules)}%
\end{array}
\right) \\
&  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}}\left(  \mathbb{C}%
_{\lambda}\otimes\mathbb{C}_{-\lambda},\mathbb{C}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right) \\
&  \cong\mathbb{C}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathbb{C}%
_{\lambda}\otimes\mathbb{C}_{-\lambda}\cong\mathbb{C}\text{ as }%
\mathfrak{h}\text{-modules (this is easy to see)}\right)  .
\end{align*}
This isomorphism $\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(
M_{\lambda}^{+}\otimes M_{-\lambda}^{-},\mathbb{C}\right)  \rightarrow
\mathbb{C}$ is easily seen to map every $\mathfrak{g}$-invariant bilinear form
$\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda}%
^{-}\rightarrow\mathbb{C}$ (seen as a linear map $M_{\lambda}^{+}\otimes
M_{-\lambda}^{-}\rightarrow\mathbb{C}$) to the value $\left(  v_{\lambda}%
^{+},v_{-\lambda}^{-}\right)  $. Hence, there exists a unique $\mathfrak{g}%
$-invariant bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  =1$ (where we denote this bilinear form by $\left(  \cdot
,\cdot\right)  $), and every other $\mathfrak{g}$-invariant bilinear form
$M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ must be a scalar
multiple of this one. This proves Proposition \ref{prop.invform} \textbf{(a)}
and \textbf{(c)}.

Now, for the proof of \textbf{(b)}: Denote by $\left(  \cdot,\cdot\right)  $
the unique $\mathfrak{g}$-invariant bilinear form $M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}%
^{+},v_{-\lambda}^{-}\right)  =1$. Let us now prove that this bilinear form is
of degree $0$:

Consider the antipode $S:U\left(  \mathfrak{g}\right)  \rightarrow U\left(
\mathfrak{g}\right)  $ of the Hopf algebra $U\left(  \mathfrak{g}\right)  $.
This $S$ is a graded algebra antiautomorphism satisfying $S\left(  x\right)
=-x$ for every $x\in\mathfrak{g}$. It can be explicitly described by
\[
S\left(  x_{1}x_{2}...x_{m}\right)  =\left(  -1\right)  ^{m}x_{m}%
x_{m-1}...x_{1}\ \ \ \ \ \ \ \ \ \ \text{for all }m\in\mathbb{N}\text{ and
}x_{1},x_{2},...,x_{m}\in\mathfrak{g}.
\]


We can easily see by induction (using the $\mathfrak{g}$-invariance of the
bilinear form $\left(  \cdot,\cdot\right)  $) that $\left(  v,aw\right)
=\left(  S\left(  a\right)  v,w\right)  $ for all $v\in M_{\lambda}^{+}$ and
$w\in M_{-\lambda}^{-}$ and $a\in U\left(  \mathfrak{g}\right)  $. In
particular, $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  =\left(
S\left(  b\right)  av_{\lambda}^{+},v_{-\lambda}^{-}\right)  =0$ whenever $a$
and $b$ are homogeneous elements of $U\left(  \mathfrak{g}\right)  $
satisfying $\deg b>-\deg a$ (this is because any two homogeneous elements $a$
and $b$ of $U\left(  \mathfrak{g}\right)  $ satisfying $\deg b>-\deg a$
satisfy $S\left(  b\right)  av_{\lambda}^{+}=0$%
\ \ \ \ \footnote{\textit{Proof.} Let $a$ and $b$ be homogeneous elements of
$U\left(  \mathfrak{g}\right)  $ satisfying $\deg b>-\deg a$. Then, $\deg
b+\deg a>0$, and thus the element $S\left(  b\right)  av_{\lambda}^{+}$ of
$M_{\lambda}^{+}$ is a homogeneous element of positive degree (since $\deg
v_{\lambda}^{+}=0$), but the only homogeneous element of $M_{\lambda}^{+}$ of
positive degree is $0$ (since $M_{\lambda}^{+}$ is concentrated in nonpositive
degrees), so that $S\left(  b\right)  av_{\lambda}^{+}=0$.}). In other words,
whenever $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ are integers satisfying $m>-n$,
we have $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  =0$ for every
$a\in U\left(  \mathfrak{g}\right)  \left[  n\right]  $ and $b\in U\left(
\mathfrak{g}\right)  \left[  m\right]  $. Since $M_{\lambda}^{+}\left[
n\right]  =\left\{  av_{\lambda}^{+}\ \mid\ a\in U\left(  \mathfrak{g}\right)
\left[  n\right]  \right\}  $ and $M_{-\lambda}^{-}\left[  m\right]  =\left\{
bv_{-\lambda}^{-}\ \mid\ b\in U\left(  \mathfrak{g}\right)  \left[  m\right]
\right\}  $, this rewrites as follows: Whenever $n\in\mathbb{Z}$ and
$m\in\mathbb{Z}$ are integers satisfying $m>-n$, we have $\left(  M_{\lambda
}^{+}\left[  n\right]  ,M_{-\lambda}^{-}\left[  m\right]  \right)  =0$.

Similarly, using the formula $\left(  av,w\right)  =\left(  v,S\left(
a\right)  w\right)  $ (which holds for all $v\in M_{\lambda}^{+}$ and $w\in
M_{-\lambda}^{-}$ and $a\in U\left(  \mathfrak{g}\right)  $), we can show that
whenever $n\in\mathbb{Z}$ and $m\in\mathbb{Z}$ are integers satisfying $m<-n$,
we have $\left(  M_{\lambda}^{+}\left[  n\right]  ,M_{-\lambda}^{-}\left[
m\right]  \right)  =0$.

Thus we have $\left(  M_{\lambda}^{+}\left[  n\right]  ,M_{-\lambda}%
^{-}\left[  m\right]  \right)  =0$ whenever $m>-n$ and whenever $m<-n$. Hence,
$\left(  M_{\lambda}^{+}\left[  n\right]  ,M_{-\lambda}^{-}\left[  m\right]
\right)  $ can only be nonzero when $m=-n$. In other words, the form $\left(
\cdot,\cdot\right)  $ has degree $0$. This proves Proposition
\ref{prop.invform}. In this proof, we have not used any properties of
$\mathbb{C}$ other than being a commutative ring over which $\mathfrak{n}_{-}%
$, $\mathfrak{n}_{+}$ and $\mathfrak{h}$ are free modules (the latter was only
used for applying consequences of Poincar\'{e}-Birkhoff-Witt); we thus have
also verified Remark \ref{rmk.invform.1}.

\begin{theorem}
\label{thm.invformnondeg}Assume that $\mathfrak{g}$ is a nondegenerate
$\mathbb{Z}$-graded Lie algebra.

Let $\left(  \cdot,\cdot\right)  $ be the unique $\mathfrak{g}$-invariant
bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$
satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  =1$. (Such a form
exists and is unique by Proposition \ref{prop.invform} \textbf{(a)}.)

In every degree, the form $\left(  \cdot,\cdot\right)  $ is nondegenerate for
generic $\lambda$. More precisely: For every $n\in\mathbb{N}$, the restriction
of the form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda
}^{-}\rightarrow\mathbb{C}$ to $M_{\lambda}^{+}\left[  -n\right]  \times
M_{-\lambda}^{-}\left[  n\right]  $ is nondegenerate for generic $\lambda$.

(What "generic $\lambda$" means here may depend on the degree. Thus, we cannot
claim that "for generic $\lambda$, the form $\left(  \cdot,\cdot\right)  $ is
nondegenerate in every degree"!)
\end{theorem}

Before we prove this, a general fact from representation theory:

\begin{lemma}
\label{lem.bilform}Let $k$ be a field, and let $G$ be a finite group. Let
$\Lambda\in k\left[  G\right]  $ be the element $\sum\limits_{g\in G}g$.

Let $V$ and $W$ be representations of $G$ over $k$. Let $B:V\times
W\rightarrow k$ be a $G$-invariant bilinear form.

\textbf{(a)} Then, there exists one and only one bilinear form $B^{\prime
}:V_{G}\times W_{G}\rightarrow k$ satisfying%
\[
B^{\prime}\left(  \overline{v},\overline{w}\right)  =B\left(  \Lambda
v,w\right)  =B\left(  v,\Lambda w\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}v\in V\text{ and }w\in W\text{.}%
\]
(Here, $\overline{v}$ denotes the projection of $v$ onto $V_{G}$, and
$\overline{w}$ denotes the projection of $w$ onto $W_{G}$.)

\textbf{(b)} Assume that $\left\vert G\right\vert $ is invertible in $k$ (in
other words, assume that $\operatorname*{char}k$ is either $0$ or coprime to
$\left\vert G\right\vert $). If the form $B$ is nondegenerate, then this form
$B^{\prime}$ is nondegenerate, too.
\end{lemma}

\textit{Proof of Lemma \ref{lem.bilform}.} Every $h\in G$ satisfies%
\begin{align*}
h\Lambda &  =h\sum\limits_{g\in G}g\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\Lambda=\sum\limits_{g\in G}g\right) \\
&  =\sum\limits_{g\in G}hg=\sum\limits_{i\in G}i\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we substituted }i\text{ for }hg\text{ in the sum, since the map}\\
G\rightarrow G,\ g\mapsto hg\text{ is a bijection}%
\end{array}
\right) \\
&  =\sum\limits_{g\in G}g=\Lambda
\end{align*}
and similarly $\Lambda h=\Lambda$.

Also,%
\begin{align*}
\sum\limits_{g\in G}g^{-1}  &  =\sum\limits_{g\in G}%
g\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we substituted }g\text{ for }g^{-1}\text{ in the sum, since the
map}\\
G\rightarrow G,\ g\mapsto g^{-1}\text{ is a bijection}%
\end{array}
\right) \\
&  =\Lambda.
\end{align*}


We further notice that the group $G$ acts trivially on the $G$-modules $k$ and
$W_{G}$ (this follows from the definitions of these modules), and thus $G$
acts trivially on $\operatorname*{Hom}\left(  W_{G},k\right)  $ as well.

For every $v\in V$, the map%
\[
W\rightarrow k,\ \ \ \ \ \ \ \ \ \ w\mapsto B\left(  \Lambda v,w\right)
\]
is clearly $G$-equivariant (since it maps $hw$ to%
\begin{align*}
B\left(  \underbrace{\Lambda}_{=h\Lambda}v,hw\right)   &  =B\left(  h\Lambda
v,hw\right)  =B\left(  \Lambda v,w\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }B\text{ is }G\text{-invariant}\right) \\
&  =hB\left(  \Lambda v,w\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}G\text{ acts trivially on }k\right)
\end{align*}
for every $h\in G$ and $w\in W$), and thus descends to a map%
\[
W_{G}\rightarrow k_{G},\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto\overline
{B\left(  \Lambda v,w\right)  }.
\]
Hence, we have obtained a map%
\[
V\rightarrow\operatorname*{Hom}\left(  W_{G},k_{G}\right)
,\ \ \ \ \ \ \ \ \ \ v\mapsto\left(  \overline{w}\mapsto\overline{B\left(
\Lambda v,w\right)  }\right)  .
\]
Since $k_{G}=k$ (because $G$ acts trivially on $k$), this rewrites as a map%
\[
V\rightarrow\operatorname*{Hom}\left(  W_{G},k\right)
,\ \ \ \ \ \ \ \ \ \ v\mapsto\left(  \overline{w}\mapsto B\left(  \Lambda
v,w\right)  \right)  .
\]


This map, too, is $G$-equivariant (since it maps $hv$ to the map%
\begin{align*}
&  \left(  W_{G}\rightarrow k,\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto B\left(
\underbrace{\Lambda h}_{=\Lambda}v,w\right)  \right) \\
&  =\left(  W_{G}\rightarrow k,\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto
B\left(  \Lambda v,w\right)  \right)  =h\left(  W_{G}\rightarrow
k,\ \ \ \ \ \ \ \ \ \ \overline{w}\mapsto B\left(  \Lambda v,w\right)  \right)
\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }G\text{ acts trivially on
}\operatorname*{Hom}\left(  W_{G},k\right)  \right)
\end{align*}
for every $h\in G$ and $v\in V$). Thus, it descends to a map%
\[
V_{G}\rightarrow\left(  \operatorname*{Hom}\left(  W_{G},k\right)  \right)
_{G},\ \ \ \ \ \ \ \ \ \ \overline{v}\mapsto\overline{\left(  \overline
{w}\mapsto B\left(  \Lambda v,w\right)  \right)  }.
\]
Since $\left(  \operatorname*{Hom}\left(  W_{G},k\right)  \right)
_{G}=\operatorname*{Hom}\left(  W_{G},k\right)  $ (because $G$ acts trivially
on $\operatorname*{Hom}\left(  W_{G},k\right)  $), this rewrites as a map%
\[
V_{G}\rightarrow\operatorname*{Hom}\left(  W_{G},k\right)
,\ \ \ \ \ \ \ \ \ \ \overline{v}\mapsto\left(  \overline{w}\mapsto B\left(
\Lambda v,w\right)  \right)  .
\]


This map can be rewritten as a bilinear form $V_{G}\times W_{G}\rightarrow k$
which maps $\left(  \overline{v},\overline{w}\right)  $ to $B\left(  \Lambda
v,w\right)  $ for all $v\in V$ and $w\in W$. Since
\begin{align*}
B\left(  \Lambda v,w\right)   &  =B\left(  \sum\limits_{g\in G}gv,w\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\Lambda=\sum\limits_{g\in G}g\right)
\\
&  =\sum\limits_{g\in G}B\left(  gv,\underbrace{w}_{=gg^{-1}w}\right)
=\sum\limits_{g\in G}\underbrace{B\left(  gv,gg^{-1}w\right)  }%
_{\substack{=B\left(  v,g^{-1}w\right)  \\\text{(since }B\text{ is
}G\text{-invariant)}}}=\sum\limits_{g\in G}B\left(  v,g^{-1}w\right) \\
&  =B\left(  v,\underbrace{\sum\limits_{g\in G}g^{-1}}_{=\Lambda}w\right)
=B\left(  v,\Lambda w\right)
\end{align*}
for all $v\in V$ and $w\in W$, we have thus proven that there exists a
bilinear form $B^{\prime}:V_{G}\times W_{G}\rightarrow k$ satisfying%
\[
B^{\prime}\left(  \overline{v},\overline{w}\right)  =B\left(  \Lambda
v,w\right)  =B\left(  v,\Lambda w\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}v\in V\text{ and }w\in W\text{.}%
\]
The uniqueness of such a form is self-evident. This proves Lemma
\ref{lem.bilform} \textbf{(a)}.

\textbf{(b)} Assume that $\left\vert G\right\vert $ is invertible in $k$.
Assume that the form $B$ is nondegenerate.

Let $p\in V_{G}$ be such that $B^{\prime}\left(  p,W_{G}\right)  =0$. Since
$p\in V_{G}$, there exists some $v\in V$ such that $p=\overline{v}$. Consider
this $v$. Then, every $w\in W$ satisfies $B\left(  \Lambda v,w\right)  =0$
(since $B\left(  \Lambda v,w\right)  =B\left(  \underbrace{\overline{v}}%
_{=p},\underbrace{\overline{w}}_{\in W_{G}}\right)  \in B^{\prime}\left(
p,W_{G}\right)  =0$). Hence, $\Lambda v=0$ (since $B$ is nondegenerate).

But since the projection of $V$ to $V_{G}$ is a $G$-module map, we have
\begin{align*}
\overline{\Lambda v}  &  =\Lambda\overline{v}=\sum\limits_{g\in G}%
\underbrace{g\overline{v}}_{\substack{=\overline{v}\\\text{(since }G\text{
acts}\\\text{trivially on }V_{G}\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }\Lambda=\sum\limits_{g\in G}g\right) \\
&  =\sum\limits_{g\in G}\overline{v}=\left\vert G\right\vert \overline{v}.
\end{align*}
Since $\left\vert G\right\vert $ is invertible in $k$, this yields
$\overline{v}=\dfrac{1}{\left\vert G\right\vert }\overline{\Lambda v}=0$
(since $\Lambda v=0$), so that $p=\overline{v}=0$.

We have thus shown that every $p\in V_{G}$ such that $B^{\prime}\left(
p,W_{G}\right)  =0$ must satisfy $p=0$. In other words, the form $B^{\prime}$
is nondegenerate. Lemma \ref{lem.bilform} \textbf{(b)} is proven.

\textit{Proof of Theorem \ref{thm.invformnondeg}.} As vector spaces,
$M_{\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)  v_{\lambda}^{+}\cong
U\left(  \mathfrak{n}_{-}\right)  $ (where the isomorphism maps $v_{\lambda
}^{+}$ to $1$) and $M_{-\lambda}^{-}=U\left(  \mathfrak{n}_{+}\right)
v_{-\lambda}^{-}\cong U\left(  \mathfrak{n}_{+}\right)  $ (where the
isomorphism maps $v_{-\lambda}^{-}$ to $1$). Thus, the bilinear form $\left(
\cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow
\mathbb{C}$ can be considered as a bilinear form $U\left(  \mathfrak{n}%
_{-}\right)  \times U\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$.

Fix $n\in\mathbb{N}$.

Let $\left(  \cdot,\cdot\right)  _{\lambda,n}$ denote the restriction of our
form $\left(  \cdot,\cdot\right)  :U\left(  \mathfrak{n}_{-}\right)  \times
U\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ to $U\left(
\mathfrak{n}_{-}\right)  \left[  -n\right]  \times U\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  $. In order to prove Theorem
\ref{thm.invformnondeg}, it is enough to prove that for every $n\in\mathbb{N}%
$, this form $\left(  \cdot,\cdot\right)  _{\lambda,n}$ is nondegenerate for
generic $\lambda$. We now introduce a $\mathbb{C}$-bilinear form:

\begin{proposition}
\label{prop.lambda_k}For every $k\in\mathbb{N}$, there exists one and only one
$\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)
\times S^{k}\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ by
\begin{align}
\lambda_{k}\left(  \alpha_{1}\alpha_{2}...\alpha_{k},\beta_{1}\beta
_{2}...\beta_{k}\right)   &  =\sum\limits_{\sigma\in S_{k}}\lambda\left(
\left[  \alpha_{1},\beta_{\sigma\left(  1\right)  }\right]  \right)
\lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  \alpha_{k},\beta_{\sigma\left(  k\right)
}\right]  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for all }\alpha_{1},\alpha_{2},...,\alpha_{k}%
\in\mathfrak{n}_{-}\text{ and }\beta_{1},\beta_{2},...,\beta_{k}%
\in\mathfrak{n}_{+}. \label{thm.invformnondeg.pf.lambda}%
\end{align}

\end{proposition}

Here, the map $\lambda:\mathfrak{g}_{0}\rightarrow\mathbb{C}$ is extended to a
linear map $\lambda:\mathfrak{g}\rightarrow\mathbb{C}$ by composing it with
the canonical projection $\mathfrak{g}\rightarrow\mathfrak{g}_{0}$.

\textit{First proof of Proposition \ref{prop.lambda_k} (sketched).} Let
$k\in\mathbb{N}$. The value of
\[
\sum\limits_{\sigma\in S_{k}}\lambda\left(  \left[  \alpha_{1},\beta
_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[  \alpha
_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{k},\beta_{\sigma\left(  k\right)  }\right]  \right)
\]
depends linearly on each of the $\alpha_{1},\alpha_{2},...,\alpha_{k}$ and
$\beta_{1},\beta_{2},...,\beta_{k}$, and is invariant under any permutation of
the $\alpha_{1},\alpha_{2},...,\alpha_{k}$ and under any permutation of the
$\beta_{1},\beta_{2},...,\beta_{k}$ (as is easily checked). This readily shows
that we can indeed define a $\mathbb{C}$-bilinear form $\lambda_{k}%
:S^{k}\left(  \mathfrak{n}_{-}\right)  \times S^{k}\left(  \mathfrak{n}%
_{+}\right)  \rightarrow\mathbb{C}$ by (\ref{thm.invformnondeg.pf.lambda}).
This proves Proposition \ref{prop.lambda_k}.

\textit{Second proof of Proposition \ref{prop.lambda_k}.} Let $G=S_{k}$. Let
$\Lambda\in\mathbb{C}\left[  G\right]  $ be the element $\sum\limits_{g\in
S_{k}}g=\sum\limits_{\sigma\in S_{k}}\sigma=\sum\limits_{\sigma\in S_{k}%
}\sigma^{-1}$. Let $V$ and $W$ be the canonical representations $\mathfrak{n}%
_{-}^{\otimes k}$ and $\mathfrak{n}_{+}^{\otimes k}$ of $S_{k}$ (where $S_{k}$
acts by permuting the tensorands). Let $B:V\times W\rightarrow\mathbb{C}$ be
the $\mathbb{C}$-bilinear form defined as the $k$-th tensor power of the
$\mathbb{C}$-bilinear form $\mathfrak{n}_{-}\times\mathfrak{n}_{+}%
\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)  \mapsto\lambda\left(
\left[  \alpha,\beta\right]  \right)  $. It is easy to see that this form is
$S_{k}$-invariant (in fact, more generally, the $k$-th tensor power of any
bilinear form is $S_{k}$-invariant). Thus, Lemma \ref{lem.bilform}
\textbf{(a)} (applied to $\mathbb{C}$ instead of $k$) yields that there exists
one and only one bilinear form $B^{\prime}:V_{G}\times W_{G}\rightarrow
\mathbb{C}$ satisfying%
\begin{equation}
B^{\prime}\left(  \overline{v},\overline{w}\right)  =B\left(  \Lambda
v,w\right)  =B\left(  v,\Lambda w\right)  \ \ \ \ \ \ \ \ \ \ \text{for all
}v\in V\text{ and }w\in W \label{thm.invformnondeg.pf.B'}%
\end{equation}
(where $\overline{v}$ denotes the projection of $v$ onto $V_{G}=V_{S_{k}%
}=S^{k}\left(  \mathfrak{n}_{-}\right)  $, and $\overline{w}$ denotes the
projection of $w$ onto $W_{G}=W_{S_{k}}=S^{k}\left(  \mathfrak{n}_{+}\right)
$). Consider this form $B^{\prime}$. All $\alpha_{1},\alpha_{2},...,\alpha
_{k}\in\mathfrak{n}_{-}$ and $\beta_{1},\beta_{2},...,\beta_{k}\in
\mathfrak{n}_{+}$ satisfy%
\begin{align*}
&  B^{\prime}\left(  \alpha_{1}\alpha_{2}...\alpha_{k},\beta_{1}\beta
_{2}...\beta_{k}\right) \\
&  =B^{\prime}\left(  \overline{\alpha_{1}\otimes\alpha_{2}\otimes
...\otimes\alpha_{k}},\overline{\beta_{1}\otimes\beta_{2}\otimes
...\otimes\beta_{k}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\alpha_{1}\alpha_{2}...\alpha
_{k}=\overline{\alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}}\text{
and }\beta_{1}\beta_{2}...\beta_{k}=\overline{\beta_{1}\otimes\beta_{2}%
\otimes...\otimes\beta_{k}}\right) \\
&  =B\left(  \alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}%
,\Lambda\left(  \beta_{1}\otimes\beta_{2}\otimes...\otimes\beta_{k}\right)
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{thm.invformnondeg.pf.B'}),
applied to }v=\alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}\text{ and
}w=\beta_{1}\otimes\beta_{2}\otimes...\otimes\beta_{k}\right) \\
&  =B\left(  \alpha_{1}\otimes\alpha_{2}\otimes...\otimes\alpha_{k}%
,\sum\limits_{\sigma\in S_{k}}\beta_{\sigma\left(  1\right)  }\otimes
\beta_{\sigma\left(  2\right)  }\otimes...\otimes\beta_{\sigma\left(
k\right)  }\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\Lambda=\sum\limits_{\sigma\in S_{k}}\sigma^{-1}\text{ yields
}\Lambda\left(  \beta_{1}\otimes\beta_{2}\otimes...\otimes\beta_{k}\right)
=\sum\limits_{\sigma\in S_{k}}\underbrace{\sigma^{-1}\left(  \beta_{1}%
\otimes\beta_{2}\otimes...\otimes\beta_{k}\right)  }_{=\beta_{\sigma\left(
1\right)  }\otimes\beta_{\sigma\left(  2\right)  }\otimes...\otimes
\beta_{\sigma\left(  k\right)  }}\\
=\sum\limits_{\sigma\in S_{k}}\beta_{\sigma\left(  1\right)  }\otimes
\beta_{\sigma\left(  2\right)  }\otimes...\otimes\beta_{\sigma\left(
k\right)  }%
\end{array}
\right) \\
&  =\sum\limits_{\sigma\in S_{k}}\underbrace{B\left(  \alpha_{1}\otimes
\alpha_{2}\otimes...\otimes\alpha_{k},\beta_{\sigma\left(  1\right)  }%
\otimes\beta_{\sigma\left(  2\right)  }\otimes...\otimes\beta_{\sigma\left(
k\right)  }\right)  }_{\substack{=\lambda\left(  \left[  \alpha_{1}%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{k},\beta_{\sigma\left(  k\right)  }\right]  \right)
\\\text{(since }B\text{ is the }k\text{-th tensor power of the }%
\mathbb{C}\text{-bilinear form }\mathfrak{n}_{-}\times\mathfrak{n}%
_{+}\rightarrow\mathbb{C},\ \left(  \alpha,\beta\right)  \mapsto\lambda\left(
\left[  \alpha,\beta\right]  \right)  \text{)}}}\\
&  =\sum\limits_{\sigma\in S_{k}}\lambda\left(  \left[  \alpha_{1}%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(
\left[  \alpha_{k},\beta_{\sigma\left(  k\right)  }\right]  \right)  .
\end{align*}
Thus, there exists a $\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(
\mathfrak{n}_{-}\right)  \times S^{k}\left(  \mathfrak{n}_{+}\right)
\rightarrow\mathbb{C}$ satisfying (\ref{thm.invformnondeg.pf.lambda}). But
such a form is also seen to be unique. Hence, we can indeed define a
$\mathbb{C}$-bilinear form $\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)
\times S^{k}\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ by
(\ref{thm.invformnondeg.pf.lambda}). And, moreover,%
\begin{equation}
\text{this form }\lambda_{k}\text{ is the form }B^{\prime}\text{ satisfying
(\ref{thm.invformnondeg.pf.B'}).} \label{thm.invformnondeg.pf.B'=l_k}%
\end{equation}
Proposition \ref{prop.lambda_k} is thus proven.

For every $k\in\mathbb{N}$, let $\lambda_{k}:S^{k}\left(  \mathfrak{n}%
_{-}\right)  \times S^{k}\left(  \mathfrak{n}_{+}\right)  \rightarrow
\mathbb{C}$ be the $\mathbb{C}$-bilinear form whose existence and uniqueness
is guaranteed by Proposition \ref{prop.lambda_k}. These forms can be added
together, resulting in a bilinear form $\bigoplus\limits_{k\geq0}\lambda
_{k}:S\left(  \mathfrak{n}_{-}\right)  \times S\left(  \mathfrak{n}%
_{+}\right)  \rightarrow\mathbb{C}$. This form is graded (where the grading on
$S\left(  \mathfrak{n}_{-}\right)  $ and $S\left(  \mathfrak{n}_{+}\right)  $
is not the one that gives the $k$-th symmetric power the degree $k$ for every
$k\in\mathbb{N}$, but is the one induced by the grading on $\mathfrak{n}_{-}$
and $\mathfrak{n}_{+}$). Denote this form by $\left(  \cdot,\cdot\right)
_{\lambda}^{\circ}$.

\begin{lemma}
\label{lem.lambda_k}Let $\lambda\in\mathfrak{h}^{\ast}$ be such that the
$\mathbb{C}$-bilinear form $\mathfrak{n}_{-}\times\mathfrak{n}_{+}%
\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)  \mapsto\lambda\left(
\left[  \alpha,\beta\right]  \right)  $ is nondegenerate. Then, the form
$\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$ is nondegenerate.
\end{lemma}

\textit{Proof of Lemma \ref{lem.lambda_k}.} Let $k\in\mathbb{N}$. Introduce
the same notations as in the Second proof of Proposition \ref{prop.lambda_k}.

The $\mathbb{C}$-bilinear form $\mathfrak{n}_{-}\times\mathfrak{n}%
_{+}\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)  \mapsto
\lambda\left(  \left[  \alpha,\beta\right]  \right)  $ is nondegenerate. Thus,
the $k$-th tensor power of this form is also nondegenerate (since all tensor
powers of a nondegenerate form are always nondegenerate). But the $k$-th
tensor power of this form is $B$. Thus, $B$ is nondegenerate. Hence, Lemma
\ref{lem.bilform} \textbf{(b)} yields that the form $B^{\prime}$ is
nondegenerate. Due to (\ref{thm.invformnondeg.pf.B'=l_k}), this yields that
the form $\lambda_{k}$ is nondegenerate.

Forget that we fixed $k$. We thus have shown that for every $k\in\mathbb{N}$,
the form $\lambda_{k}$ is nondegenerate. Thus, the direct sum $\bigoplus
\limits_{k\geq0}\lambda_{k}$ of these forms is also nondegenerate. Since
$\bigoplus\limits_{k\geq0}\lambda_{k}=\left(  \cdot,\cdot\right)  _{\lambda
}^{\circ}$, this yields that $\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}$
is nondegenerate. This proves Lemma \ref{lem.lambda_k}.

Define $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}:S\left(
\mathfrak{n}_{-}\right)  \left[  -n\right]  \times S\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  \rightarrow\mathbb{C}$ to be the restriction of
this form $\left(  \cdot,\cdot\right)  _{\lambda}^{\circ}=\bigoplus
\limits_{k\geq0}\lambda_{k}:S\left(  \mathfrak{n}_{-}\right)  \times S\left(
\mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}$ to $S\left(  \mathfrak{n}%
_{-}\right)  \left[  -n\right]  \times S\left(  \mathfrak{n}_{+}\right)
\left[  n\right]  $. We now need the following strengthening of Lemma
\ref{lem.lambda_k}:

\begin{lemma}
\label{lem.lambda_k.2}Let $n\in\mathbb{N}$ and $\lambda\in\mathfrak{h}^{\ast}$
be such that the bilinear form%
\[
\mathfrak{g}_{-k}\times\mathfrak{g}_{k}\rightarrow\mathbb{C}%
,\ \ \ \ \ \ \ \ \ \ \left(  a,b\right)  \mapsto\lambda\left(  \left[
a,b\right]  \right)
\]
is nondegenerate for every $k\in\left\{  1,2,...,n\right\}  $. Then, the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ must also be nondegenerate.
\end{lemma}

\textit{Proof of Lemma \ref{lem.lambda_k.2}.} For Lemma \ref{lem.lambda_k} to
hold, we did not need $\mathfrak{g}$ to be a graded Lie algebra; we only
needed that $\mathfrak{g}$ is a graded vector space with a well-defined
bilinear map $\left[  \cdot,\cdot\right]  :\mathfrak{g}_{-k}\times
\mathfrak{g}_{k}\rightarrow\mathbb{C}$ for every positive integer $k$. This is
a rather weak condition, and holds not only for $\mathfrak{g}$, but also for
the graded subspace $\mathfrak{g}_{-n}\oplus\mathfrak{g}_{-n+1}\oplus
...\oplus\mathfrak{g}_{n}$ of $\mathfrak{g}$. Denote this graded subspace
$\mathfrak{g}_{-n}\oplus\mathfrak{g}_{-n+1}\oplus...\oplus\mathfrak{g}_{n}$ by
$\mathfrak{g}^{\prime}$, and let $\mathfrak{n}_{-}^{\prime}\oplus
\mathfrak{h}^{\prime}\oplus\mathfrak{n}_{+}^{\prime}$ be its triangular
decomposition (thus, $\mathfrak{n}_{-}^{\prime}=\mathfrak{g}_{-n}%
\oplus\mathfrak{g}_{-n+1}\oplus...\oplus\mathfrak{g}_{-1}$, $\mathfrak{h}%
^{\prime}=\mathfrak{g}_{0}=\mathfrak{h}$ and $\mathfrak{n}_{+}^{\prime
}=\mathfrak{g}_{1}\oplus\mathfrak{g}_{2}\oplus...\oplus\mathfrak{g}_{n}$). The
$\mathbb{C}$-bilinear form $\mathfrak{n}_{-}^{\prime}\times\mathfrak{n}%
_{+}^{\prime}\rightarrow\mathbb{C},$ $\left(  \alpha,\beta\right)
\mapsto\lambda\left(  \left[  \alpha,\beta\right]  \right)  $ is nondegenerate
(because the bilinear form $\mathfrak{g}_{-k}\times\mathfrak{g}_{k}%
\rightarrow\mathbb{C},\ \left(  a,b\right)  \mapsto\lambda\left(  \left[
a,b\right]  \right)  $ is nondegenerate for every $k\in\left\{
1,2,...,n\right\}  $). Hence, by Lemma \ref{lem.lambda_k}, the form $\left(
\cdot,\cdot\right)  _{\lambda}^{\circ}$ \textit{defined for }$\mathfrak{g}%
^{\prime}$ \textit{instead of }$\mathfrak{g}$ is nondegenerate. Since this
form is of degree $0$, the restriction $\left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}$ of this form to $S\left(  \mathfrak{n}_{-}^{\prime
}\right)  \left[  -n\right]  \times S\left(  \mathfrak{n}_{+}^{\prime}\right)
\left[  n\right]  $ must also be nondegenerate\footnote{This is because if $V$
and $W$ are two graded vector spaces, and $\phi:V\times W\rightarrow
\mathbb{C}$ is a nondegenerate bilinear form of degree $0$, then for every
$n\in\mathbb{Z}$, the restriction of $\phi$ to $V\left[  -n\right]  \times
W\left[  n\right]  $ must also be nondegenerate.}. But since $S\left(
\mathfrak{n}_{+}^{\prime}\right)  \left[  n\right]  =S\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  $\ \ \ \ \footnote{\textit{Proof.} Since
$\mathfrak{n}_{+}=\sum\limits_{i\geq1}\mathfrak{g}_{i}$, we have $S\left(
\mathfrak{n}_{+}\right)  =\sum\limits_{k\in\mathbb{N}}\sum
\limits_{\substack{\left(  i_{1},i_{2},...,i_{k}\right)  \in\mathbb{N}%
^{k};\\\text{each }i_{j}\geq1}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}%
}...\mathfrak{g}_{i_{k}}$ and thus%
\[
S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  =\sum\limits_{k\in
\mathbb{N}}\sum\limits_{\substack{\left(  i_{1},i_{2},...,i_{k}\right)
\in\mathbb{N}^{k};\\\text{each }i_{j}\geq1;\\i_{1}+i_{2}+...+i_{k}%
=n}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}}%
\]
(since $\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}%
}\subseteq S\left(  \mathfrak{n}_{+}\right)  \left[  i_{1}+i_{2}%
+...+i_{k}\right]  $ for all $\left(  i_{1},i_{2},...,i_{k}\right)
\in\mathbb{N}^{k}$). Similarly,%
\[
S\left(  \mathfrak{n}_{+}^{\prime}\right)  \left[  n\right]  =\sum
\limits_{k\in\mathbb{N}}\sum\limits_{\substack{\left(  i_{1},i_{2}%
,...,i_{k}\right)  \in\mathbb{N}^{k};\\\text{each }i_{j}\geq1;\\\text{each
}\left\vert i_{j}\right\vert \leq n\\i_{1}+i_{2}+...+i_{k}=n}}\mathfrak{g}%
_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}}%
\]
(because $\mathfrak{g}^{\prime}$ is obtained from $\mathfrak{g}$ by removing
all $\mathfrak{g}_{i}$ with $\left\vert i\right\vert >n$). Thus,%
\begin{align*}
S\left(  \mathfrak{n}_{+}^{\prime}\right)  \left[  n\right]   &
=\sum\limits_{k\in\mathbb{N}}\sum\limits_{\substack{\left(  i_{1}%
,i_{2},...,i_{k}\right)  \in\mathbb{N}^{k};\\\text{each }i_{j}\geq
1;\\\text{each }\left\vert i_{j}\right\vert \leq n\\i_{1}+i_{2}+...+i_{k}%
=n}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}}...\mathfrak{g}_{i_{k}}%
=\sum\limits_{k\in\mathbb{N}}\sum\limits_{\substack{\left(  i_{1}%
,i_{2},...,i_{k}\right)  \in\mathbb{N}^{k};\\\text{each }i_{j}\geq
1;\\i_{1}+i_{2}+...+i_{k}=n}}\mathfrak{g}_{i_{1}}\mathfrak{g}_{i_{2}%
}...\mathfrak{g}_{i_{k}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we removed the condition }\left(  \text{each }\left\vert
i_{j}\right\vert \leq n\right)  \text{, because it was redundant}\\
\text{(since every }\left(  i_{1},i_{2},...,i_{k}\right)  \in\mathbb{N}%
^{k}\text{ satisfying }i_{1}+i_{2}+...+i_{k}=n\text{ automatically}\\
\text{satisfies }\left(  \text{each }\left\vert i_{j}\right\vert \leq
n\right)  \text{)}%
\end{array}
\right) \\
&  =S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  ,
\end{align*}
qed.} and $S\left(  \mathfrak{n}_{-}^{\prime}\right)  \left[  -n\right]
=S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  $\ \ \ \ \footnote{for
analogous reasons}, this restriction is exactly our form $\left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)  \left[
-n\right]  \times S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]
\rightarrow\mathbb{C}$ (in fact, the form is clearly given by the same
formula). Thus we have shown that our form $\left(  \cdot,\cdot\right)
_{\lambda,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]
\times S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  \rightarrow
\mathbb{C}$ is nondegenerate. Lemma \ref{lem.lambda_k.2} is proven.

Fix bases of $S\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  $,
$S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]  $, $U\left(
\mathfrak{n}_{-}\right)  \left[  -n\right]  $ and $U\left(  \mathfrak{n}%
_{+}\right)  \left[  n\right]  $. Then, for every $\lambda\in\mathfrak{h}%
^{\ast}$, the bilinear forms $\left(  \cdot,\cdot\right)  _{\lambda
,n}:U\left(  \mathfrak{n}_{-}\right)  \left[  -n\right]  \times U\left(
\mathfrak{n}_{+}\right)  \left[  n\right]  \rightarrow\mathbb{C}$ and $\left(
\cdot,\cdot\right)  _{\lambda,n}^{\circ}:S\left(  \mathfrak{n}_{-}\right)
\left[  -n\right]  \times S\left(  \mathfrak{n}_{+}\right)  \left[  n\right]
\rightarrow\mathbb{C}$ are represented by matrices with respect to these
bases. These matrices are not in general square, \textit{but they are square
if }$\dim\left(  \mathfrak{g}_{n}\right)  =\dim\left(  \mathfrak{g}%
_{-n}\right)  $ \textit{for every integer }$n>0$ (this condition is
automatically satisfied when $\mathfrak{g}$ is a nondegenerate $\mathbb{Z}%
$-graded Lie algebra, but of course not only then). In this case, we can talk
about the determinants of these forms (because we can identify these forms
with the matrices that represent them). These determinants will depend on the
choice of basis, but since a change of basis always multiplies the determinant
by a \textit{nonzero} scalar, the property of these determinants to be zero or
nonzero will \textit{not} depend on the choice of basis.

We now need the following fact:

\begin{proposition}
\label{prop.det.US}Let $n\in\mathbb{N}$ be positive. Assume that
$\mathfrak{g}$ is a nondegenerate $\mathbb{Z}$-graded Lie algebra. (Actually,
we could weaken the condition \textbf{(3)} in Definition
\ref{def.gradLienondeg} to the condition that $\dim\left(  \mathfrak{g}%
_{n}\right)  =\dim\left(  \mathfrak{g}_{-n}\right)  $ for every integer $n>0$.)

The determinants $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}\right)
$ and $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}\right)  $
are polynomials in $\lambda$ (this means: polynomials in the coordinates of
$\lambda$ with respect to any basis of $\mathfrak{h}^{\ast}$). The leading
term of the polynomial $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda
,n}\right)  $ is $\det\left(  \left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ
}\right)  $, up to multiplication by a nonzero scalar.

(Here, the "leading term" of a polynomial means its highest nonzero graded
component. It may (and usually will) contain more than one monomial.)
\end{proposition}

\textit{Proof of Proposition \ref{prop.det.US}.} Consider the $\mathbb{C}%
\left[  \varepsilon\right]  $-Lie algebra $\mathfrak{g}\left[  \varepsilon
\right]  $ (this is defined as $\mathfrak{g}\otimes\mathbb{C}\left[
\varepsilon\right]  $, where $\mathbb{C}\left[  \varepsilon\right]  $ is the
$\mathbb{C}$-algebra of all polynomials in an indeterminate $\varepsilon$).

Let $\widetilde{\mathfrak{g}}\subseteq\mathfrak{g}\left[  \varepsilon\right]
$ be the Lie subalgebra $\bigoplus\limits_{i\neq0}\varepsilon\mathfrak{g}%
_{i}\left[  \varepsilon\right]  \oplus\varepsilon^{2}\mathfrak{g}_{0}\left[
\varepsilon\right]  $. Note that this $\mathbb{C}\left[  \varepsilon\right]
$-Lie algebra $\widetilde{\mathfrak{g}}$ is graded (in the obvious way:
$\widetilde{\mathfrak{g}}\left[  i\right]  =\left\{
\begin{array}
[c]{c}%
\varepsilon\mathfrak{g}_{i}\left[  \varepsilon\right]
,\ \ \ \ \ \ \ \ \ \ \text{if }i\neq0;\\
\varepsilon^{2}\mathfrak{g}_{0}\left[  \varepsilon\right]
,\ \ \ \ \ \ \ \ \ \ \text{if }i=0
\end{array}
\right.  $), and has the property that each of the $\mathbb{C}\left[
\varepsilon\right]  $-modules $\widetilde{\mathfrak{g}}_{-}=\bigoplus
\limits_{i<0}\varepsilon\mathfrak{g}_{i}\left[  \varepsilon\right]  $,
$\widetilde{\mathfrak{g}}_{0}=\varepsilon^{2}\mathfrak{g}_{0}\left[
\varepsilon\right]  $ and $\widetilde{\mathfrak{g}}_{+}=\bigoplus
\limits_{i>0}\varepsilon\mathfrak{g}_{i}\left[  \varepsilon\right]  $ is a
free $\mathbb{C}\left[  \varepsilon\right]  $-module. Hence, even though
$\mathbb{C}\left[  \varepsilon\right]  $ is not a field, we can apply our
previous results to it - most importantly, Proposition \ref{prop.invform}
(because of Remark \ref{rmk.invform.1}).

For every nonzero $\alpha\in\mathbb{C}$, we have $\widetilde{\mathfrak{g}%
}\diagup\left(  \varepsilon-\alpha\right)  \cong\mathfrak{g}$%
\ \ \ \ \footnote{In fact, a Lie algebra isomorphism $\mathfrak{g}%
\rightarrow\widetilde{\mathfrak{g}}\diagup\left(  \varepsilon-\alpha\right)  $
is given by $x\mapsto\overline{\dfrac{1}{\alpha^{2}}\varepsilon^{2}x}$.}.
(Here, $\widetilde{\mathfrak{g}}\diagup J$ means $\widetilde{\mathfrak{g}%
}\diagup\left(  J\widetilde{\mathfrak{g}}\right)  $ for every ideal $J$ of
$\mathbb{C}\left[  \varepsilon\right]  $.)

But $\widetilde{\mathfrak{g}}\diagup\left(  \varepsilon\right)  \cong%
\overline{\mathfrak{g}}$, where the Lie algebra $\overline{\mathfrak{g}}$ has
the following description: As a vector space, $\overline{\mathfrak{g}%
}=\mathfrak{g}$, but the bracket on $\overline{\mathfrak{g}}$ is given by%
\begin{align*}
\left[  \cdot,\cdot\right]  :\overline{\mathfrak{g}}_{i}\otimes\overline
{\mathfrak{g}}_{j}\rightarrow\overline{\mathfrak{g}}_{i+j}\text{ }  &
\text{is }\text{zero if }i+j\neq0\text{,}\\
&  \text{and is the usual Lie bracket if }i+j=0\text{.}%
\end{align*}
\footnote{In fact, a Lie algebra isomorphism $\overline{\mathfrak{g}%
}\rightarrow\widetilde{\mathfrak{g}}\diagup\left(  \varepsilon\right)  $ is
given by%
\begin{align*}
x  &  \mapsto\overline{\varepsilon x}\ \ \ \ \ \ \ \ \ \ \text{for all }%
x\in\mathfrak{g}_{i}\text{ with }i\neq0;\\
x  &  \mapsto\overline{\varepsilon^{2}x}\ \ \ \ \ \ \ \ \ \ \text{for all
}x\in\mathfrak{g}_{0}.
\end{align*}
This is proven easily (use that $\mathfrak{g}_{0}$ is abelian).}

We denote by $\overline{\mathfrak{n}_{-}}$, $\overline{\mathfrak{n}_{+}}$ and
$\overline{\mathfrak{h}}$ the vector subspaces $\mathfrak{n}_{-}$,
$\mathfrak{n}_{+}$ and $\mathfrak{h}$ of $\mathfrak{g}$, considered as
subspaces of $\overline{\mathfrak{g}}$. So when we speak of $\left[
\overline{\mathfrak{n}_{-}},\overline{\mathfrak{h}}\right]  $ (for example),
we mean the Lie bracket in $\overline{\mathfrak{g}}$, not in $\mathfrak{g}$.

It is very easy to see (from the definition of $\overline{\mathfrak{g}}$) that
$\left[  \overline{\mathfrak{n}_{-}},\overline{\mathfrak{n}_{-}}\right]  =0$,
$\left[  \overline{\mathfrak{n}_{+}},\overline{\mathfrak{n}_{+}}\right]  =0$,
$\left[  \overline{\mathfrak{n}_{-}},\overline{\mathfrak{n}_{+}}\right]
=\left[  \overline{\mathfrak{n}_{+}},\overline{\mathfrak{n}_{-}}\right]
\subseteq\overline{\mathfrak{h}}$ and that $\overline{\mathfrak{h}}\subseteq
Z\left(  \overline{\mathfrak{g}}\right)  $.

Since $\left[  \overline{\mathfrak{n}_{-}},\overline{\mathfrak{n}_{-}}\right]
=0$, the Lie algebra $\overline{\mathfrak{n}_{-}}$ is abelian, so that
$U\left(  \overline{\mathfrak{n}_{-}}\right)  =S\left(  \overline
{\mathfrak{n}_{-}}\right)  =S\left(  \mathfrak{n}_{-}\right)  $. Similarly,
$U\left(  \overline{\mathfrak{n}_{+}}\right)  =S\left(  \overline
{\mathfrak{n}_{+}}\right)  =S\left(  \mathfrak{n}_{+}\right)  $.

Let $M_{\lambda}^{+\overline{\mathfrak{g}}}$ denote the Verma highest-weight
module of $\left(  \overline{\mathfrak{g}},\lambda\right)  $ (not of $\left(
\mathfrak{g},\lambda\right)  $ !), and let $M_{-\lambda}^{-\overline
{\mathfrak{g}}}$ denote the Verma lowest-weight module of $\left(
\overline{\mathfrak{g}},-\lambda\right)  $ (not of $\left(  \mathfrak{g}%
,-\lambda\right)  $ !).

We now denote the forms $\left(  \cdot,\cdot\right)  _{\lambda}$ and $\left(
\cdot,\cdot\right)  _{\lambda}^{\circ}$ which we defined for our Lie algebra
$\mathfrak{g}$ by $\left(  \cdot,\cdot\right)  _{\lambda}^{\mathfrak{g}}$ and
$\left(  \cdot,\cdot\right)  _{\lambda}^{\mathfrak{g}\circ}$, and we denote by
$\left(  \cdot,\cdot\right)  _{\lambda}^{\overline{\mathfrak{g}}}$ and
$\left(  \cdot,\cdot\right)  _{\lambda}^{\overline{\mathfrak{g}}\circ}$ the
similarly defined forms for the Lie algebra $\overline{\mathfrak{g}}$. We now
will show:%
\begin{equation}
\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  _{\lambda}^{\overline
{\mathfrak{g}}}=\left(  a,b\right)  _{\lambda}^{\mathfrak{g}\circ
}\ \ \ \ \ \ \ \ \ \ \text{for all }a\in S\left(  \mathfrak{n}_{-}\right)
\text{ and }b\in S\left(  \mathfrak{n}_{+}\right)  . \label{prop.det.US.pf.1}%
\end{equation}
Here, $av_{\lambda}^{+}$ and $bv_{-\lambda}^{-}$ are elements of $M_{\lambda
}^{+\overline{\mathfrak{g}}}$ and $M_{-\lambda}^{-\overline{\mathfrak{g}}}$,
respectively (because $a\in S\left(  \mathfrak{n}_{-}\right)  =U\left(
\overline{\mathfrak{n}_{-}}\right)  $ and $b\in S\left(  \mathfrak{n}%
_{+}\right)  =U\left(  \overline{\mathfrak{n}_{+}}\right)  $).

\textit{Proof of (\ref{prop.det.US.pf.1}).} Let $a\in S\left(  \mathfrak{n}%
_{-}\right)  $ and $b\in S\left(  \mathfrak{n}_{+}\right)  $ be arbitrary.
Since the claim that $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)
_{\lambda}^{\overline{\mathfrak{g}}}=\left(  a,b\right)  _{\lambda
}^{\mathfrak{g}\circ}$ is linear in each of $a$ and $b$, we can WLOG assume
that $a=a_{1}a_{2}...a_{u}$ for some homogeneous $a_{1},a_{2},...,a_{u}%
\in\mathfrak{n}_{-}$ and that $b=b_{1}b_{2}...b_{v}$ for some homogeneous
$b_{1},b_{2},...,b_{v}\in\mathfrak{n}_{+}$.

WLOG assume that $v\geq u$. (Else, the proof is analogous.)

From the proof of Proposition \ref{prop.invform}, we recall that $\left(
av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  =\left(  S\left(  b\right)
av_{\lambda}^{+},v_{-\lambda}^{-}\right)  $. Applied to $\overline
{\mathfrak{g}}$ instead of $\mathfrak{g}$, this yields $\left(  av_{\lambda
}^{+},bv_{-\lambda}^{-}\right)  ^{\overline{\mathfrak{g}}}=\left(  S\left(
b\right)  av_{\lambda}^{+},v_{-\lambda}^{-}\right)  ^{\overline{\mathfrak{g}}%
}$.

Since $\overline{\mathfrak{h}}\subseteq Z\left(  \overline{\mathfrak{g}%
}\right)  $, we have $\overline{\mathfrak{h}}\subseteq Z\left(  U\left(
\overline{\mathfrak{g}}\right)  \right)  $.

Since $b=b_{1}b_{2}...b_{v}$, we have $S\left(  b\right)  =\left(  -1\right)
^{v}b_{v}b_{v-1}...b_{1}$. Combined with $a=a_{1}a_{2}...a_{u}$, this yields%
\[
S\left(  b\right)  a=\left(  -1\right)  ^{v}b_{v}b_{v-1}...b_{1}a_{1}%
a_{2}...a_{u},
\]
so that%
\begin{equation}
\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  ^{\overline{\mathfrak{g}}%
}=\left(  \underbrace{S\left(  b\right)  a}_{=\left(  -1\right)  ^{v}%
b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}}v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  ^{\overline{\mathfrak{g}}}=\left(  -1\right)  ^{v}\left(
b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+},v_{-\lambda}^{-}\right)
^{\overline{\mathfrak{g}}}. \label{prop.det.US.pf.4}%
\end{equation}


We will now prove some identities in order to simplify the $b_{v}%
b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+}$ term here.

First: In the Verma highest-weight module $M_{\lambda}^{+\overline
{\mathfrak{g}}}$ of $\left(  \overline{\mathfrak{g}},\lambda\right)  $ (not of
$\left(  \mathfrak{g},\lambda\right)  $ !), we have%
\begin{align}
\beta\alpha_{1}\alpha_{2}...\alpha_{\ell}v_{\lambda}^{+}  &  =\sum
\limits_{p=1}^{\ell}\lambda\left(  \left[  \beta,\alpha_{p}\right]  \right)
\alpha_{1}\alpha_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha_{\ell
}v_{\lambda}^{+}\label{prop.det.US.pf.3}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\ell\in\mathbb{N}\text{, }\alpha
_{1},\alpha_{2},...,\alpha_{\ell}\in\overline{\mathfrak{n}_{-}}\text{ and
}\beta\in\overline{\mathfrak{n}_{+}}.\nonumber
\end{align}
\footnote{\textit{Proof of (\ref{prop.det.US.pf.3}).} We will prove
(\ref{prop.det.US.pf.3}) by induction over $\ell$:
\par
\textit{Induction base:} For $\ell=0$, the left hand side of
(\ref{prop.det.US.pf.3}) is $\beta v_{\lambda}^{+}=0$ (since $\beta
\in\overline{\mathfrak{n}_{+}}$), and the right hand side of
(\ref{prop.det.US.pf.3}) is $\left(  \text{empty sum}\right)  =0$. Thus, for
$\ell=0$, the equality (\ref{prop.det.US.pf.3}) holds. This completes the
induction base.
\par
\textit{Induction step:} Let $m\in\mathbb{N}$ be positive. Assume that
(\ref{prop.det.US.pf.3}) holds for $\ell=m-1$. We now must show that
(\ref{prop.det.US.pf.3}) holds for $\ell=m$.
\par
Let $\alpha_{1},\alpha_{2},...,\alpha_{m}\in\overline{\mathfrak{n}_{-}}$ and
$\beta\in\overline{\mathfrak{n}_{+}}$.
\par
Since (\ref{prop.det.US.pf.3}) holds for $\ell=m-1$, we can apply
(\ref{prop.det.US.pf.3}) to $m-1$ and $\left(  \alpha_{2},\alpha
_{3},...,\alpha_{m}\right)  $ instead of $\ell$ and $\left(  \alpha_{1}%
,\alpha_{2},...,\alpha_{\ell}\right)  $, and thus obtain%
\begin{align*}
\beta\alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda}^{+}  &  =\sum\limits_{p=1}%
^{m-1}\lambda\left(  \left[  \beta,\alpha_{p+1}\right]  \right)  \alpha
_{2}\alpha_{3}...\alpha_{p-1+1}\alpha_{p+1+1}\alpha_{p+2+1}...\alpha
_{m}v_{\lambda}^{+}\\
&  =\sum\limits_{p=2}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}%
...\alpha_{m}v_{\lambda}^{+}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }p\text{ for
}p+1\text{ in the sum}\right)  .
\end{align*}
\par
Now,%
\begin{align*}
\beta\alpha_{1}\alpha_{2}...\alpha_{m}v_{\lambda}^{+}  &  =\underbrace{\beta
\alpha_{1}}_{=\alpha_{1}\beta+\left[  \beta,\alpha_{1}\right]  }\alpha
_{2}\alpha_{3}...\alpha_{m}v_{\lambda}^{+}=\left(  \alpha_{1}\beta+\left[
\beta,\alpha_{1}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda
}^{+}\\
&  =\alpha_{1}\underbrace{\beta\alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda
}^{+}}_{\substack{=\sum\limits_{p=2}^{m}\lambda\left(  \left[  \beta
,\alpha_{p}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha
_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda}^{+}}}+\underbrace{\left[
\beta,\alpha_{1}\right]  \alpha_{2}\alpha_{3}...\alpha_{m}}_{\substack{=\alpha
_{2}\alpha_{3}...\alpha_{m}\left[  \beta,\alpha_{1}\right]  \\\text{(since
}\beta\in\overline{\mathfrak{n}_{+}}\text{ and }\alpha_{1}\in\overline
{\mathfrak{n}_{-}}\text{, so that}\\\left[  \beta,\alpha_{1}\right]
\in\left[  \overline{\mathfrak{n}_{+}},\overline{\mathfrak{n}_{-}}\right]
\subseteq\overline{\mathfrak{h}}\subseteq Z\left(  \mathfrak{g}\right)
\text{)}}}v_{\lambda}^{+}\\
&  =\underbrace{\alpha_{1}\sum\limits_{p=2}^{m}\lambda\left(  \left[
\beta,\alpha_{p}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{p-1}%
\alpha_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda}^{+}}_{=\sum\limits_{p=2}%
^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]  \right)  \alpha_{1}%
\alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha
_{m}v_{\lambda}^{+}}+\alpha_{2}\alpha_{3}...\alpha_{m}\underbrace{\left[
\beta,\alpha_{1}\right]  v_{\lambda}^{+}}_{=\lambda\left(  \left[
\beta,\alpha_{1}\right]  \right)  v_{\lambda}^{+}}\\
&  =\sum\limits_{p=2}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha
_{p+2}...\alpha_{m}v_{\lambda}^{+}+\lambda\left(  \left[  \beta,\alpha
_{1}\right]  \right)  \alpha_{2}\alpha_{3}...\alpha_{m}v_{\lambda}^{+}\\
&  =\sum\limits_{p=1}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}\alpha_{3}...\alpha_{p-1}\alpha_{p+1}\alpha
_{p+2}...\alpha_{m}v_{\lambda}^{+}\\
&  =\sum\limits_{p=1}^{m}\lambda\left(  \left[  \beta,\alpha_{p}\right]
\right)  \alpha_{1}\alpha_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}%
...\alpha_{m}v_{\lambda}^{+}.
\end{align*}
Thus, (\ref{prop.det.US.pf.3}) holds for $\ell=m$. This completes the
induction step. Thus, (\ref{prop.det.US.pf.3}) is proven.}

Next we will show that in the Verma highest-weight module $M_{\lambda
}^{+\overline{\mathfrak{g}}}$ of $\left(  \overline{\mathfrak{g}}%
,\lambda\right)  $ (not of $\left(  \mathfrak{g},\lambda\right)  $ !), we have%
\begin{align}
\beta_{\ell}\beta_{\ell-1}...\beta_{1}\alpha_{1}\alpha_{2}...\alpha_{\ell
}v_{\lambda}^{+}  &  =\left(  -1\right)  ^{\ell}\sum\limits_{\sigma\in
S_{\ell}}\lambda\left(  \left[  \alpha_{1},\beta_{\sigma\left(  1\right)
}\right]  \right)  \lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  \alpha_{\ell}%
,\beta_{\sigma\left(  \ell\right)  }\right]  \right)  v_{\lambda}%
^{+}\label{prop.det.US.pf.2}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\ell\in\mathbb{N}\text{, }\alpha
_{1},\alpha_{2},...,\alpha_{\ell}\in\overline{\mathfrak{n}_{-}}\text{ and
}\beta_{1},\beta_{2},...,\beta_{\ell}\in\overline{\mathfrak{n}_{+}}%
\text{.}\nonumber
\end{align}


\textit{Proof of (\ref{prop.det.US.pf.2}).} We will prove
(\ref{prop.det.US.pf.2}) by induction over $\ell$:

\textit{Induction base:} For $\ell=0$, we have $\underbrace{\beta_{\ell}%
\beta_{\ell-1}...\beta_{1}}_{\text{empty product}}\underbrace{\alpha_{1}%
\alpha_{2}...\alpha_{\ell}}_{\text{empty product}}v_{\lambda}^{+}=v_{\lambda
}^{+}$ and \newline$\underbrace{\left(  -1\right)  ^{\ell}}_{=1}%
\underbrace{\sum\limits_{\sigma\in S_{\ell}}}_{\text{sum over }1\text{
element}}\underbrace{\lambda\left(  \left[  \alpha_{1},\beta_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  \alpha_{2},\beta
_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
\alpha_{\ell},\beta_{\sigma\left(  \ell\right)  }\right]  \right)
}_{\text{empty product}}v_{\lambda}^{+}=v_{\lambda}^{+}$. Thus, for $\ell=0$,
the equality (\ref{prop.det.US.pf.2}) holds. This completes the induction base.

\textit{Induction step:} Let $m\in\mathbb{N}$ be positive. Assume that
(\ref{prop.det.US.pf.2}) holds for $\ell=m-1$. We now must show that
(\ref{prop.det.US.pf.2}) holds for $\ell=m$.

Let $\alpha_{1},\alpha_{2},...,\alpha_{m}\in\overline{\mathfrak{n}_{-}}$ and
$\beta_{1},\beta_{2},...,\beta_{m}\in\overline{\mathfrak{n}_{+}}$.

For every $p\in\left\{  1,2,...,m\right\}  $, let $c_{p}$ denote the
permutation in $S_{m}$ which is written in row form as $\left(
1,2,...,p-1,p+1,p+2,...,m,p\right)  $. (This is the permutation with cycle
decomposition $\left(  1\right)  \left(  2\right)  ...\left(  p-1\right)
\left(  p,p+1,...,m\right)  $.) Since (\ref{prop.det.US.pf.2}) holds for
$\ell=m-1$, we can apply (\ref{prop.det.US.pf.2}) to $m-1$ and $\left(
\alpha_{c_{p}\left(  1\right)  },\alpha_{c_{p}\left(  2\right)  }%
,...,\alpha_{c_{p}\left(  m-1\right)  }\right)  $ instead of $\ell$ and
$\left(  \alpha_{1},\alpha_{2},...,\alpha_{\ell}\right)  $. This results in%
\begin{align*}
&  \beta_{m-1}\beta_{m-2}...\beta_{1}\alpha_{c_{p}\left(  1\right)  }%
\alpha_{c_{p}\left(  2\right)  }...\alpha_{c_{p}\left(  m-1\right)
}v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m-1}}%
\underbrace{\lambda\left(  \left[  \alpha_{c_{p}\left(  1\right)  }%
,\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
\alpha_{c_{p}\left(  2\right)  },\beta_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  \beta_{c_{p}\left(  m-1\right)  }%
,\alpha_{\sigma\left(  m-1\right)  }\right]  \right)  }_{\substack{=\prod
\limits_{i\in\left\{  1,2,...,m-1\right\}  }\lambda\left(  \left[
\alpha_{c_{p}\left(  i\right)  },\beta_{\sigma\left(  i\right)  }\right]
\right)  =\prod\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{
p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  c_{p}%
^{-1}\left(  i\right)  \right)  }\right]  \right)  \\\text{(here, we
substituted }i\text{ for }c_{p}\left(  i\right)  \text{ in the product)}%
}}v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m-1}}\prod
\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }%
\lambda\left(  \left[  \alpha_{i},\underbrace{\beta_{\sigma\left(  c_{p}%
^{-1}\left(  i\right)  \right)  }}_{=\beta_{\left(  \sigma\circ c_{p}%
^{-1}\right)  \left(  i\right)  }}\right]  \right)  v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m-1}}\prod
\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }%
\lambda\left(  \left[  \alpha_{i},\beta_{\left(  \sigma\circ c_{p}%
^{-1}\right)  \left(  i\right)  }\right]  \right)  v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m};\ \sigma\left(
m\right)  =m}\prod\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{
p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta_{\left(  \sigma\circ
c_{p}^{-1}\right)  \left(  i\right)  }\right]  \right)  v_{\lambda}^{+}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we identified the permutations in }S_{m-1}\text{ with the
permutations}\\
\sigma\in S_{m}\text{ satisfying }\sigma\left(  m\right)  =m
\end{array}
\right) \\
&  =\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in S_{m};\ \sigma\left(
p\right)  =m}\prod\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{
p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  i\right)
}\right]  \right)  v_{\lambda}^{+}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }\sigma\text{ for
}\sigma\circ c_{p}^{-1}\text{ in the sum}\right)  .
\end{align*}


The elements $\beta_{m}$, $\beta_{m-1}$, $...$, $\beta_{1}$ all lie in
$\overline{\mathfrak{n}_{+}}$ and thus commute in $U\left(  \overline
{\mathfrak{g}}\right)  $ (since $\left[  \overline{\mathfrak{n}_{+}}%
,\overline{\mathfrak{n}_{+}}\right]  =0$). Thus, $\beta_{m}\beta_{m-1}%
...\beta_{1}=\beta_{m-1}\beta_{m-2}...\beta_{1}\beta_{m}$, so that%
\begin{align*}
&  \beta_{m}\beta_{m-1}...\beta_{1}\alpha_{1}\alpha_{2}...\alpha_{m}%
v_{\lambda}^{+}\\
&  =\beta_{m-1}\beta_{m-2}...\beta_{1}\underbrace{\beta_{m}\alpha_{1}%
\alpha_{2}...\alpha_{m}v_{\lambda}^{+}}_{\substack{=\sum\limits_{p=1}%
^{m}\lambda\left(  \left[  \beta_{m},\alpha_{p}\right]  \right)  \alpha
_{1}\alpha_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda
}^{+}\\\text{(by (\ref{prop.det.US.pf.3}), applied to }\beta=\beta_{m}\text{
and }\ell=m\text{)}}}\\
&  =\beta_{m-1}\beta_{m-2}...\beta_{1}\sum\limits_{p=1}^{m}\lambda\left(
\left[  \beta_{m},\alpha_{p}\right]  \right)  \alpha_{1}\alpha_{2}%
...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha_{m}v_{\lambda}^{+}\\
&  =\sum\limits_{p=1}^{m}\underbrace{\lambda\left(  \left[  \beta_{m}%
,\alpha_{p}\right]  \right)  }_{=\lambda\left(  -\left[  \alpha_{p},\beta
_{m}\right]  \right)  =-\lambda\left(  \left[  \alpha_{p},\beta_{m}\right]
\right)  }\beta_{m-1}\beta_{m-2}...\beta_{1}\underbrace{\alpha_{1}\alpha
_{2}...\alpha_{p-1}\alpha_{p+1}\alpha_{p+2}...\alpha_{m}}_{\substack{=\alpha
_{c_{p}\left(  1\right)  }\alpha_{c_{p}\left(  2\right)  }...\alpha
_{c_{p}\left(  m-1\right)  }\\\text{(by the definition of }c_{p}\text{)}%
}}v_{\lambda}^{+}\\
&  =-\sum\limits_{p=1}^{m}\lambda\left(  \left[  \alpha_{p},\beta_{m}\right]
\right)  \underbrace{\beta_{m-1}\beta_{m-2}...\beta_{1}\alpha_{c_{p}\left(
1\right)  }\alpha_{c_{p}\left(  2\right)  }...\alpha_{c_{p}\left(  m-1\right)
}v_{\lambda}^{+}}_{=\left(  -1\right)  ^{m-1}\sum\limits_{\sigma\in
S_{m};\ \sigma\left(  p\right)  =m}\prod\limits_{i\in\left\{
1,2,...,m\right\}  \diagdown\left\{  p\right\}  }\lambda\left(  \left[
\alpha_{i},\beta_{\sigma\left(  i\right)  }\right]  \right)  v_{\lambda}^{+}%
}\\
&  =\underbrace{-\left(  -1\right)  ^{m-1}}_{=\left(  -1\right)  ^{m}}%
\sum\limits_{p=1}^{m}\sum\limits_{\sigma\in S_{m};\ \sigma\left(  p\right)
=m}\lambda\left(  \left[  \alpha_{p},\underbrace{\beta_{m}}_{\substack{=\beta
_{\sigma\left(  p\right)  }\\\text{(since }\sigma\left(  p\right)  =m\text{)}%
}}\right]  \right)  \prod\limits_{i\in\left\{  1,2,...,m\right\}
\diagdown\left\{  p\right\}  }\lambda\left(  \left[  \alpha_{i},\beta
_{\sigma\left(  i\right)  }\right]  \right)  v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m}\sum\limits_{p=1}^{m}\sum\limits_{\sigma\in
S_{m};\ \sigma\left(  p\right)  =m}\underbrace{\lambda\left(  \left[
\alpha_{p},\beta_{\sigma\left(  p\right)  }\right]  \right)  \prod
\limits_{i\in\left\{  1,2,...,m\right\}  \diagdown\left\{  p\right\}  }%
\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  i\right)  }\right]
\right)  }_{\substack{=\prod\limits_{i\in\left\{  1,2,...,m\right\}  }%
\lambda\left(  \left[  \alpha_{i},\beta_{\sigma\left(  i\right)  }\right]
\right)  \\=\lambda\left(  \left[  \alpha_{1},\beta_{\sigma\left(  1\right)
}\right]  \right)  \lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  \alpha_{m}%
,\beta_{\sigma\left(  m\right)  }\right]  \right)  }}v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m}\underbrace{\sum\limits_{p=1}^{m}\sum
\limits_{\sigma\in S_{m};\ \sigma\left(  p\right)  =m}}_{=\sum\limits_{\sigma
\in S_{m}}}\lambda\left(  \left[  \alpha_{1},\beta_{\sigma\left(  1\right)
}\right]  \right)  \lambda\left(  \left[  \alpha_{2},\beta_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  \alpha_{m}%
,\beta_{\sigma\left(  m\right)  }\right]  \right)  v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{m}\sum\limits_{\sigma\in S_{m}}\lambda\left(  \left[
\alpha_{1},\beta_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(
\left[  \alpha_{2},\beta_{\sigma\left(  2\right)  }\right]  \right)
...\lambda\left(  \left[  \alpha_{m},\beta_{\sigma\left(  m\right)  }\right]
\right)  v_{\lambda}^{+}.
\end{align*}
In other words, (\ref{prop.det.US.pf.2}) is proven for $\ell=m$. This
completes the induction step. Thus, the induction proof of
(\ref{prop.det.US.pf.2}) is done.

Now, back to proving $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)
_{\lambda}^{\overline{\mathfrak{g}}}=\left(  av_{\lambda}^{+},bv_{-\lambda
}^{-}\right)  _{\lambda}^{\mathfrak{g}\circ}$. Applying
(\ref{prop.det.US.pf.2}) to $\ell=u$, $\alpha_{i}=a_{i}$ and $\beta_{i}=b_{i}%
$, we obtain%
\[
b_{u}b_{u-1}...b_{1}a_{1}a_{2}...a_{\ell}v_{\lambda}^{+}=\sum\limits_{\sigma
\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]
\right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]
\right)  v_{\lambda}^{+}.
\]
Hence, if $v>u$, then%
\begin{align*}
&  b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+}\\
&  =b_{v}b_{v-1}...b_{u+2}b_{u+1}\underbrace{b_{u}b_{u-1}...b_{1}a_{1}%
a_{2}...a_{u}v_{\lambda}^{+}}_{=\left(  -1\right)  ^{u}\sum\limits_{\sigma\in
S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]
\right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]
\right)  v_{\lambda}^{+}}\\
&  =b_{v}b_{v-1}...b_{u+2}b_{u+1}\left(  -1\right)  ^{u}\sum\limits_{\sigma\in
S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]
\right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]
\right)  v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[
a_{1},b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right)  b_{v}b_{v-1}%
...b_{u+2}\underbrace{b_{u+1}v_{\lambda}^{+}}_{\substack{=0\\\text{(since
}b_{u+1}\in\mathfrak{n}_{+}\text{)}}}\\
&  =0,
\end{align*}
and thus%
\begin{align*}
\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  _{\lambda}^{\overline
{\mathfrak{g}}}  &  =\left(  -1\right)  ^{v}\left(  \underbrace{b_{v}%
b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+}}_{=0},v_{-\lambda}%
^{-}\right)  ^{\overline{\mathfrak{g}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{prop.det.US.pf.4})}\right) \\
&  =0=\left(  a,b\right)  _{\lambda}^{\mathfrak{g}\circ}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because the form }\left(  \cdot,\cdot\right)  _{\lambda}^{\mathfrak{g}%
\circ}\text{ was defined as a restriction of a sum}\\
\bigoplus\limits_{k\geq0}\lambda_{k}:S\left(  \mathfrak{n}_{-}\right)  \times
S\left(  \mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}\text{ of bilinear
forms }\lambda_{k}:S^{k}\left(  \mathfrak{n}_{-}\right)  \times S^{k}\left(
\mathfrak{n}_{+}\right)  \rightarrow\mathbb{C}\text{,}\\
\text{and thus }\left(  S^{u}\left(  \mathfrak{n}_{-}\right)  ,S^{v}\left(
\mathfrak{n}_{+}\right)  \right)  _{\lambda}^{\mathfrak{g}\circ}=0\text{ for
}u\neq v
\end{array}
\right)  .
\end{align*}
We thus have proven $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)
_{\lambda}^{\overline{\mathfrak{g}}}=\left(  a,b\right)  _{\lambda
}^{\mathfrak{g}\circ}$ in the case when $v>u$. It remains to prove that
$\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  _{\lambda}^{\overline
{\mathfrak{g}}}=\left(  a,b\right)  _{\lambda}^{\mathfrak{g}\circ}$ in the
case when $v=u$. So let us assume that $v=u$. In this case,%
\begin{align*}
b_{v}b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+}  &  =b_{u}%
b_{u-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+}\\
&  =\left(  -1\right)  ^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[
a_{1},b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right)  v_{\lambda}^{+},
\end{align*}
so that%
\begin{align*}
\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  _{\lambda}^{\overline
{\mathfrak{g}}}  &  =\left(  -1\right)  ^{v}\left(  \underbrace{b_{v}%
b_{v-1}...b_{1}a_{1}a_{2}...a_{u}v_{\lambda}^{+}}_{=\left(  -1\right)
^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  v_{\lambda}^{+}},v_{-\lambda}^{-}\right)
^{\overline{\mathfrak{g}}}\\
&  =\left(  -1\right)  ^{v}\left(  \left(  -1\right)  ^{u}\sum\limits_{\sigma
\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(  1\right)  }\right]
\right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(  2\right)  }\right]
\right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(  u\right)  }\right]
\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  ^{\overline{\mathfrak{g}}}\\
&  =\underbrace{\left(  -1\right)  ^{v}}_{\substack{=\left(  -1\right)
^{u}\\\text{(since }v=u\text{)}}}\left(  \underbrace{-1}_{=1/\left(
-1\right)  }\right)  ^{u}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[
a_{1},b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right)  \underbrace{\left(
v_{\lambda}^{+},v_{-\lambda}^{-}\right)  ^{\overline{\mathfrak{g}}}}_{=1}\\
&  =\underbrace{\left(  -1\right)  ^{u}\cdot\left(  \dfrac{1}{-1}\right)
^{u}}_{=1}\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1}%
,b_{\sigma\left(  1\right)  }\right]  \right)  \lambda\left(  \left[
a_{2},b_{\sigma\left(  2\right)  }\right]  \right)  ...\lambda\left(  \left[
a_{u},b_{\sigma\left(  u\right)  }\right]  \right) \\
&  =\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  .
\end{align*}
Compared to%
\begin{align*}
\left(  \underbrace{a}_{=a_{1}a_{2}...a_{u}},\underbrace{b}_{\substack{=b_{1}%
b_{2}...b_{v}=b_{1}b_{2}...b_{u}\\\text{(since }v=u\text{)}}}\right)
_{\lambda}^{\mathfrak{g}\circ}  &  =\left(  a_{1}a_{2}...a_{u},b_{1}%
b_{2}...b_{u}\right)  _{\lambda}^{\mathfrak{g}\circ}=\lambda_{u}\left(
a_{1}a_{2}...a_{u},b_{1}b_{2}...b_{u}\right) \\
&  =\sum\limits_{\sigma\in S_{u}}\lambda\left(  \left[  a_{1},b_{\sigma\left(
1\right)  }\right]  \right)  \lambda\left(  \left[  a_{2},b_{\sigma\left(
2\right)  }\right]  \right)  ...\lambda\left(  \left[  a_{u},b_{\sigma\left(
u\right)  }\right]  \right)  ,
\end{align*}
this yields $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  _{\lambda
}^{\overline{\mathfrak{g}}}=\left(  a,b\right)  _{\lambda}^{\mathfrak{g}\circ
}$. Now that $\left(  av_{\lambda}^{+},bv_{-\lambda}^{-}\right)  _{\lambda
}^{\overline{\mathfrak{g}}}=\left(  a,b\right)  _{\lambda}^{\mathfrak{g}\circ
}$ is proven in each of the cases $v>u$ and $v=u$ (and the case $v<u$ is
analogous), we are done with proving (\ref{prop.det.US.pf.1}).

[...]

\textbf{[From here on, everything is just a very rough draft. It will be
detailed in the next days.]}

Now, $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\overline{\mathfrak{g}}%
}=\left(  \cdot,\cdot\right)  _{\lambda,n}^{\mathfrak{g}\circ}$ [as proven
above] and $\left(  \cdot,\cdot\right)  _{\lambda^{\prime},n}%
^{\widetilde{\mathfrak{g}}}=\varepsilon^{2\ell_{n}\text{ (degree of the
polynomial)}}\left(  \cdot,\cdot\right)  _{\lambda/\varepsilon^{2}%
,n}^{\mathfrak{g}\left[  \varepsilon\right]  }$. When $\varepsilon
\rightarrow0$, the latter goes exactly to the leading term, but the former
goes to $\left(  \cdot,\cdot\right)  _{\lambda,n}^{\overline{\mathfrak{g}}}$. Qed.

[...] explain this stuff.

Now we can complete the proof of Theorem \ref{thm.invformnondeg}:

Fix $n\in\mathbb{N}$. For generic $\lambda$, the bilinear form%
\[
\mathfrak{g}_{-k}\times\mathfrak{g}_{k}\rightarrow\mathbb{C}%
,\ \ \ \ \ \ \ \ \ \ \left(  a,b\right)  \mapsto\lambda\left(  \left[
a,b\right]  \right)
\]
is nondegenerate for every $k\in\left\{  1,2,...,n\right\}  $ (because
$\mathfrak{g}$ is nondegenerate). Thus, for generic $\lambda$, the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}^{\circ}$ must also be nondegenerate
(by Lemma \ref{lem.lambda_k.2}), so that $\det\left(  \left(  \cdot
,\cdot\right)  _{\lambda,n}^{\circ}\right)  \neq0$. By Proposition
\ref{prop.det.US}, this yields that $\det\left(  \left(  \cdot,\cdot\right)
_{\lambda,n}\right)  \neq0$ for generic $\lambda$. In other words, the form
$\left(  \cdot,\cdot\right)  _{\lambda,n}$ is nondegenerate for generic
$\lambda$. But this form $\left(  \cdot,\cdot\right)  _{\lambda,n}$ is exactly
the restriction of the form $\left(  \cdot,\cdot\right)  :M_{\lambda}%
^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$ to $M_{\lambda}^{+}\left[
-n\right]  \times M_{-\lambda}^{-}\left[  n\right]  $. Hence, the restriction
of the form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda
}^{-}\rightarrow\mathbb{C}$ to $M_{\lambda}^{+}\left[  -n\right]  \times
M_{-\lambda}^{-}\left[  n\right]  $ is nondegenerate for generic $\lambda$.
This proves Theorem \ref{thm.invformnondeg}.

\subsection{The irreducible quotients of the Verma modules}

We will now use the form $\left(  \cdot,\cdot\right)  $ to develop the
representation theory of $\mathfrak{g}$. In the following, we assume that
$\mathfrak{g}$ is nondegenerate.

\begin{definition}
Let $J_{\lambda}^{\pm}$ be the kernel of $\left(  \cdot,\cdot\right)  $ on
$M_{\lambda}^{\pm}$. This is a graded $\mathfrak{g}$-submodule of $M_{\lambda
}^{\pm}$ (since the form $\left(  \cdot,\cdot\right)  $ is $\mathfrak{g}%
$-invariant). Let $L_{\lambda}^{\pm}$ be the quotient module $M_{\lambda}%
^{\pm}\diagup J_{\lambda}^{\pm}$. Then, $\left(  \cdot,\cdot\right)  $
descends to a nondegenerate pairing $L_{\lambda}^{+}\times L_{-\lambda}%
^{-}\rightarrow\mathbb{C}$.
\end{definition}

\begin{remark}
For Weil-generic $\lambda$ (away from a countable union of hypersurfaces), we
have $J_{\lambda}^{\pm}=0$ (by Theorem \ref{thm.invformnondeg}) and thus
$L_{\lambda}^{\pm}=M_{\lambda}^{\pm}$.
\end{remark}

\begin{theorem}
\label{thm.verma}\textbf{(i)} The $\mathfrak{g}$-module $L_{\lambda}^{\pm}$ is irreducible.

\textbf{(ii)} The $\mathfrak{g}$-module $J_{\lambda}^{\pm}$ is the maximal
proper graded submodule of $M_{\lambda}^{\pm}$. (This means that $J_{\lambda
}^{\pm}$ contains all proper graded submodules in $M_{\lambda}^{\pm}$.)

\textbf{(iii)} Assume that there exists some $L\in\mathfrak{g}_{0}$ such that
every $n\in\mathbb{Z}$ satisfies
\[
\left(  \operatorname*{ad}L\right)  \mid_{\mathfrak{g}_{n}}=n\cdot
\operatorname*{id}\mid_{\mathfrak{g}_{n}}.
\]
(In this case it is said that \textit{the grading on }$\mathfrak{g}$
\textit{is internal}, i. e., comes from bracketing with some $L\in
\mathfrak{g}_{0}$.) Then $J_{\lambda}^{\pm}$ is the maximal proper submodule
of $M_{\lambda}^{\pm}$.
\end{theorem}

\begin{remark}
The grading is internal if $\mathfrak{g}$ is a simple Lie algebra (in this
case, we can take $L=\rho^{\vee}$) and if $\mathfrak{g}=\operatorname*{Vir}$
(in this case, $L=-L_{0}$), but not for $\mathfrak{g}$ being the affine
Kac-Moody algebra $\widehat{\mathfrak{g}}_{\omega}$ of Definition
\ref{def.kac}.
\end{remark}

\textit{Proof of Theorem \ref{thm.verma}.} \textbf{(i)} Let us show that
$L_{\lambda}^{-}$ is irreducible (the proof for $L_{\lambda}^{+}$ will be similar).

In fact, assume the contrary. Then, there exists a nonzero $w\in L_{\lambda
}^{-}$ such that $U\left(  \mathfrak{g}\right)  \cdot w\neq L_{\lambda}^{-}$.
Since $L_{\lambda}^{-}$ is graded by \textit{nonnegative} integers, we can
choose $w$ to have the smallest possible degree $m$ (without necessarily being
homogeneous). Clearly, $m>0$. Thus we can write $w=w_{0}+w_{1}+...+w_{m}$,
where each $w_{i}$ is homogeneous of degree $\deg w_{i}=i$ and $w_{m}\neq0$.

Let $a\in\mathfrak{g}_{j}$ for some $j<0$. Then $aw=0$ (since $\deg\left(
aw\right)  <\deg w$, but still $U\left(  \mathfrak{g}\right)  \cdot aw\neq
L_{\lambda}^{-}$ (since $U\left(  \mathfrak{g}\right)  \cdot aw\subseteq
U\left(  \mathfrak{g}\right)  \cdot w$ and $U\left(  \mathfrak{g}\right)
\cdot w\neq L_{\lambda}^{-}$), and we have chosen $w$ to have the smallest
possible degree). By homogeneity, this yields $aw_{m}=0$.

For every $u\in L_{-\lambda}^{+}\left[  -m-j\right]  $, the term $\left(
au,w_{m}\right)  $ is well-defined (since $au\in L_{-\lambda}^{+}$ and
$w_{m}\in L_{\lambda}^{-}$). Since the form $\left(  \cdot,\cdot\right)  $ is
$\mathfrak{g}$-invariant, it satisfies $\left(  au,w_{m}\right)  =-\left(
u,\underbrace{aw_{m}}_{=0}\right)  =0$. But since $m>0$, we have $L_{-\lambda
}^{+}\left[  -m\right]  =\sum\limits_{j<0}\mathfrak{g}_{j}\cdot L_{-\lambda
}^{+}\left[  -m-j\right]  $ (because Proposition \ref{prop.verma1}
\textbf{(a)} yields $M_{-\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)
v_{\lambda}^{+}$, so that $L_{-\lambda}^{+}=U\left(  \mathfrak{n}_{-}\right)
\overline{v_{\lambda}^{+}}$, thus%
\[
L_{-\lambda}^{+}\left[  -m\right]  =\underbrace{U\left(  \mathfrak{n}%
_{-}\right)  \left[  -m\right]  }_{=\sum\limits_{j<0}\left(  \mathfrak{n}%
_{-}\right)  \left[  j\right]  \cdot U\left(  \mathfrak{n}_{-}\right)  \left[
-m-j\right]  }\overline{v_{\lambda}^{+}}=\sum\limits_{j<0}\underbrace{\left(
\mathfrak{n}_{-}\right)  \left[  j\right]  }_{=\mathfrak{g}\left[  j\right]
=\mathfrak{g}_{j}}\cdot\underbrace{U\left(  \mathfrak{n}_{-}\right)  \left[
-m-j\right]  \overline{v_{\lambda}^{+}}}_{\substack{=L_{-\lambda}^{+}\left[
-m-j\right]  \\\text{(since }U\left(  \mathfrak{n}_{-}\right)  \overline
{v_{\lambda}^{+}}=L_{-\lambda}^{+}\text{)}}}=\sum\limits_{j<0}\mathfrak{g}%
_{j}\cdot L_{-\lambda}^{+}\left[  -m-j\right]
\]
). Hence, any element of $L_{-\lambda}^{+}\left[  -m\right]  $ is a linear
combination of elements of the form $au$ with $a\in\mathfrak{g}_{j}$ (for
$j<0$) and $u\in L_{-\lambda}^{+}\left[  -m-j\right]  $. Thus, since we know
that $\left(  au,w_{m}\right)  =0$ for every $a\in\mathfrak{g}_{j}$ and $u\in
L_{-\lambda}^{+}\left[  -m-j\right]  $, we conclude that $\left(  L_{-\lambda
}^{+}\left[  -m\right]  ,w_{m}\right)  =0$. As a consequence, $\left(
L_{-\lambda}^{+},w_{m}\right)  =0$ (because the form $\left(  \cdot
,\cdot\right)  :L_{-\lambda}^{+}\times L_{\lambda}^{-}\rightarrow\mathbb{C}$
is of degree $0$, and thus $\left(  L_{-\lambda}^{+}\left[  j\right]
,w_{m}\right)  =0$ for all $j\neq-m$). Since the form $\left(  \cdot
,\cdot\right)  :L_{-\lambda}^{+}\times L_{\lambda}^{-}\rightarrow\mathbb{C}$
is nondegenerate, this yields $w_{m}=0$. This is a contradiction to $w_{m}%
\neq0$. This contradiction shows that our assumption was wrong. Thus,
$L_{\lambda}^{-}$ is irreducible. Similarly, $L_{\lambda}^{+}$ is irreducible.

\textbf{(ii)} First let us prove that the $\mathfrak{g}$-module $J_{\lambda
}^{+}$ is the maximal proper graded submodule of $M_{\lambda}^{+}$.

Let $K\subseteq M_{\lambda}^{+}$ be a proper graded submodule, and let
$\overline{K}$ be its image in $L_{\lambda}^{+}$. Then, $K$ lives in strictly
negative degrees (because it is graded, so if it would have a component in
degrees $\geq0$, it would contain $v_{\lambda}^{+}$ and thus contain
everything, and thus not be proper). Hence, $\overline{K}$ also lives in
strictly negative degrees, and thus is proper. Hence, by \textbf{(i)}, we have
$\overline{K}=0$, thus $K\subseteq J_{\lambda}^{+}$. This shows that
$J_{\lambda}^{+}$ is the maximal proper graded submodule of $M_{\lambda}^{+}$.
The proof of the corresponding statement for $J_{\lambda}^{-}$ and
$M_{\lambda}^{-}$ is similar.

\textbf{(iii)} Assume that there exists some $L\in\mathfrak{g}_{0}$ such that
every $n\in\mathbb{Z}$ satisfies
\[
\left(  \operatorname*{ad}L\right)  \mid_{\mathfrak{g}_{n}}=n\cdot
\operatorname*{id}\mid_{\mathfrak{g}_{n}}.
\]
Consider this $L$. It is easy to prove (by induction) that $\left[
L,a\right]  =na$ for every $a\in U\left(  \mathfrak{g}\right)  \left[
n\right]  $.

We are now going to show that all $\mathfrak{g}$-submodules of $M_{\lambda
}^{+}$ are automatically graded.

In fact, it is easy to see that $M_{\lambda}^{+}\left[  n\right]
\subseteq\operatorname*{Ker}\left(  L\mid_{M_{\lambda}^{+}}-\left(
\lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)  $ for every
$n\in\mathbb{Z}$.\ \ \ \ \footnote{\textit{Proof.} Let $n\in\mathbb{Z}$. Let
$a\in U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  $. Then, $a\in
U\left(  \mathfrak{g}\right)  \left[  n\right]  $, so that $\left[
L,a\right]  =na$ and thus $La=aL+\underbrace{\left[  L,a\right]  }%
_{=na}=aL+na$. Thus,%
\begin{align*}
\left(  L\mid_{M_{\lambda}^{+}}\right)  \left(  av_{\lambda}^{+}\right)   &
=\underbrace{La}_{=aL+na}v_{\lambda}^{+}=\left(  aL+na\right)  v_{\lambda}%
^{+}=a\underbrace{Lv_{\lambda}^{+}}_{=\lambda\left(  L\right)  v_{\lambda}%
^{+}}+nav_{\lambda}^{+}=\lambda\left(  L\right)  av_{\lambda}^{+}%
+nav_{\lambda}^{+}\\
&  =\left(  \lambda\left(  L\right)  +n\right)  av_{\lambda}^{+},
\end{align*}
so that $av_{\lambda}^{+}\in\operatorname*{Ker}\left(  L\mid_{M_{\lambda}^{+}%
}-\left(  \lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)  $.
Forget that we fixed $a\in U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]
$. Thus we have showed that every $a\in U\left(  \mathfrak{n}_{-}\right)
\left[  n\right]  $ satisfies $av_{\lambda}^{+}\in\operatorname*{Ker}\left(
L\mid_{M_{\lambda}^{+}}-\left(  \lambda\left(  L\right)  +n\right)
\operatorname*{id}\right)  $. In other words, $\left\{  av_{\lambda}^{+}%
\ \mid\ a\in U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  \right\}
\subseteq\operatorname*{Ker}\left(  L\mid_{M_{\lambda}^{+}}-\left(
\lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)  $. Since
$\left\{  av_{\lambda}^{+}\ \mid\ a\in U\left(  \mathfrak{n}_{-}\right)
\left[  n\right]  \right\}  =U\left(  \mathfrak{n}_{-}\right)  \left[
n\right]  \cdot v_{\lambda}^{+}=M_{\lambda}^{+}\left[  n\right]  $ (since
$U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  =M_{\lambda}^{+}$), this
becomes $M_{\lambda}^{+}\left[  n\right]  \subseteq\operatorname*{Ker}\left(
L\mid_{M_{\lambda}^{+}}-\left(  \lambda\left(  L\right)  +n\right)
\operatorname*{id}\right)  $, qed.} In other words, for every $n\in\mathbb{Z}%
$, the $n$-th graded component $M_{\lambda}^{+}\left[  n\right]  $ of
$M_{\lambda}^{+}$ is contained in the eigenspace of the operator
$L\mid_{M_{\lambda}^{+}}$ for the eigenvalue $\lambda\left(  L\right)  +n$.
Now,%
\begin{align*}
M_{\lambda}^{+}  &  =\bigoplus\limits_{n\in\mathbb{Z}}M_{\lambda}^{+}\left[
n\right]  =\sum\limits_{n\in\mathbb{Z}}\underbrace{M_{\lambda}^{+}\left[
n\right]  }_{\substack{\subseteq\operatorname*{Ker}\left(  L\mid_{M_{\lambda
}^{+}}-\left(  \lambda\left(  L\right)  +n\right)  \operatorname*{id}\right)
\\=\left(  \text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{ for
the eigenvalue }\lambda\left(  L\right)  +n\right)  }}\\
&  \subseteq\sum\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of the
operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)  .
\end{align*}
Since all eigenspaces of $L\mid_{M_{\lambda}^{+}}$ are clearly contained in
$M_{\lambda}^{+}$, this rewrites as%
\[
M_{\lambda}^{+}=\sum\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of the
operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)  .
\]
Since eigenspaces of an operator corresponding to distinct eigenvalues are
linearly disjoint, the sum $\sum\limits_{n\in\mathbb{Z}}\left(
\text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{ for the
eigenvalue }\lambda\left(  L\right)  +n\right)  $ must be a direct sum, so
this becomes%
\begin{equation}
M_{\lambda}^{+}=\bigoplus\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of
the operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)  . \label{thm.verma.pf.5}%
\end{equation}
As a consequence of this, the map $L\mid_{M_{\lambda}^{+}}$ is diagonalizable,
and all of its eigenvalues belong to the set $\left\{  \lambda\left(
L\right)  +n\ \mid\ n\in\mathbb{Z}\right\}  $.

So for every $n\in\mathbb{Z}$, we have the inclusion%
\begin{align*}
M_{\lambda}^{+}\left[  n\right]   &  \subseteq\operatorname*{Ker}\left(
L\mid_{M_{\lambda}^{+}}-\left(  \lambda\left(  L\right)  +n\right)
\operatorname*{id}\right) \\
&  =\left(  \text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{
for the eigenvalue }\lambda\left(  L\right)  +n\right)  ,
\end{align*}
but the direct sum of these inclusions over all $n\in\mathbb{Z}$ is an
equality (since%
\[
\bigoplus\limits_{n\in\mathbb{Z}}M_{\lambda}^{+}\left[  n\right]  =M_{\lambda
}^{+}=\bigoplus\limits_{n\in\mathbb{Z}}\left(  \text{eigenspace of the
operator }L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(
L\right)  +n\right)
\]
by (\ref{thm.verma.pf.5})). Hence, each of these inclusions must be an
equality. In other words,
\begin{equation}
M_{\lambda}^{+}\left[  n\right]  =\left(  \text{eigenspace of the operator
}L\mid_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(  L\right)
+n\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}.
\label{thm.verma.pf.6}%
\end{equation}


Now, let $K$ be a $\mathfrak{g}$-submodule of $M_{\lambda}^{+}$. Then,
$L\mid_{K}$ is a restriction of $L\mid_{M_{\lambda}^{+}}$ to $K$. Hence, map
$L\mid_{K}$ is diagonalizable, and all of its eigenvalues belong to the set
$\left\{  \lambda\left(  L\right)  +n\ \mid\ n\in\mathbb{Z}\right\}  $
(because we know that the map $L\mid_{M_{\lambda}^{+}}$ is diagonalizable, and
all of its eigenvalues belong to the set $\left\{  \lambda\left(  L\right)
+n\ \mid\ n\in\mathbb{Z}\right\}  $). In other words,%
\begin{align*}
K  &  =\bigoplus\limits_{n\in\mathbb{Z}}\underbrace{\left(  \text{eigenspace
of the operator }L\mid_{K}\text{ for the eigenvalue }\lambda\left(  L\right)
+n\right)  }_{=K\cap\left(  \text{eigenspace of the operator }L\mid
_{M_{\lambda}^{+}}\text{ for the eigenvalue }\lambda\left(  L\right)
+n\right)  }\\
&  =\bigoplus\limits_{n\in\mathbb{Z}}\left(  K\cap\underbrace{\left(
\text{eigenspace of the operator }L\mid_{M_{\lambda}^{+}}\text{ for the
eigenvalue }\lambda\left(  L\right)  +n\right)  }_{=M_{\lambda}^{+}\left[
n\right]  }\right) \\
&  =\bigoplus\limits_{n\in\mathbb{Z}}\left(  K\cap M_{\lambda}^{+}\left[
n\right]  \right)  .
\end{align*}
Hence, $K$ is graded. We thus have shown that every $\mathfrak{g}$-submodule
of $M_{\lambda}^{+}$ is graded. Similarly, every $\mathfrak{g}$-submodule of
$M_{\lambda}^{-}$ is graded. Thus, Theorem \ref{thm.verma} \textbf{(iii)}
follows from Theorem \ref{thm.verma} \textbf{(ii)}.

\begin{remark}
Theorem \ref{thm.verma} \textbf{(ii)} does not hold if the word "graded" is
removed. In fact, here is a counterexample: Let $\mathfrak{g}$ be the
3-dimensional Heisenberg algebra. (This is the Lie algebra with vector-space
basis $\left(  x,K,y\right)  $ and with Lie bracket given by $\left[
y,x\right]  =K$, $\left[  x,K\right]  =0$ and $\left[  y,K\right]  =0$. It can
be considered as a Lie subalgebra of the oscillator algebra $\mathcal{A}$
defined in Definition \ref{def.osc}.) It is easy to see that $\mathfrak{g}$
becomes a nondegenerate $\mathbb{Z}$-graded Lie algebra by setting
$\mathfrak{g}_{-1}=\left\langle x\right\rangle $, $\mathfrak{g}_{0}%
=\left\langle K\right\rangle $, $\mathfrak{g}_{1}=\left\langle y\right\rangle
$ and $\mathfrak{g}_{i}=0$ for every $i\in\mathbb{Z}\diagdown\left\{
-1,0,1\right\}  $. Then, on the Verma highest-weight module $M_{0}%
^{+}=\mathbb{C}\left[  x\right]  v_{0}^{+}$, both $K$ and $y$ act as $0$ (and
$x$ acts as multiplication with $x$), so that $Iv_{0}^{+}$ is a $\mathfrak{g}%
$-submodule of $M_{0}^{+}$ for every ideal $I\subseteq\mathbb{C}\left[
x\right]  $, but not all of these ideals are graded, and not all of them are
contained in $J_{0}^{+}$ (as can be easily checked).
\end{remark}

\begin{corollary}
\label{cor.verma.irred}For Weil-generic $\lambda$ (this means a $\lambda$
outside of countably many hypersurfaces in $\mathfrak{h}^{\ast}$), the
$\mathfrak{g}$-modules $M_{\lambda}^{+}$ and $M_{\lambda}^{-}$ are irreducible.
\end{corollary}

\begin{remark}
Let $Y$ be a $\mathfrak{g}$-module. A vector $w\in Y$ is called a
\textit{singular vector of weight }$\mu\in\mathfrak{h}^{\ast}$ (here, recall
that $\mathfrak{h}=\mathfrak{g}_{0}$) if it satisfies%
\[
hw=\mu\left(  h\right)  w\ \ \ \ \ \ \ \ \ \ \text{for every }h\in\mathfrak{h}%
\]
and%
\[
aw=0\ \ \ \ \ \ \ \ \ \ \text{for every }a\in\mathfrak{g}_{i}\text{ for every
}i>0\text{.}%
\]
We denote by $\operatorname*{Sing}\nolimits_{\mu}\left(  Y\right)  $ the space
of singular vectors of $Y$ of weight $\mu$.
\end{remark}

When people talk about "singular vectors", they usually mean nonzero singular
vectors in negative degrees. We are not going to adhere to this convention, though.

\begin{lemma}
\label{lem.singvec}Let $Y$ be a $\mathfrak{g}$-module. Then there is a
canonical isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
&  \rightarrow\operatorname*{Sing}\nolimits_{\lambda}Y,\\
\phi &  \mapsto\phi\left(  v_{\lambda}^{+}\right)  .
\end{align*}

\end{lemma}

\textit{Proof of Lemma \ref{lem.singvec}.} We have $M_{\lambda}^{+}=U\left(
\mathfrak{g}\right)  \otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}%
_{+}\right)  }\mathbb{C}_{\lambda}=\operatorname*{Ind}\nolimits_{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\mathbb{C}_{\lambda}$, so that
\[
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
=\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  \operatorname*{Ind}%
\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}^{\mathfrak{g}}\mathbb{C}%
_{\lambda},Y\right)  \cong\operatorname*{Hom}\nolimits_{\mathfrak{h}%
\oplus\mathfrak{n}_{+}}\left(  \mathbb{C}_{\lambda},Y\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Frobenius reciprocity}\right)  .
\]
But $\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(
\mathbb{C}_{\lambda},Y\right)  \cong\operatorname*{Sing}\nolimits_{\lambda}Y$
(because every $\mathbb{C}$-linear map $\mathbb{C}_{\lambda}\rightarrow Y$ is
uniquely determined by the image of $v_{\lambda}^{+}$, and this map is a
$\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  $-module map if and only
if this image is a singular vector of $Y$ of weight $\lambda$). Thus,
$\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
\cong\operatorname*{Hom}\nolimits_{\mathfrak{h}\oplus\mathfrak{n}_{+}}\left(
\mathbb{C}_{\lambda},Y\right)  \cong\operatorname*{Sing}\nolimits_{\lambda}Y$.
If we make this isomorphism explicit, we notice that it sends every $\phi$ to
$\phi\left(  v_{\lambda}^{+}\right)  $, so that Lemma \ref{lem.singvec} is proven.

\begin{corollary}
\label{cor.singvec}The representation $M_{\lambda}^{+}$ is irreducible if and
only if it does not have nonzero singular vectors in negative degrees. Here, a
vector in $M_{\lambda}^{+}$ is said to be "in negative degrees" if its
projection on the $0$-th graded component $M_{\lambda}^{+}\left[  0\right]  $
is zero.
\end{corollary}

\textit{Proof of Corollary \ref{cor.singvec}.} $\Longleftarrow:$ Assume that
$M_{\lambda}^{+}$ does not have nonzero singular vectors in negative degrees.

We must then show that $M_{\lambda}^{+}$ is irreducible.

In fact, assume the contrary. Then, $M_{\lambda}^{+}$ is not irreducible.
Hence, there exists a nonzero \textit{homogeneous} $v\in M_{\lambda}^{+}$ such
that $U\left(  \mathfrak{g}\right)  \cdot v\neq M_{\lambda}^{+}$%
.\ \ \ \ \footnote{\textit{Proof.} Since $M_{\lambda}^{+}$ is not irreducible,
there exists a nonzero $w\in M_{\lambda}^{+}$ such that $U\left(
\mathfrak{g}\right)  \cdot w\neq M_{\lambda}^{+}$. Since $M_{\lambda}^{+}$ is
graded by \textit{nonpositive} integers, we can write $w$ in the form
$w=\sum\limits_{j=0}^{m}w_{j}$, where each $w_{i}$ is homogeneous of degree
$\deg w_{i}=-i$ and $m\in\mathbb{Z}$. Now,
\begin{align*}
\underbrace{U\left(  \mathfrak{g}\right)  }_{=\sum\limits_{i\in\mathbb{Z}%
}U\left(  \mathfrak{g}\right)  \left[  i\right]  }\cdot\underbrace{w}%
_{=\sum\limits_{j=0}^{m}w_{j}}  &  =\left(  \sum\limits_{i\in\mathbb{Z}%
}U\left(  \mathfrak{g}\right)  \left[  i\right]  \right)  \cdot\left(
\sum\limits_{j=0}^{m}w_{j}\right) \\
&  =\sum\limits_{i\in\mathbb{Z}}\sum\limits_{j=0}^{m}U\left(  \mathfrak{g}%
\right)  \left[  i\right]  \cdot w_{j}.
\end{align*}
Hence, for every $n\in\mathbb{Z}$, we have
\[
\left(  U\left(  \mathfrak{g}\right)  \cdot w\right)  \left[  n\right]
=\left(  \sum\limits_{i\in\mathbb{Z}}\sum\limits_{j=0}^{m}U\left(
\mathfrak{g}\right)  \left[  i\right]  \cdot w_{j}\right)  \left[  n\right]
=\sum\limits_{j=0}^{m}U\left(  \mathfrak{g}\right)  \left[  n-j\right]  \cdot
w_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }M_{\lambda}^{+}\text{ is a
graded }\mathfrak{g}\text{-module}\right)  .
\]
Now, since $U\left(  \mathfrak{g}\right)  \cdot w\neq M_{\lambda}^{+}$, there
exists at least one $n\in\mathbb{Z}$ such that $\left(  U\left(
\mathfrak{g}\right)  \cdot w\right)  \left[  n\right]  \neq M_{\lambda}%
^{+}\left[  n\right]  $. Consider such an $n$. Then, $M_{\lambda}^{+}\left[
n\right]  \neq\left(  U\left(  \mathfrak{g}\right)  \cdot w\right)  \left[
n\right]  =\sum\limits_{j=0}^{m}U\left(  \mathfrak{g}\right)  \left[
n-j\right]  \cdot w_{j}$. Thus, $U\left(  \mathfrak{g}\right)  \left[
n-j\right]  \cdot w_{j}\neq M_{\lambda}^{+}\left[  n\right]  $ for all
$j\in\left\{  0,1,...,m\right\}  $. But some $j\in\left\{  0,1,...,m\right\}
$ satisfies $w_{j}\neq0$ (since $\sum\limits_{j=0}^{m}w_{j}=w\neq0$). Consider
this $j$. Then, $w_{j}$ is a nonzero homogeneous element of $M_{\lambda}^{+}$
satisfying $U\left(  \mathfrak{g}\right)  \cdot w_{j}\neq M_{\lambda}^{+}$
(because $\left(  U\left(  \mathfrak{g}\right)  \cdot w_{j}\right)  \left[
n\right]  =U\left(  \mathfrak{g}\right)  \left[  n-j\right]  \cdot w_{j}\neq
M_{\lambda}^{+}\left[  n\right]  $). This proves that there exists a nonzero
\textit{homogeneous} $v\in M_{\lambda}^{+}$ such that $U\left(  \mathfrak{g}%
\right)  \cdot v\neq M_{\lambda}^{+}$. Qed.} Consider this $v$. Then,
$U\left(  \mathfrak{g}\right)  \cdot v$ is a proper graded submodule of
$M_{\lambda}^{+}$, and thus is contained in $J_{\lambda}^{+}$. Hence,
$J_{\lambda}^{+}\neq0$.

There exist some $d\in\mathbb{Z}$ such that $J_{\lambda}^{+}\left[  d\right]
\neq0$ (since $J_{\lambda}^{+}\neq0$ and since $J_{\lambda}^{+}$ is graded).
All such $d$ are nonpositive (since $J_{\lambda}^{+}$ is nonpositively
graded). Thus, there exists a highest integer $d$ such that $J_{\lambda}%
^{+}\left[  d\right]  \neq0$. Consider this $d$. Clearly, $d<0$ (since the
bilinear form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times M_{-\lambda
}^{-}$ is obviously nondegenerate on $M_{\lambda}^{+}\left[  0\right]  \times
M_{-\lambda}^{-}\left[  0\right]  $, so that $J_{\lambda}^{+}\left[  0\right]
=0$).

Every $i>0$ satisfies
\begin{align*}
\mathfrak{g}_{i}\cdot\left(  J_{\lambda}^{+}\left[  d\right]  \right)   &
\subseteq J_{\lambda}^{+}\left[  i+d\right]  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }J_{\lambda}^{+}\text{ is a graded }\mathfrak{g}\text{-module}%
\right) \\
&  =0\ \ \ \ \ \ \ \ \ \ \left(  \text{since }i+d>d\text{, but }d\text{ was
the highest integer such that }J_{\lambda}^{+}\left[  d\right]  \neq0\right)
.
\end{align*}


By Conditions \textbf{(1)} and \textbf{(2)} of Definition
\ref{def.gradLienondeg}, the Lie algebra $\mathfrak{g}_{0}$ is abelian and
finite-dimensional. Hence, every nonzero $\mathfrak{g}_{0}$-module has a
one-dimensional submodule\footnote{\textit{Proof.} This is because of the
following fact:
\par
Every nonzero module over an abelian finite-dimensional Lie algebra has a
one-dimensional submodule. (This is just a restatement of the fact that a
finite set of pairwise commuting matrices on a nonzero $\mathbb{C}$-vector
space has a common eigenvector.)}. Thus, the nonzero $\mathfrak{g}_{0}$-module
$J_{\lambda}^{+}\left[  d\right]  $ has a one-dimensional submodule. Let $w$
be the generator of this submodule. Then, this submodule is $\left\langle
w\right\rangle $.

For every $h\in\mathfrak{h}$, the vector $hw$ is a scalar multiple of $w$
(since $h\in\mathfrak{h}=\mathfrak{g}_{0}$, so that $hw$ lies in the
$\mathfrak{g}_{0}$-submodule of $J_{\lambda}^{+}\left[  d\right]  $ generated
by $w$, but this submodule is $\left\langle w\right\rangle $). Thus, we can
write $hw=\lambda_{h}w$ for some $\lambda_{h}\in\mathbb{C}$. This $\lambda
_{h}$ is uniquely determined (since $h\neq0$), so we can define a map
$\mu:\mathfrak{h}\rightarrow\mathbb{C}$ such that $\mu\left(  h\right)
=\lambda_{h}$ for every $h\in\mathfrak{h}$. This map $\mu$ is easily seen to
be $\mathbb{C}$-linear, so that we have found a $\mu\in\mathfrak{h}^{\ast}$
such that%
\[
hw=\mu\left(  h\right)  w\ \ \ \ \ \ \ \ \ \ \text{for every }h\in
\mathfrak{h}.
\]
Also,%
\[
aw=0\ \ \ \ \ \ \ \ \ \ \text{for every }a\in\mathfrak{g}_{i}\text{ for every
}i>0
\]
(since $\underbrace{a}_{\in\mathfrak{g}_{i}}\underbrace{w}_{\in J_{\lambda
}^{+}\left[  d\right]  }\in\mathfrak{g}_{i}\cdot\left(  J_{\lambda}^{+}\left[
d\right]  \right)  =0$). Thus, $w$ is a nonzero singular vector. Since $w\in
J_{\lambda}^{+}\left[  d\right]  $ and $d<0$, this vector $w$ is in negative
degrees. This contradicts to the assumption that $M_{\lambda}^{+}$ does not
have nonzero singular vectors in negative degrees. This contradiction shows
that our assumption was wrong, so that $M_{\lambda}^{+}$ is irreducible. This
proves the $\Longleftarrow$ direction of Corollary \ref{cor.singvec}.

$\Longrightarrow:$ Assume that $M_{\lambda}^{+}$ is irreducible.

We must then show that $M_{\lambda}^{+}$ does not have nonzero singular
vectors in negative degrees.

Let $v$ be a singular vector of $M_{\lambda}^{+}$ in negative degrees. Let it
be a singular vector of weight $\mu$ for some $\mu\in\mathfrak{h}^{\ast}$.

By Lemma \ref{lem.singvec} (applied to $\mu$ and $M_{\lambda}^{+}$ instead of
$\lambda$ and $Y$), we have an isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\mu}^{+},M_{\lambda}%
^{+}\right)   &  \rightarrow\operatorname*{Sing}\nolimits_{\mu}\left(
M_{\lambda}^{+}\right)  ,\\
\phi &  \mapsto\phi\left(  v_{\mu}^{+}\right)  .
\end{align*}
Let $\phi$ be the preimage of $v$ under this isomorphism. Then, $v=\phi\left(
v_{\mu}^{+}\right)  $.

Since $v$ is in negative degrees, we have $v\in\sum\limits_{n<0}M_{\lambda
}^{+}\left[  n\right]  $. Now, $M_{\mu}^{+}=U\left(  \mathfrak{n}_{-}\right)
v_{\mu}^{+}=\sum\limits_{m\leq0}U\left(  \mathfrak{n}_{-}\right)  \left[
m\right]  v_{\mu}^{+}$ (since $M_{\mu}^{+}$ is nonpositively graded), so that%
\begin{align*}
\phi\left(  M_{\mu}^{+}\right)   &  =\phi\left(  \sum\limits_{m\leq0}U\left(
\mathfrak{n}_{-}\right)  \left[  m\right]  v_{\mu}^{+}\right)  =\sum
\limits_{m\leq0}U\left(  \mathfrak{n}_{-}\right)  \left[  m\right]
\underbrace{\phi\left(  v_{\mu}^{+}\right)  }_{=v\in\sum\limits_{n<0}%
M_{\lambda}^{+}\left[  n\right]  }\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\phi\in\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\mu}%
^{+},M_{\lambda}^{+}\right)  \right) \\
&  \in\sum\limits_{m\leq0}U\left(  \mathfrak{n}_{-}\right)  \left[  m\right]
\sum\limits_{n<0}M_{\lambda}^{+}\left[  n\right]  =\sum\limits_{m\leq0}%
\sum\limits_{n<0}\underbrace{U\left(  \mathfrak{n}_{-}\right)  \left[
m\right]  \cdot M_{\lambda}^{+}\left[  n\right]  }_{\substack{\in M_{\lambda
}^{+}\left[  m+n\right]  \\\text{(since }M_{\lambda}^{+}\text{ is a graded
}\mathfrak{g}\text{-module)}}}\\
&  \in\sum\limits_{m\leq0}\sum\limits_{n<0}M_{\lambda}^{+}\left[  m+n\right]
\subseteq\sum\limits_{r<0}M_{\lambda}^{+}\left[  r\right]  .
\end{align*}
Thus, the projection of $\phi\left(  M_{\mu}^{+}\right)  $ onto the $0$-th
degree of $M_{\lambda}^{+}$ is $0$. Hence, $\phi\left(  M_{\mu}^{+}\right)  $
is a proper $\mathfrak{g}$-submodule of $M_{\lambda}^{+}$. Therefore,
$\phi\left(  M_{\mu}^{+}\right)  =0$ (since $M_{\lambda}^{+}$ is irreducible).
Thus, $v=\phi\left(  v_{\mu}^{+}\right)  \in\phi\left(  M_{\mu}^{+}\right)
=0$, so that $v=0$.

We have thus proven: Whenever $v$ is a singular vector of $M_{\lambda}^{+}$ in
negative degrees, we have $v=0$. In other words, $M_{\lambda}^{+}$ does not
have nonzero singular vectors in negative degrees. This proves the
$\Longrightarrow$ direction of Corollary \ref{cor.singvec}.

Here is a variation on Corollary \ref{cor.singvec}:

\begin{corollary}
\label{cor.singvec.2}The representation $M_{\lambda}^{+}$ is irreducible if
and only if it does not have nonzero homogeneous singular vectors in negative degrees.
\end{corollary}

\textit{Proof of Corollary \ref{cor.singvec.2}.} $\Longrightarrow:$ This
follows from the $\Longrightarrow$ direction of Corollary \ref{cor.singvec}.

$\Longleftarrow:$ Repeat the proof of the $\Longleftarrow$ direction of
Corollary \ref{cor.singvec}, noticing that $w$ is homogeneous (since $w\in
J_{\lambda}^{+}\left[  d\right]  $).

Corollary \ref{cor.singvec.2} is thus proven.

\subsection{Highest/lowest weight modules}

\begin{definition}
A \textit{highest weight module} with highest weight $\lambda\in
\mathfrak{h}^{\ast}$ is a quotient of $M_{\lambda}^{+}$ by a proper graded submodule.

A \textit{lowest weight module} with lowest weight $\lambda\in\mathfrak{h}%
^{\ast}$ is a quotient of $M_{\lambda}^{-}$ by a proper graded submodule.

If $Y$ is a highest weight module with highest weight $\lambda$, then we have
an exact sequence $%
%TCIMACRO{\TeXButton{M surj Y surj L}{\xymatrix{
%M^{+}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{+}_{\lambda}
%}}}%
%BeginExpansion
\xymatrix{
M^{+}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{+}_{\lambda}
}%
%EndExpansion
$ (by Theorem \ref{thm.verma} \textbf{(ii)}).

If $Y$ is a lowest weight module with lowest weight $\lambda$, then we have an
exact sequence $%
%TCIMACRO{\TeXButton{M surj Y surj L}{\xymatrix{
%M^{-}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{-}_{\lambda}
%}}}%
%BeginExpansion
\xymatrix{
M^{-}_{\lambda} \arsurj[r] & Y \arsurj[r] & L^{-}_{\lambda}
}%
%EndExpansion
$ (by Theorem \ref{thm.verma} \textbf{(ii)}).
\end{definition}

\subsection{Categories $\mathcal{O}^{+}$ and $\mathcal{O}^{-}$}

The category of all $\mathfrak{g}$-modules for a graded Lie algebra is normally

We now define the so-called Category $\mathcal{O}$; actually, there are two of
these categories, $\mathcal{O}^{+}$ and $\mathcal{O}^{-}$, which are
antiequivalent to each other (in general) and equivalent to each other (in
some more restrictive cases). There are several definitions for each of these
categories, and some of them are not even equivalent to each other, although
they mostly differ in minor technicalities. Here is our definition:

\begin{definition}
\label{def.O+}The objects of \textit{category }$\mathcal{O}^{+}$ will be
$\mathbb{C}$-graded $\mathfrak{g}$-modules $M$ such that:

\textbf{(1)} all degrees lie in a halfplane $\operatorname{Re}z<a$ and fall
into finitely many arithmetic progressions with step $1$;

\textbf{(2)} for every $d\in\mathbb{C}$, the space $M\left[  d\right]  $ is finite-dimensional.

The \textit{morphisms of category }$\mathcal{O}^{+}$ will be graded
$\mathfrak{g}$-module homomorphisms.
\end{definition}

\begin{definition}
\label{def.O-}The objects of \textit{category }$\mathcal{O}^{-}$ will be
$\mathbb{C}$-graded $\mathfrak{g}$-modules $M$ such that:

\textbf{(1)} all degrees lie in a halfplane $\operatorname{Re}z>a$ and fall
into finitely many arithmetic progressions with step $1$;

\textbf{(2)} for every $d\in\mathbb{C}$, the space $M\left[  d\right]  $ is finite-dimensional.

The \textit{morphisms of category }$\mathcal{O}^{-}$ will be graded
$\mathfrak{g}$-module homomorphisms.
\end{definition}

It is rather clear that for a nondegenerate $\mathbb{Z}$-graded Lie algebra
(or, more generally, for a $\mathbb{Z}$-graded Lie algebra satisfying
conditions \textbf{(1)} and \textbf{(2)} of Definition \ref{def.gradLienondeg}%
), the Verma highest-weight module $M_{\lambda}^{+}$ lies in category
$\mathcal{O}^{+}$ for every $\lambda\in\mathfrak{h}^{\ast}$, and the Verma
lowest-weight module $M_{\lambda}^{-}$ lies in category $\mathcal{O}^{-}$ for
every $\lambda\in\mathfrak{h}^{\ast}$.

\begin{definition}
Let $V$ and $W$ be two $\mathbb{C}$-graded vector spaces, and $x\in\mathbb{C}%
$. A map $f:V\rightarrow W$ is said to be \textit{homogeneous of degree }$x$
if and only if every $z\in\mathbb{C}$ satisfies $f\left(  V\left[  z\right]
\right)  \subseteq W\left[  z+x\right]  $. (For example, this yields that a
map is homogeneous of degree $0$ if and only if it is graded.)
\end{definition}

\begin{proposition}
\label{prop.O.irred}The irreducible modules in category $\mathcal{O}^{\pm}$
(up to homogeneous isomorphism) are $L_{\lambda}^{\pm}$ for varying
$\lambda\in\mathbb{C}$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.O.irred}.} First of all, for every
$\lambda\in\mathfrak{h}^{\ast}$, the $\mathfrak{g}$-module $L_{\lambda}^{+}$
has a unique singular vector (up to scaling), and this vector is a singular
vector of weight $\lambda$.\ \ \ \ \footnote{\textit{Proof.} It is clear that
$\overline{v_{\lambda}^{+}}\in L_{\lambda}^{+}$ is a singular vector of weight
$\lambda$. Now we must prove that it is the only singular vector (up to
scaling).
\par
In fact, assume the opposite. Then, there exists a singular vector in
$L_{\lambda}^{+}$ which is not a scalar multiple of $\overline{v_{\lambda}%
^{+}}$. This singular vector must have a nonzero $d$-th homogeneous component
for some $d<0$ (because it is not a scalar multiple of $\overline{v_{\lambda
}^{+}}$), and this component itself must be a singular vector (since any
homogeneous component of a singular vector must itself be a singular vector).
So the module $L_{\lambda}^{+}$ has a nonzero homogeneous singular vector $w$
of degree $d$.
\par
Now, repeat the proof of the $\Longrightarrow$ part of Corollary
\ref{cor.singvec}, with $M_{\lambda}^{+}$ replaced by $L_{\lambda}^{+}$ (using
the fact that $L_{\lambda}^{+}$ is irreducible). As a consequence, it follows
that $L_{\lambda}^{+}$ does not have nonzero singular vectors in negative
degrees. This contradicts the fact that the module $L_{\lambda}^{+}$ has a
nonzero homogeneous singular vector $w$ of degree $d<0$. This contradiction
shows that our assumption was wrong, so that indeed, $\overline{v_{\lambda
}^{+}}$ is the only singular vector of $L_{\lambda}^{+}$ (up to scaling),
qed.} Thus, the $\mathfrak{g}$-modules $L_{\lambda}^{+}$ are pairwise
nonisomorphic for varying $\lambda$. Similarly, the $\mathfrak{g}$-modules
$L_{\lambda}^{+}$ are pairwise nonisomorphic for varying $\lambda$.

Let $Y$ be any irreducible module in category $\mathcal{O}^{+}$. We are now
going to prove that $Y\cong L_{\lambda}^{+}$ for some $\lambda\in
\mathfrak{h}^{\ast}$.

Let $d$ be a complex number such that $Y\left[  d\right]  \neq0$ and $Y\left[
d+j\right]  =0$ for all $j\geq1$. (Such a complex number exists due to
condition \textbf{(1)} in Definition \ref{def.O+}.) For every $v\in Y\left[
d\right]  $, we have $av=0$ for every $a\in\mathfrak{g}_{i}$ for every
$i>0$\ \ \ \ \footnote{\textit{Proof.} Let $i>0$ and $a\in\mathfrak{g}_{i}$.
Then, $i\geq1$. Now, $a\in\mathfrak{g}_{i}$ and $v\in Y\left[  d\right]  $
yield $av\in\mathfrak{g}_{i}\cdot Y\left[  d\right]  \subseteq Y\left[
d+i\right]  =0$ (since $Y\left[  d+j\right]  =0$ for all $j\geq1$), so that
$av=0$, qed.}.

By Conditions \textbf{(1)} and \textbf{(2)} of Definition
\ref{def.gradLienondeg}, the Lie algebra $\mathfrak{g}_{0}$ is abelian and
finite-dimensional. Hence, every nonzero $\mathfrak{g}_{0}$-module has a
one-dimensional submodule\footnote{\textit{Proof.} This is because of the
following fact:
\par
Every nonzero module over an abelian finite-dimensional Lie algebra has a
one-dimensional submodule. (This is just a restatement of the fact that a
finite set of pairwise commuting matrices on a nonzero $\mathbb{C}$-vector
space has a common eigenvector.)}. Thus, the nonzero $\mathfrak{g}_{0}$-module
$Y\left[  d\right]  $ has a one-dimensional submodule. Let $w$ be the
generator of this submodule. Then, this submodule is $\left\langle
w\right\rangle $.

For every $h\in\mathfrak{h}$, the vector $hw$ is a scalar multiple of $w$
(since $h\in\mathfrak{h}=\mathfrak{g}_{0}$, so that $hw$ lies in the
$\mathfrak{g}_{0}$-submodule of $Y\left[  d\right]  $ generated by $w$, but
this submodule is $\left\langle w\right\rangle $). Thus, we can write
$hw=\lambda_{h}w$ for some $\lambda_{h}\in\mathbb{C}$. This $\lambda_{h}$ is
uniquely determined (since $h\neq0$), so we can define a map $\lambda
:\mathfrak{h}\rightarrow\mathbb{C}$ such that $\lambda\left(  h\right)
=\lambda_{h}$ for every $h\in\mathfrak{h}$. This map $\lambda$ is easily seen
to be $\mathbb{C}$-linear, so that we have found a $\lambda\in\mathfrak{h}%
^{\ast}$ such that%
\[
hw=\lambda\left(  h\right)  w\ \ \ \ \ \ \ \ \ \ \text{for every }%
h\in\mathfrak{h}.
\]
Also,%
\[
aw=0\ \ \ \ \ \ \ \ \ \ \text{for every }a\in\mathfrak{g}_{i}\text{ for every
}i>0
\]
(since $av=0$ for every $v\in Y\left[  d\right]  $ and every $a\in
\mathfrak{g}_{i}$ for every $i>0$). Thus, $w$ is a nonzero singular vector of
weight $\lambda$.

By Lemma \ref{lem.singvec}, we have an isomorphism%
\begin{align*}
\operatorname*{Hom}\nolimits_{\mathfrak{g}}\left(  M_{\lambda}^{+},Y\right)
&  \rightarrow\operatorname*{Sing}\nolimits_{\lambda}Y,\\
\phi &  \mapsto\phi\left(  v_{\lambda}^{+}\right)  .
\end{align*}
Let $\phi$ be the preimage of $w$ under this isomorphism. Then, $w=\phi\left(
v_{\lambda}^{+}\right)  $. Since $w\in Y\left[  d\right]  $, it is easy to see
that $\phi$ is a homogeneous homomorphism of degree $d$ (in fact, every
$n\in\mathbb{Z}$ satisfies $M_{\lambda}^{+}\left[  n\right]  =U\left(
\mathfrak{n}_{-}\right)  \left[  n\right]  \cdot v_{\lambda}^{+}$, so that%
\begin{align*}
\phi\left(  M_{\lambda}^{+}\left[  n\right]  \right)   &  =\phi\left(
U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  \cdot v_{\lambda}%
^{+}\right)  =U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]
\cdot\underbrace{\phi\left(  v_{\lambda}^{+}\right)  }_{=w\in Y\left[
d\right]  }\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\phi\text{ is
}\mathfrak{g}\text{-linear}\right) \\
&  \subseteq U\left(  \mathfrak{n}_{-}\right)  \left[  n\right]  \cdot
Y\left[  d\right]  \subseteq Y\left[  n+d\right]
\end{align*}
). This homomorphism $\phi$ must be surjective, since $Y$ is irreducible.
Thus, we have a homogeneous isomorphism $M_{\lambda}^{+}\diagup\left(
\operatorname*{Ker}\phi\right)  \cong Y$. Also, $\operatorname*{Ker}\phi$ is a
proper graded submodule of $M_{\lambda}^{+}$, thus a submodule of $J_{\lambda
}^{+}$ (by Theorem \ref{thm.verma} \textbf{(ii)}). Hence, we have a projection
$M_{\lambda}^{+}\diagup\left(  \operatorname*{Ker}\phi\right)  \rightarrow
M_{\lambda}^{+}\diagup J_{\lambda}^{+}$. since $M_{\lambda}^{+}\diagup\left(
\operatorname*{Ker}\phi\right)  \cong Y$ is irreducible, this projection must
either be an isomorphism or the zero map. It cannot be a zero map (since it is
a projection onto the nonzero module $M_{\lambda}^{+}\diagup J_{\lambda}^{+}%
$), so it therefore is an isomorphism. Thus, $M_{\lambda}^{+}\diagup
J_{\lambda}^{+}\cong M_{\lambda}^{+}\diagup\left(  \operatorname*{Ker}%
\phi\right)  \cong Y$, so we have a homogeneous isomorphism $Y\cong
M_{\lambda}^{+}\diagup J_{\lambda}^{+}=L_{\lambda}^{+}$.

We thus have showed that any irreducible module in category $\mathcal{O}^{+}$
is isomorphic to $L_{\lambda}^{+}$ for some $\lambda\in\mathfrak{h}^{\ast}$.
Similarly, the analogous assertion holds for $\mathcal{O}^{-}$. Proposition
\ref{prop.O.irred} is thus proven.

\begin{definition}
Let $M$ be a module in category $\mathcal{O}^{+}$. We define the
\textit{character} $\operatorname*{ch}M$ of $M$ as follows:

Write $M=\bigoplus\limits_{d}M\left[  d\right]  $. Then, define
$\operatorname*{ch}M$ by%
\[
\operatorname*{ch}M=\sum\limits_{d}q^{-d}\operatorname*{tr}\nolimits_{M\left[
d\right]  }\left(  e^{x}\right)  \ \ \ \ \ \ \ \ \ \ \text{as a power series
in }q
\]
for every $x\in\mathfrak{h}$. We also write $\left(  \operatorname*{ch}%
M\right)  \left(  q,x\right)  $ for this, so it becomes a formal power series
in both $q$ and $x$. (Note that this power series can contain noninteger
powers of $q$, but due to $M\in\mathcal{O}^{+}$, the exponents in these powers
are bounded from above in their real part, and fall into infinitely many
arithmetic progressions with step $1$.)
\end{definition}

\begin{proposition}
Here is an example:%
\[
\left(  \operatorname*{ch}M_{\lambda}^{+}\right)  \left(  x\right)  =\dfrac
{1}{\prod\limits_{j>0}\det\nolimits_{\mathfrak{g}\left[  -j\right]  }\left(
1-q^{j}e^{\operatorname*{ad}\left(  x\right)  }\right)  }.
\]
(To prove this, use Molien's identity which states that, for every linear map
$A:V\rightarrow V$, we have%
\[
\sum\limits_{n\in\mathbb{N}}q^{n}\operatorname*{Tr}\nolimits_{S^{n}V}\left(
S^{n}A\right)  =\dfrac{1}{\det\left(  1-qA\right)  },
\]
where $S^{n}A$ denotes the $n$-th symmetric power of the operator $A$.)
\end{proposition}

Let us consider some examples:

\textbf{1st Example:} Let $\mathfrak{g}=\mathfrak{sl}_{2}$. We can write this
Lie algebra in terms of Chevalley generators and Serre relations (this is a
particular case of what we did in Proposition \ref{prop.grad.g}). The most
traditional way to do this is by setting $e=\left(
\begin{array}
[c]{cc}%
0 & 1\\
0 & 0
\end{array}
\right)  $, $f=\left(
\begin{array}
[c]{cc}%
0 & 0\\
1 & 0
\end{array}
\right)  $ and $h=\left(
\begin{array}
[c]{cc}%
1 & 0\\
0 & 1
\end{array}
\right)  $; then, $\mathfrak{g}$ is generated by $e$, $f$ and $h$ as a Lie
algebra, and these generators satisfy $\left[  h,e\right]  =2e$, $\left[
h,f\right]  =-2f$ and $\left[  e,f\right]  =h$. Also, $\left(  e,f,h\right)  $
is a basis of the vector space $\mathfrak{g}$. In accordance with Proposition
\ref{prop.grad.g}, we grade $\mathfrak{g}$ by setting $\deg e=1$, $\deg f=-1$
and $\deg h=0$. Then, $\mathfrak{n}_{+}=\left\langle e\right\rangle $,
$\mathfrak{n}_{-}=\left\langle f\right\rangle $ and $\mathfrak{h}=\left\langle
h\right\rangle $. Hence, linear maps $\lambda:\mathfrak{h}\rightarrow
\mathbb{C}$ are in 1-to-1 correspondence with complex numbers (namely, the
images $\lambda\left(  h\right)  $ of $h$ under these maps). Thus, we can
identify any linear map $\lambda:\mathfrak{h}\rightarrow\mathbb{C}$ with the
image $\lambda\left(  h\right)  \in\mathbb{C}$.

Consider any $\lambda\in\mathfrak{h}^{\ast}$. Since $\mathfrak{n}%
_{-}=\left\langle f\right\rangle $, the universal enveloping algebra $U\left(
\mathfrak{n}_{-}\right)  $ is the polynomial algebra $\mathbb{C}\left[
f\right]  $, and Proposition \ref{prop.verma1} \textbf{(a)} yields
$M_{\lambda}^{+}=\underbrace{U\left(  \mathfrak{n}_{-}\right)  }%
_{=\mathbb{C}\left[  f\right]  }v_{\lambda}^{+}=\mathbb{C}\left[  f\right]
v_{\lambda}^{+}$. Similarly, $M_{-\lambda}^{-}=\mathbb{C}\left[  e\right]
v_{-\lambda}^{-}$. In order to compute the bilinear form $\left(  \cdot
,\cdot\right)  $ on $M_{\lambda}^{+}\times M_{-\lambda}^{-}$, it is thus
enough to compute $\left(  f^{n}v_{\lambda}^{+},e^{n}v_{-\lambda}^{-}\right)
$ for all $n\in\mathbb{N}$. (The values $\left(  f^{n}v_{\lambda}^{+}%
,e^{m}v_{-\lambda}^{-}\right)  $ for $n\neq m$ are zero since the form has
degree $0$.) In order to do this, we notice that $e^{n}f^{n}v_{\lambda}%
^{+}=n!\lambda\left(  \lambda-1\right)  ...\left(  \lambda-n+1\right)
v_{\lambda}^{+}$\ \ \ \ \footnote{\textit{Proof (sketched).} First show that
$hf^{m}v_{\lambda}^{+}=\left(  \lambda-2m\right)  f^{m}v_{\lambda}^{+}$ for
every $m\in\mathbb{N}$. (This follows easily by induction over $m$, using
$hf-fh=\left[  h,f\right]  =-2f$.)
\par
Next show that $ef^{n}v_{\lambda}^{+}=n\left(  \lambda-n+1\right)
f^{n-1}v_{\lambda}^{+}$ for every positive $n\in\mathbb{N}$. (This is again an
easy induction proof using the equalities $ef-fe=\left[  e,f\right]  =h$,
$hv_{\lambda}^{+}=\underbrace{\lambda\left(  h\right)  }_{=\lambda}v_{\lambda
}^{+}=\lambda v_{\lambda}^{+}$ and $ev_{\lambda}^{+}=0$, and using the
equality $hf^{m}v_{\lambda}^{+}=\left(  \lambda-2m\right)  f^{m}v_{\lambda
}^{+}$ applied to $m=n-1$.)
\par
Now show that $e^{n}f^{n}v_{\lambda}^{+}=n!\lambda\left(  \lambda-1\right)
...\left(  \lambda-n+1\right)  v_{\lambda}^{+}$ for every $n\in\mathbb{N}$.
(For this, again use induction.)} and thus%
\begin{align*}
\left(  f^{n}v_{\lambda}^{+},e^{n}v_{-\lambda}^{-}\right)   &  =\left(
\underbrace{S\left(  e^{n}\right)  }_{=\left(  -1\right)  ^{n}e^{n}}%
f^{n}v_{\lambda}^{+},v_{-\lambda}^{-}\right)  =\left(  \left(  -1\right)
^{n}\underbrace{e^{n}f^{n}}_{\substack{=n!\lambda\left(  \lambda-1\right)
...\left(  \lambda-n+1\right)  }}v_{\lambda}^{+},v_{-\lambda}^{-}\right) \\
&  =\left(  \left(  -1\right)  ^{n}n!\lambda\left(  \lambda-1\right)
...\left(  \lambda-n+1\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right) \\
&  =\left(  -1\right)  ^{n}n!\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  \underbrace{\left(  v_{\lambda}^{+},v_{-\lambda}%
^{-}\right)  }_{=1}\\
&  =\left(  -1\right)  ^{n}n!\lambda\left(  \lambda-1\right)  ...\left(
\lambda-n+1\right)  .
\end{align*}
So $M_{\lambda}^{+}$ is irreducible if $\lambda\notin\mathbb{Z}_{+}$. If
$\lambda\in\mathbb{Z}_{+}$, then $J_{\lambda}^{+}=\left\langle f^{n}%
v_{\lambda}^{+}\ \mid\ n\geq\lambda+1\right\rangle =\mathbb{C}\left[
f\right]  \cdot\left(  f^{\lambda+1}v_{\lambda}^{+}\right)  $, and the
irreducible $\mathfrak{g}$-module $L_{\lambda}^{+}=\left\langle \overline
{v_{\lambda}^{+}},f\overline{v_{\lambda}^{+}},...,f^{\lambda}\overline
{v_{\lambda}^{+}}\right\rangle $ has dimension $\dim\lambda+1$%
.\ \ \ \ \footnote{If you know the representation theory of $\mathfrak{sl}%
_{2}$, you probably recognize this module $L_{\lambda}^{+}$ as the $\left(
\dim\lambda\right)  $-th symmetric power of the vector module $\mathbb{C}^{2}$
(as there is only one irreducible $\mathfrak{sl}_{2}$-module of every
dimension).}

\textbf{2nd Example:} Let $\mathfrak{g}=\operatorname*{Vir}$. With the grading
that we have defined on $\operatorname*{Vir}$, we have $\mathfrak{h}%
=\mathfrak{g}_{0}=\left\langle L_{0},C\right\rangle $. Thus, linear maps
$\lambda:\mathfrak{h}\rightarrow\mathbb{C}$ can be uniquely described by the
images of $L_{0}$ and $C$ under these maps. We thus identify every linear map
$\lambda:\mathfrak{h}\rightarrow\mathbb{C}$ with the pair $\left(
\lambda\left(  L_{0}\right)  ,\lambda\left(  C\right)  \right)  $.

For every $\lambda=\left(  \lambda\left(  L_{0}\right)  ,\lambda\left(
C\right)  \right)  $, the number $\lambda\left(  L_{0}\right)  $ is denoted by
$h$ and called the \textit{conformal weight} of $\lambda$, and the number
$\lambda\left(  C\right)  $ is denoted by $c$ and called the \textit{central
charge} of $\lambda$. Thus, $\lambda$ is identified with the pair $\left(
h,c\right)  $. As a consequence, the Verma modules $M_{\lambda}^{+}$ and
$M_{\lambda}^{-}$ are often denoted by $M_{h,c}^{+}$ and $M_{h,c}^{-}$,
respectively, and similarly for the modules $L_{\lambda}^{+}$ and $L_{\lambda
}^{-}$.

Consider any $\lambda\in\mathfrak{h}^{\ast}$. Let us compute the bilinear form
$\left(  \cdot,\cdot\right)  $ on $M_{\lambda}^{+}\times M_{-\lambda}^{-}$. In
order to compute $\left(  L_{-1}v_{\lambda}^{+},L_{1}v_{-\lambda}^{-}\right)
$, we notice that
\[
\underbrace{L_{1}L_{-1}}_{=L_{-1}L_{1}+\left[  L_{1},L_{-1}\right]
}v_{\lambda}^{+}=L_{-1}\underbrace{L_{1}v_{\lambda}^{+}}_{=0}%
+\underbrace{\left[  L_{1},L_{-1}\right]  }_{=2L_{0}}v_{\lambda}%
^{+}=2\underbrace{L_{0}v_{\lambda}^{+}}_{=\lambda\left(  L_{0}\right)
v_{\lambda}^{+}}=2\underbrace{\lambda\left(  L_{0}\right)  }_{=h}v_{\lambda
}^{+}=2hv_{\lambda}^{+},
\]
so that%
\[
\left(  L_{-1}v_{\lambda}^{+},L_{1}v_{-\lambda}^{-}\right)  =\left(
-\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}},v_{-\lambda}%
^{-}\right)  =\left(  -2hv_{\lambda}^{+},v_{-\lambda}^{-}\right)
=-2h\underbrace{\left(  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  }_{=1}=-2h.
\]
Since $\left(  L_{-1}v_{\lambda}^{+}\right)  $ is a basis of $M_{\lambda}%
^{+}\left[  -1\right]  $ and $\left(  L_{1}v_{-\lambda}^{-}\right)  $ is a
basis of $M_{-\lambda}^{-}\left[  1\right]  $, this yields $\det\left(
\left(  \cdot,\cdot\right)  _{1}\right)  =2h$ (where $\left(  \cdot
,\cdot\right)  _{1}$ denotes the restriction of the form $\left(  \cdot
,\cdot\right)  $ to $M_{\lambda}^{+}\left[  -1\right]  \times M_{-\lambda}%
^{-}\left[  1\right]  $). This vanishes for $h=0$.

In degree $2$, the form is somewhat more complicated: With respect to the
basis $\left(  L_{-1}^{2}v_{\lambda}^{+},L_{-2}v_{\lambda}^{+}\right)  $ of
$M_{\lambda}^{+}\left[  -2\right]  $, and the basis $\left(  L_{1}%
^{2}v_{-\lambda}^{-},L_{2}v_{-\lambda}^{-}\right)  $ of $M_{-\lambda}%
^{-}\left[  2\right]  $, the restriction $\left(  \cdot,\cdot\right)  _{2}$ of
the form $\left(  \cdot,\cdot\right)  $ to $M_{\lambda}^{+}\left[  -2\right]
\times M_{-\lambda}^{-}\left[  2\right]  $ is given by the matrix%
\[
\left(
\begin{array}
[c]{cc}%
\left(  L_{-1}^{2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda}^{-}\right)  & \left(
L_{-1}^{2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right) \\
\left(  L_{-2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda}^{-}\right)  & \left(
L_{-2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right)
\end{array}
\right)  .
\]


Let us compute, as an example, the lower right entry of this matrix, that is,
the entry $\left(  L_{-2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right)  $. We
have%
\begin{align*}
\underbrace{L_{2}L_{-2}}_{=L_{-2}L_{2}+\left[  L_{2},L_{-2}\right]
}v_{\lambda}^{+}  &  =L_{-2}\underbrace{L_{2}v_{\lambda}^{+}}_{=0}%
+\underbrace{\left[  L_{2},L_{-2}\right]  }_{=4L_{0}+\dfrac{1}{2}C}v_{\lambda
}^{+}=\left(  4L_{0}+\dfrac{1}{2}C\right)  v_{\lambda}^{+}\\
&  =4\underbrace{L_{0}v_{\lambda}^{+}}_{=\lambda\left(  L_{0}\right)
v_{\lambda}^{+}}+\dfrac{1}{2}\underbrace{Cv_{\lambda}^{+}}_{=\lambda\left(
C\right)  v_{\lambda}^{+}}=4\underbrace{\lambda\left(  L_{0}\right)  }%
_{=h}v_{\lambda}^{+}+\dfrac{1}{2}\underbrace{\lambda\left(  C\right)  }%
_{=c}v_{\lambda}^{+}\\
&  =\left(  4h+\dfrac{1}{2}c\right)  v_{\lambda}^{+},
\end{align*}
so that%
\begin{align*}
\left(  L_{-2}v_{\lambda}^{+},L_{2}v_{-\lambda}^{-}\right)   &  =\left(
-\underbrace{L_{2}L_{-2}v_{\lambda}^{+}}_{=\left(  4h+\dfrac{1}{2}c\right)
v_{\lambda}^{+}},v_{-\lambda}^{-}\right)  =\left(  -\left(  4h+\dfrac{1}%
{2}c\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right) \\
&  =-\left(  4h+\dfrac{1}{2}c\right)  \underbrace{\left(  v_{\lambda}%
^{+},v_{-\lambda}^{-}\right)  }_{=1}=-\left(  4h+\dfrac{1}{2}c\right)  .
\end{align*}
As a further (more complicated) example, let us compute the upper left entry
of the matrix, namely $\left(  L_{-1}^{2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda
}^{-}\right)  $. We have%
\begin{align*}
L_{1}^{2}L_{-1}^{2}v_{\lambda}^{+}  &  =L_{1}\underbrace{L_{1}L_{-1}}%
_{=L_{-1}L_{1}+\left[  L_{1},L_{-1}\right]  }L_{-1}v_{\lambda}^{+}=L_{1}%
L_{-1}\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}}%
+L_{1}\underbrace{\left[  L_{1},L_{-1}\right]  }_{=2L_{0}}L_{-1}v_{\lambda
}^{+}\\
&  =2h\underbrace{L_{1}L_{-1}v_{\lambda}^{+}}_{=2hv_{\lambda}^{+}}%
+2L_{1}\underbrace{L_{0}L_{-1}}_{\substack{=L_{-1}L_{0}+\left[  L_{0}%
,L_{-1}\right]  \\=L_{-1}L_{0}+L_{-1}\\\text{(since }\left[  L_{0}%
,L_{-1}\right]  =L_{-1}\text{)}}}v_{\lambda}^{+}=4h^{2}v_{\lambda}^{+}%
+2L_{1}L_{-1}\underbrace{L_{0}v_{\lambda}^{+}}_{\substack{=\lambda\left(
L_{0}\right)  v_{\lambda}^{+}=hv_{\lambda}^{+}\\\text{(since }\lambda\left(
L_{0}\right)  =h\text{)}}}+2\underbrace{L_{1}L_{-1}v_{\lambda}^{+}%
}_{=2hv_{\lambda}^{+}}\\
&  =4h^{2}v_{\lambda}^{+}+2h\underbrace{L_{1}L_{-1}v_{\lambda}^{+}%
}_{=2hv_{\lambda}^{+}}+4hv_{\lambda}^{+}=4h^{2}v_{\lambda}^{+}+4h^{2}%
v_{\lambda}^{+}+4hv_{\lambda}^{+}=\left(  8h^{2}+4h\right)  v_{\lambda}^{+}%
\end{align*}
and thus%
\begin{align*}
\left(  L_{-1}^{2}v_{\lambda}^{+},L_{1}^{2}v_{-\lambda}^{-}\right)   &
=\left(  -L_{1}L_{-1}^{2}v_{\lambda}^{+},L_{1}v_{-\lambda}^{-}\right)
=\left(  \underbrace{L_{1}^{2}L_{-1}^{2}v_{\lambda}^{+}}_{=\left(
8h^{2}+4h\right)  v_{\lambda}^{+}},v_{-\lambda}^{-}\right)  =\left(  \left(
8h^{2}+4h\right)  v_{\lambda}^{+},v_{-\lambda}^{-}\right) \\
&  =\left(  8h^{2}+4h\right)  \underbrace{\left(  v_{\lambda}^{+},v_{-\lambda
}^{-}\right)  }_{=1}=8h^{2}+4h.
\end{align*}


Similarly, we compute the other two entries of the matrix. The matrix thus
becomes%
\[
\left(
\begin{array}
[c]{cc}%
8h^{2}+4h & 6h\\
-6h & -\left(  4h+\dfrac{1}{2}c\right)
\end{array}
\right)  .
\]
The determinant of this matrix is%
\[
\det\left(  \left(  \cdot,\cdot\right)  _{2}\right)  =\left(  8h^{2}%
+4h\right)  \left(  -\left(  4h+\dfrac{1}{2}c\right)  \right)  -6h\left(
-6h\right)  =-4h\left(  \left(  2h+1\right)  \left(  4h+\dfrac{1}{2}c\right)
-9h\right)  .
\]
Notice the term $\left(  2h+1\right)  \left(  4h+\dfrac{1}{2}c\right)  -9h$:
The set of zeroes of this term is a hyperbola (an affine conic). The
determinant of $\left(  \cdot,\cdot\right)  _{2}$ thus vanishes on the union
of a line and a hyperbola. For every point $\left(  h,c\right)  $ lying on
this hyperbola, the highest-weight module $M_{h,c}^{+}$ has a nonzero singular
vector in degree $-2$ (this means a nonzero singular vector of the form
$\alpha L_{-2}v_{\lambda}^{+}+\beta L_{-1}^{2}v_{\lambda}^{+}$ for some
$\alpha,\beta\in\mathbb{C}$).

We will later discuss $\det\left(  \left(  \cdot,\cdot\right)  _{n}\right)  $
for generic $n$ (there is a precise formula for this: Kac determinant formula).

\subsubsection{Restricted dual modules}

\begin{definition}
Let $V=\bigoplus\limits_{i\in I}V\left[  i\right]  $ be a graded vector space
(where $I$ might be $\mathbb{Z}$, $\mathbb{N}$, $\mathbb{C}$ or any other
set). The \textit{restricted dual} $V^{\vee}$ of $V$ is defined to be the
direct sum $\bigoplus\limits_{i\in I}V\left[  i\right]  ^{\ast}$. This is a
vector subspace of the dual $V^{\ast}$ of $V$, but (in general) not the same
as $V^{\ast}$ unless the direct sum is finite.

If $V\left[  i\right]  $ is finite-dimensional for every $i\in I$, then
$V^{\vee\vee}\cong V$ canonically.

If $\mathfrak{g}$ is a $\mathbb{Z}$-graded Lie algebra, and $V$ is a
$\mathbb{C}$-graded $\mathfrak{g}$-module, then $V^{\vee}$ canonically becomes
a $\mathbb{C}$-graded $\mathfrak{g}$-module. (The grading on $V^{\vee}$ is
such that $V^{\vee}\left[  -i\right]  =V\left[  i\right]  ^{\ast}$ for every
$i\in\mathbb{C}$.)
\end{definition}

It is clear that:

\begin{proposition}
We have two mutually inverse antiequivalences of categories $\mathcal{O}%
^{+}\overset{\vee}{\rightarrow}\mathcal{O}^{-}$ and $\mathcal{O}%
^{-}\overset{\vee}{\rightarrow}\mathcal{O}^{+}$, each defined by mapping every
$\mathfrak{g}$-module in one category to its restricted dual.
\end{proposition}

We can view the form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$ as a linear map $M_{\lambda}%
^{+}\rightarrow\left(  M_{-\lambda}^{-}\right)  ^{\vee}$. The kernel of this
map is $J_{\lambda}^{+}$, and therefore, when $\mathfrak{g}$ is nondegenerate,
this map is an isomorphism for generic $\lambda$. In general, this map factors
as $%
%TCIMACRO{\TeXButton{diag}{\xymatrix{
%M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong} &
%\left(L^{-}_{-\lambda}\right)^{\vee} \arinj[r] & \left(M^{-}_{-\lambda}%
%\right)^{\vee}
%}}}%
%BeginExpansion
\xymatrix{
M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong} &
\left(L^{-}_{-\lambda}\right)^{\vee} \arinj[r] & \left(M^{-}_{-\lambda}%
\right)^{\vee}
}%
%EndExpansion
$.

\subsubsection{Involutions}

In many applications, we are not just working with a graded Lie algebra
$\mathfrak{g}$. Very often we additionally have a degree-reversing involution:

\begin{definition}
\label{def.invol}Let $\mathfrak{g}$ be a graded Lie algebra. Let
$\omega:\mathfrak{g}\rightarrow\mathfrak{g}$ be an involutive automorphism of
the Lie algebra $\mathfrak{g}$ ("involutive" means $\omega^{2}%
=\operatorname*{id}$) such that $\omega\left(  \mathfrak{g}_{i}\right)
=\mathfrak{g}_{-i}$ for all $i\in\mathbb{Z}$ and such that $\omega
\mid_{\mathfrak{g}_{0}}=-1$. Then, for every graded $\mathfrak{g}$-module $M$,
we can define a graded $\mathfrak{g}$-module $M^{c}$ as being the
$\mathfrak{g}$-module $M^{\omega}$ with opposite grading (i. e., the grading
on $M^{c}$ is defined by $M^{c}\left[  i\right]  =M^{\omega}\left[  -i\right]
$ for every $i$). Then, we have an equivalence of categories $\mathcal{O}%
^{+}\overset{\omega}{\rightarrow}\mathcal{O}^{-}$ which sends every
$\mathfrak{g}$-module $M\in\mathcal{O}^{+}$ to the $\mathfrak{g}$-module
$M^{c}\in\mathcal{O}^{-}$, and the quasiinverse equivalence of categories
$\mathcal{O}^{-}\overset{\omega}{\rightarrow}\mathcal{O}^{+}$ which does the
same thing.

So the functor $\mathcal{O}^{+}\overset{\vee}{\rightarrow}\mathcal{O}%
^{-}\overset{\omega}{\rightarrow}\mathcal{O}^{+}$ is an antiequivalence,
called the \textit{functor of contragredient module}. This functor allows us
to identify $\left(  M_{-\lambda}^{-}\right)  ^{\omega}$ with $M_{\lambda}%
^{+}$ (via the isomorphism $M_{\lambda}^{+}\rightarrow\left(  M_{-\lambda}%
^{-}\right)  ^{\omega}$ which sends $x\otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }v_{\lambda}^{+}$ to $\left(  U\left(
\omega\right)  \right)  \left(  x\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }v_{-\lambda}^{-}$ for every $x\in U\left(
\mathfrak{g}\right)  $), and thus to view the form $\left(  \cdot
,\cdot\right)  $ as a form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times
M_{\lambda}^{+}\rightarrow\mathbb{C}$. But this form is not symmetric; it is
contravariant: $\left(  av,w\right)  =-\left(  v,\omega\left(  a\right)
w\right)  $ and $\left(  v,aw\right)  =-\left(  \omega\left(  a\right)
v,w\right)  $.

This form can be viewed as a linear map $M_{\lambda}^{+}\rightarrow\left(
M_{\lambda}^{+}\right)  ^{c}$, which factors into $%
%TCIMACRO{\TeXButton{diag}{\xymatrix{
%M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong}
%& \left(L^{+}_{\lambda}\right)^{c} \arinj[r] & \left(M^{+}_{\lambda}%
%\right)^{c}
%}}}%
%BeginExpansion
\xymatrix{
M^{+}_{\lambda} \arsurj[r] & L^{+}_{\lambda} \ar[r]^-{\cong}
& \left(L^{+}_{\lambda}\right)^{c} \arinj[r] & \left(M^{+}_{\lambda}%
\right)^{c}
}%
%EndExpansion
$.
\end{definition}

Involutive automorphisms of $\mathfrak{g}$ satisfying the conditions of
Definition \ref{def.invol} are not uncommon; here are four examples:

\begin{proposition}
The $\mathbb{C}$-linear map $\omega:\mathcal{A}\rightarrow\mathcal{A}$ defined
by $\omega\left(  K\right)  =-K$ and $\omega\left(  a_{i}\right)  =-a_{-i}$
for every $i\in\mathbb{Z}$ is an involutive automorphism of the Lie algebra
$\mathcal{A}$. This automorphism $\omega$ satisfies the conditions of
Definition \ref{def.invol} (for $\mathfrak{g}=\mathcal{A}$).
\end{proposition}

\begin{proposition}
The $\mathbb{C}$-linear map $\omega:\operatorname*{Vir}\rightarrow
\operatorname*{Vir}$ defined by $\omega\left(  C\right)  =-C$ and
$\omega\left(  L_{i}\right)  =-L_{-i}$ for every $i\in\mathbb{Z}$ is an
involutive automorphism of the Lie algebra $\operatorname*{Vir}$. This
automorphism $\omega$ satisfies the conditions of Definition \ref{def.invol}
(for $\mathfrak{g}=\operatorname*{Vir}$).
\end{proposition}

\begin{proposition}
\label{prop.simple.omega}Let $\mathfrak{g}$ be a simple Lie algebra, graded
and presented as in Proposition \ref{prop.grad.g}. Then, there exists a unique
Lie algebra homomorphism $\omega:\mathfrak{g}\rightarrow\mathfrak{g}$
satisfying $\omega\left(  e_{i}\right)  =-f_{i}$, $\omega\left(  h_{i}\right)
=-h_{i}$ and $\omega\left(  f_{i}\right)  =-e_{i}$ for every $i\in\left\{
1,2,...,m\right\}  $. This automorphism $\omega$ satisfies the conditions of
Definition \ref{def.invol}.
\end{proposition}

\begin{proposition}
Let $\mathfrak{g}$ be a simple finite-dimensional Lie algebra, graded and
presented as in Proposition \ref{prop.grad.g}. Let $\widehat{\mathfrak{g}}$ be
the Kac-Moody Lie algebra defined in Definition \ref{def.kac}. Let $K$ denote
the element $\left(  0,1\right)  $ of $\mathfrak{g}\left[  t,t^{-1}\right]
\otimes\mathbb{C}=\widehat{\mathfrak{g}}$.

Let $\omega:\mathfrak{g}\rightarrow\mathfrak{g}$ be defined as in Proposition
\ref{prop.simple.omega}. Then, the $\mathbb{C}$-linear map $\widehat{\omega
}:\widehat{\mathfrak{g}}\rightarrow\widehat{\mathfrak{g}}$ defined by
$\widehat{\omega}\left(  a\cdot t^{j}\right)  =\omega\left(  a\right)  t^{-j}$
for every $a\in\mathfrak{g}$ and $j\in\mathbb{N}$, and $\widehat{\omega
}\left(  K\right)  =-K$, is an involutive automorphism of the Lie algebra
$\widehat{\mathfrak{g}}$. This automorphism $\widehat{\omega}$ satisfies the
conditions of Definition \ref{def.invol} (for $\widehat{\mathfrak{g}}$ and
$\widehat{\omega}$ instead of $\mathfrak{g}$ and $\omega$).
\end{proposition}

More generally:

\begin{proposition}
Let $\mathfrak{g}$ be a graded Lie algebra with a symmetric bilinear form
$\left(  \cdot,\cdot\right)  $ of degree $0$ invariant under the Lie bracket.
Let $\widehat{\mathfrak{g}}$ be the Lie algebra defined in Definition
\ref{def.loop}. Let $K$ denote the element $\left(  0,1\right)  $ of
$\mathfrak{g}\left[  t,t^{-1}\right]  \otimes\mathbb{C}=\widehat{\mathfrak{g}%
}$. Give $\widehat{\mathfrak{g}}$ a grading which makes $K$ homogeneous of
degree $0$ and the multiplications by $t$ and $t^{-1}$ into graded maps.

Let $\omega:\mathfrak{g}\rightarrow\mathfrak{g}$ be an involutive automorphism
satisfying the conditions of Definition \ref{def.invol} (not to be confused
with the $2$-cocycle $\omega$ of Definition \ref{def.loop}). Then, the
$\mathbb{C}$-linear map $\widehat{\omega}:\widehat{\mathfrak{g}}%
\rightarrow\widehat{\mathfrak{g}}$ defined by $\widehat{\omega}\left(  a\cdot
t^{j}\right)  =\omega\left(  a\right)  t^{-j}$ for every $a\in\mathfrak{g}$
and $j\in\mathbb{N}$, and $\widehat{\omega}\left(  K\right)  =-K$, is an
involutive automorphism of the Lie algebra $\widehat{\mathfrak{g}}$. This
automorphism $\widehat{\omega}$ satisfies the conditions of Definition
\ref{def.invol} (for $\widehat{\mathfrak{g}}$ and $\widehat{\omega}$ instead
of $\mathfrak{g}$ and $\omega$).
\end{proposition}

\subsubsection{Unitary structures}

Over $\mathbb{C}$, it makes sense to study not only linear but also antilinear
maps. Sometimes, the latter actually enjoy even better properties of the
former (e. g., Hermitian forms are better behaved than complex-symmetric forms).

\begin{definition}
If $\mathfrak{g}$ and $\mathfrak{h}$ are two Lie algebras over a field $k$,
then a $k$-\textit{antihomomorphism} from $\mathfrak{g}$ to $\mathfrak{h}$
means a $k$-linear map $f:\mathfrak{g}\rightarrow\mathfrak{h}$ such that
$f\left(  \left[  x,y\right]  \right)  =-\left[  f\left(  x\right)  ,f\left(
y\right)  \right]  $ for all $x,y\in\mathfrak{g}$.
\end{definition}

\begin{definition}
In the following, an \textit{antiinvolution} of a complex Lie algebra
$\mathfrak{g}$ means an $\mathbb{R}$-antihomomorphism from $\mathfrak{g}$ to
$\mathfrak{g}$ which is simultaneously an involution.
\end{definition}

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra. Let $\dag:\mathfrak{g}%
\rightarrow\mathfrak{g}$ be an antilinear antiinvolution. This means that
$\dag$ is an $\mathbb{R}$-linear map and satisfies the relations%
\begin{align*}
\dag^{2}  &  =\operatorname*{id};\\
\left(  za\right)  ^{\dag}  &  =\overline{z}a^{\dag}%
\ \ \ \ \ \ \ \ \ \ \text{for all }z\in\mathbb{C}\text{ and }a\in
\mathfrak{g};\\
\left[  a,b\right]  ^{\dag}  &  =-\left[  a^{\dag},b^{\dag}\right]
\ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in\mathfrak{g}.
\end{align*}
(Here and in the following, we write $c^{\dag}$ for the image of an element
$c\in\mathfrak{g}$ under $\dag$.) Such a map $\dag$ is called a \textit{real
structure}, for the following reason: If $\dag$ is such a map, then we can
define a subspace $\mathfrak{g}_{\mathbb{R}}=\left\{  a\in\mathfrak{g}%
\ \mid\ a^{\dag}=-a\right\}  $ of $\mathfrak{g}$, and this $\mathfrak{g}%
_{\mathbb{R}}$ is a real Lie algebra such that $\mathfrak{g}\cong%
\mathfrak{g}_{\mathbb{R}}\otimes_{\mathbb{R}}\mathbb{C}$ as complex Lie
algebras. (It is said that $\mathfrak{g}_{\mathbb{R}}$ is a \textit{real form}
of $\mathfrak{g}$.)
\end{definition}

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra with a real structure $\dag$. If
$V$ is a $\mathfrak{g}$-module, we say that $V$ is \textit{Hermitian} if $V$
is equipped with a nondegenerate Hermitian form $\left(  \cdot,\cdot\right)  $
satisfying%
\[
\left(  av,w\right)  =\left(  v,a^{\dag}w\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}\text{, }v\in V\text{ and
}w\in V.
\]
The $\mathfrak{g}$-module $V$ is said to be \textit{unitary} if this form is
positive definite.
\end{definition}

The real Lie algebra $\mathfrak{g}_{\mathbb{R}}$ acts on a Hermitian module by
skew-Hermitian operators.

\begin{remark}
While we will not be studying Lie groups in this course, here are some facts
about them that explain why unitary $\mathfrak{g}$-modules are called "unitary":

If $\mathfrak{g}$ is a finite-dimensional Lie algebra, and $V$ is a unitary
$\mathfrak{g}$-module, then the Hilbert space completion of $V$ is a unitary
representation of the Lie group $G_{\mathbb{R}}=\exp\left(  \mathfrak{g}%
_{\mathbb{R}}\right)  $ corresponding to $\mathfrak{g}_{\mathbb{R}}$ by Lie's
Third Theorem. (Note that this Hilbert space completion of $V$ is $V$ itself
if $\dim V<\infty$.) This even holds for some infinite-dimensional
$\mathfrak{g}$ under sufficiently restrictive conditions.
\end{remark}

\begin{Convention}
In the following, when we will talk about real structures on graded Lie
algebras, we will always consider the situation when $\mathfrak{g}$ is a
graded Lie algebra, and the map $\dag$ reverses the degree (i. e., every
$j\in\mathbb{Z}$ satisfies $\dag\left(  \mathfrak{g}_{j}\right)
\subseteq\mathfrak{g}_{-j}$). In particular, $\dag\left(  \mathfrak{g}%
_{0}\right)  \subseteq\mathfrak{g}_{0}$. We also assume that $\mathfrak{g}%
_{0}$ is an abelian Lie algebra (but we don't need to require $\mathfrak{g}$
to be nondegenerate).
\end{Convention}

So let us consider this situation. Two definitions:

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra with a real structure $\dag$. Let
$V$ be a $\mathfrak{g}$-module. A Hermitian form $\left(  \cdot,\cdot\right)
$ on $V$ is said to be $\dag$\textit{-invariant} if and only if%
\[
\left(  av,w\right)  =\left(  v,a^{\dag}w\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathfrak{g}\text{, }v\in V\text{ and
}w\in V.
\]

\end{definition}

\begin{definition}
Let $\mathfrak{g}$ be a complex Lie algebra with a real structure $\dag$. For
every $f\in\mathfrak{g}_{0}^{\ast}$, we denote by $f^{\dag}$ the map
$\mathfrak{g}_{0}\rightarrow\mathbb{C},$ $x\mapsto\overline{f\left(  x^{\dag
}\right)  }$ (this map $f^{\dag}$ is easily seen to be $\mathbb{C}$-linear).
Let $\mathfrak{g}_{0\mathbb{R}}^{\ast}$ be the subset $\left\{  f\in
\mathfrak{g}_{0}^{\ast}\ \mid\ f^{\dag}=-f\right\}  $ of $\mathfrak{g}%
_{0}^{\ast}$. Then, it is easily seen that%
\[
\mathfrak{g}_{0\mathbb{R}}^{\ast}=\left\{  f\in\mathfrak{g}_{0}^{\ast}%
\ \mid\ f\left(  \mathfrak{g}_{0\mathbb{R}}\right)  \subseteq\mathbb{R}%
\right\}  .
\]
Hence, we get an $\mathbb{R}$-bilinear form $\mathfrak{g}_{0\mathbb{R}}^{\ast
}\times\mathfrak{g}_{0\mathbb{R}}\rightarrow\mathbb{R},$ $\left(  f,a\right)
\mapsto f\left(  a\right)  $, which enables us to identify $\mathfrak{g}%
_{0\mathbb{R}}^{\ast}$ with the dual space of the $\mathbb{R}$-vector space
$\mathfrak{g}_{0\mathbb{R}}$. (More precisely, we have an isomorphism from
$\mathfrak{g}_{0\mathbb{R}}^{\ast}$ to the dual space of the $\mathbb{R}%
$-vector space $\mathfrak{g}_{0\mathbb{R}}$. This isomorphism sends every
$f\in\mathfrak{g}_{0\mathbb{R}}^{\ast}$ to the map $f\mid_{\mathfrak{g}%
_{0\mathbb{R}}}$ (with target restricted to $\mathbb{R}$), and conversely, the
preimage of any $\mathbb{R}$-linear map $F:\mathfrak{g}_{0\mathbb{R}%
}\rightarrow\mathbb{R}$ is the $\mathbb{C}$-linear map $f\in\mathfrak{g}%
_{0\mathbb{R}}^{\ast}$ given by%
\[
f\left(  a\right)  =F\left(  \dfrac{a-a^{\dag}}{2}\right)  +iF\left(
\dfrac{a+a^{\dag}}{2i}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }%
a\in\mathfrak{g}_{0}.
\]
)

The elements of $\mathfrak{g}_{0\mathbb{R}}^{\ast}$ are said to be
\textit{real}.
\end{definition}

\begin{proposition}
\label{prop.M+l.unitary}If $\lambda\in\mathfrak{g}_{0\mathbb{R}}^{\ast}$, then
the $\mathfrak{g}$-module $M_{\lambda}^{+}$ carries a $\dag$-invariant
Hermitian form satisfying $\left(  v_{\lambda}^{+},v_{\lambda}^{+}\right)  =1$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.M+l.unitary}.} In the following,
whenever $U$ is a $\mathbb{C}$-vector space, we will denote by $\overline{U}$
the $\mathbb{C}$-vector space which is identical to $U$ as a set, but with the
$\mathbb{C}$-vector structure twisted by complex conjugation.

The antilinear $\mathbb{R}$-Lie algebra homomorphism $-\dag:\mathfrak{g}%
\rightarrow\mathfrak{g}$ can be viewed as a $\mathbb{C}$-Lie algebra
homomorphism $-\dag:\mathfrak{g}\rightarrow\overline{\mathfrak{g}}$, and thus
induces a $\mathbb{C}$-algebra homomorphism $U\left(  -\dag\right)  :U\left(
\mathfrak{g}\right)  \rightarrow U\left(  \overline{\mathfrak{g}}\right)  $.
Since $U\left(  \overline{\mathfrak{g}}\right)  \cong\overline{U\left(
\mathfrak{g}\right)  }$ canonically as $\mathbb{C}$-algebras (because taking
the universal enveloping algebra commutes with base change)\footnote{Warning:
This isomorphism $U\left(  \overline{\mathfrak{g}}\right)  \rightarrow
\overline{U\left(  \mathfrak{g}\right)  }$ sends $i\cdot1_{U\left(
\overline{\mathfrak{g}}\right)  }$ to $-i\cdot1_{U\left(  \mathfrak{g}\right)
}$.}, we can thus consider this $U\left(  -\dag\right)  $ as a $\mathbb{C}%
$-algebra homomorphism $U\left(  \mathfrak{g}\right)  \rightarrow
\overline{U\left(  \mathfrak{g}\right)  }$. This, in turn, can be viewed as an
antilinear $\mathbb{R}$-algebra homomorphism $U\left(  -\dag\right)  :U\left(
\mathfrak{g}\right)  \rightarrow U\left(  \mathfrak{g}\right)  $.

Let $\lambda\in\mathfrak{g}_{0\mathbb{R}}^{\ast}$. Let $\left(  M_{-\lambda
}^{-}\right)  ^{-\dag}$ be the $\mathfrak{g}$-module $M_{-\lambda}^{-}$
twisted by the isomorphism $-\dag:\mathfrak{g}\rightarrow\mathfrak{g}$ of
$\mathbb{R}$-Lie algebras. Then, $\left(  M_{-\lambda}^{-}\right)  ^{-\dag}$
is a module over the $\mathbb{R}$-Lie algebra $\mathfrak{g}$, but not a module
over the $\mathbb{C}$-Lie algebra $\mathfrak{g}$, since it satisfies $\left(
za\right)  \rightharpoonup v=\overline{z}\left(  a\rightharpoonup v\right)  $
(rather than $\left(  za\right)  \rightharpoonup v=z\left(  a\rightharpoonup
v\right)  $) for all $z\in\mathbb{C}$, $a\in\mathfrak{g}$ and $v\in
M_{-\lambda}^{-}$ (where $\rightharpoonup$ denotes the action of
$\mathfrak{g}$). However, this can be easily transformed into a $\mathbb{C}%
$-Lie algebra action: Namely, $\overline{\left(  M_{-\lambda}^{-}\right)
^{-\dag}}$ is a module over the $\mathbb{C}$-Lie algebra $\mathfrak{g}$.

We have an isomorphism%
\begin{align*}
\overline{\left(  M_{-\lambda}^{-}\right)  ^{-\dag}}  &  \rightarrow
M_{\lambda}^{+},\\
x\otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }zv_{-\lambda
}^{-}  &  \mapsto U\left(  -\dag\right)  \left(  x\right)  \otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{-}\right)  }\overline{z}v_{\lambda}^{+}%
\end{align*}
of modules over the $\mathbb{C}$-Lie algebra $\mathfrak{g}$%
.\ \ \ \ \footnote{Here are some details on the definition of this
isomorphism:
\par
As $\mathbb{R}$-vector spaces, $\overline{\left(  M_{-\lambda}^{-}\right)
^{-\dag}}=M_{-\lambda}^{-}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }\mathbb{C}_{-\lambda}$ and
$M_{\lambda}^{+}=U\left(  \mathfrak{g}\right)  \otimes_{U\left(
\mathfrak{h}\oplus\mathfrak{n}_{-}\right)  }\mathbb{C}_{\lambda}$. Hence, we
can define an $\mathbb{R}$-linear map $\overline{\left(  M_{-\lambda}%
^{-}\right)  ^{-\dag}}\rightarrow M_{\lambda}^{+}$ that sends $x\otimes
_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  }zv_{-\lambda}^{-}$ to
$U\left(  -\dag\right)  \left(  x\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\overline{z}v_{\lambda}^{+}$ for every $x\in
U\left(  \mathfrak{g}\right)  $ and $z\in\mathbb{C}$ if we are able to show
that
\[
U\left(  -\dag\right)  \left(  xw\right)  \otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{-}\right)  }\overline{z}v_{\lambda}^{+}=U\left(
-\dag\right)  \left(  x\right)  \otimes_{U\left(  \mathfrak{h}\oplus
\mathfrak{n}_{-}\right)  }\overline{wz}v_{\lambda}^{+}%
\ \ \ \ \ \ \ \ \ \ \text{for all }x\in U\left(  \mathfrak{g}\right)  \text{,
}w\in U\left(  \mathfrak{h}\oplus\mathfrak{n}_{+}\right)  \text{ and }%
z\in\mathbb{C}.
\]
But showing this is rather easy (left to the reader), and thus we get an
$\mathbb{R}$-linear map $\overline{\left(  M_{-\lambda}^{-}\right)  ^{-\dag}%
}\rightarrow M_{\lambda}^{+}$ that sends $x\otimes_{U\left(  \mathfrak{h}%
\oplus\mathfrak{n}_{+}\right)  }zv_{-\lambda}^{-}$ to $U\left(  -\dag\right)
\left(  x\right)  \otimes_{U\left(  \mathfrak{h}\oplus\mathfrak{n}_{-}\right)
}\overline{z}v_{\lambda}^{+}$ for every $x\in U\left(  \mathfrak{g}\right)  $
and $z\in\mathbb{C}$. This map is easily seen to be $\mathfrak{g}$-linear and
$\mathbb{C}$-linear, so it is a homomorphism of modules over $\mathbb{C}$-Lie
algebra $\mathfrak{g}$. Showing that it is an isomorphism is easy as well (one
just has to construct its inverse).} Hence, $M_{-\lambda}^{-}\cong%
\overline{\left(  M_{\lambda}^{+}\right)  ^{-\dag}}$.

Hence, our bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}%
\rightarrow\mathbb{C}$ can be viewed as a bilinear form $M_{\lambda}^{+}%
\times\overline{M_{\lambda}^{+}}\rightarrow\mathbb{C}$, id est, as a
sesquilinear form $M_{\lambda}^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}%
$. This sesquilinear form is the unique sesquilinear Hermitian form
$M_{\lambda}^{+}\times M_{\lambda}^{+}\rightarrow\mathbb{C}$ satisfying
$\left(  v_{\lambda}^{+},v_{\lambda}^{+}\right)  =1$\ \ \ \ \footnote{This can
be easily derived from Proposition \ref{prop.invform} \textbf{(a)}, which
claims that our form $\left(  \cdot,\cdot\right)  :M_{\lambda}^{+}\times
M_{-\lambda}^{-}\rightarrow\mathbb{C}$ is the unique $\mathfrak{g}$-invariant
bilinear form $M_{\lambda}^{+}\times M_{-\lambda}^{-}\rightarrow\mathbb{C}$
satisfying $\left(  v_{\lambda}^{+},v_{-\lambda}^{-}\right)  =1$.}. As a
consequence, this sesquilinear form can be easily seen to be Hermitian
symmetric, i. e., to satisfy%
\[
\left(  v,w\right)  =\overline{\left(  w,v\right)  }%
\ \ \ \ \ \ \ \ \ \ \text{for all }v\in M_{\lambda}^{+}\text{ and }w\in
M_{\lambda}^{+}.
\]
\footnote{In fact, the form which sends $v\times w$ to $\overline{\left(
w,v\right)  }$ is also a sesquilinear Hermitian form $M_{\lambda}^{+}\times
M_{\lambda}^{+}\rightarrow\mathbb{C}$ satisfying $\left(  v_{\lambda}%
^{+},v_{\lambda}^{+}\right)  =1$, so that by uniqueness, it must be identical
with the form which sends $v\times w$ to $\left(  v,w\right)  $.}

However, this form can be degenerate. Its kernel is $J_{\lambda}^{+}$, so it
descends to a nondegenerate Hermitian form on $L_{\lambda}^{+}$. Thus, we get:

\begin{proposition}
If $\lambda$ is real (this means that $\lambda\in\mathfrak{g}_{0\mathbb{R}%
}^{\ast}$), then $L_{\lambda}^{+}$ carries a $\dag$-invariant nondegenerate
Hermitian form. Different degrees in $L_{\lambda}^{+}$ are orthogonal with
respect to this form.
\end{proposition}

A reasonable (and, in most cases, difficult and interesting) question to ask
is the following: For which $\lambda$ is $L_{\lambda}^{+}$ unitary?

We are going to address this question in some cases and give hints in some
others, leaving many more unanswered.

First, let us give several examples of complex Lie algebras $\mathfrak{g}$
with antilinear antiinvolutions $\dag:\mathfrak{g}\rightarrow\mathfrak{g}$:

\begin{proposition}
We can define an antilinear map $\dag:\mathcal{A}\rightarrow\mathcal{A}$
by\ $a_{i}^{\dag}=a_{-i}$ for all $i\in\mathbb{Z}$. This map is an antilinear
antiinvolution of the Heisenberg algebra $\mathcal{A}$.
\end{proposition}

\begin{proposition}
One can define an antilinear map $\dag:\mathfrak{sl}_{2}\rightarrow
\mathfrak{sl}_{2}$ by$\ e^{\dag}=f,\ f^{\dag}=e,\ h^{\dag}=h$. This map is an
antilinear antiinvolution of the Lie algebra $\mathfrak{sl}_{2}$.
\end{proposition}

More generally:

\begin{proposition}
Let $\mathfrak{g}$ be a simple finite-dimensional Lie algebra. Using the
Chevalley generators $e_{1}$, $e_{2}$, $...$, $e_{m}$, $f_{1}$, $f_{2}$,
$...$, $f_{m}$, $h_{1}$, $h_{2}$, $...$, $h_{m}$ of Proposition
\ref{prop.grad.g}, we can define an antilinear map $\dag:\mathfrak{g}%
\rightarrow\mathfrak{g}$ by $e_{i}^{\dag}=f_{i},$ $f_{i}^{\dag}=e_{i}%
,\ h_{i}^{\dag}=h_{i}$ for all $i\in\left\{  1,2,...,m\right\}  $. This map is
an antilinear antiinvolution of the Lie algebra $\mathfrak{g}$.
\end{proposition}

\begin{proposition}
We can define an antilinear map $\dag:\operatorname*{Vir}\rightarrow
\operatorname*{Vir}$ by $L_{i}^{\dag}=L_{-i}$ for all $i\in\mathbb{Z}$, and
$C^{\dag}=C$. This map is an antilinear antiinvolution of the Virasoro algebra
$\operatorname*{Vir}$.
\end{proposition}

\begin{proposition}
If $\mathfrak{g}$ is a Lie algebra with an antilinear antiinvolution
$\dag:\mathfrak{g}\rightarrow\mathfrak{g}$ and with a symmetric bilinear form
$\left(  \cdot,\cdot\right)  $ of degree $0$ invariant under the Lie bracket,
then we can define an antilinear map $\dag:\widehat{\mathfrak{g}}%
\rightarrow\widehat{\mathfrak{g}}$ (where $\widehat{\mathfrak{g}}$ is the Lie
algebra defined in Definition \ref{def.loop}) by $\left(  at^{n}\right)
^{\dag}=a^{\dag}\cdot t^{-n}$ for every $a\in\mathfrak{g}$ and $t\in
\mathbb{Z}$, and by $K^{\dag}=K$ (where $K$ denotes the element $\left(
0,1\right)  $ of $\mathfrak{g}\left[  t,t^{-1}\right]  \otimes\mathbb{C}%
=\widehat{\mathfrak{g}}$). This map $\dag$ is an antilinear involution of the
Lie algebra $\widehat{\mathfrak{g}}$.
\end{proposition}

As for examples of Hermitian modules: The $\operatorname*{Vir}$-module
$L_{h,c}$ for $h,c\in\mathbb{R}$ has a $\dag$-invariant nondegenerate
Hermitian form.

\begin{proposition}
\label{prop.unitrick}Let $V$ be a unitary representation in Category
$\mathcal{O}^{+}$. Then, $V$ is completely reducible (i. e., the
representation $V$ is a direct sum of irreducible representations).
\end{proposition}

To prove this, we will use a lemma:

\begin{lemma}
\label{lem.unitrick}If $V$ is a highest weight representation, and $V$ has a
nondegenerate $\dag$-invariant Hermitian form, then $V$ is irreducible. (A
"highest weight representation" means a quotient of $M_{\lambda}^{+}$ by a
graded submodule for some $\lambda$.)
\end{lemma}

\textit{Proof of Lemma \ref{lem.unitrick}.} Such a form is unique up to
scaling (by Proposition \ref{prop.invform} \textbf{(c)}), and thus must be the
form defined in Proposition \ref{prop.invform} \textbf{(a)}. But if this form
is nondegenerate, $V$ is irreducible. Lemma \ref{lem.unitrick} is proven.

\textit{Proof of Proposition \ref{prop.unitrick}.} Take a homogeneous vector
$v\in V$ of maximal degree. ("Maximal" means "maximal in real part".) Let $v$
be an eigenvector of $\mathfrak{g}_{0}$ with eigenvalue $\lambda$. Consider
the submodule of $V$ generated by $v$. By Lemma, this submodule is $\cong
L_{\lambda_{1}}^{+}$ (since $\mathfrak{g}_{j}v=0$ for $j>0$, so that this
submodule is highest weight). Let $V_{1}$ be the orthogonal complement of
$L_{\lambda_{1}}^{+}$. Then, $V=L_{\lambda_{1}}^{+}\oplus V_{1}$. Now take a
vector in $V_{1}$ etc. etf.. Since the degrees of $V$ lie in finitely many
arithmetic progressions, and homogeneous subspaces have finite dimension, this
process is exhaustive, so we obtain $V=L_{\lambda_{1}}^{+}\oplus
L_{\lambda_{2}}^{+}\oplus...$.

\begin{remark}
In this decomposition, every irreducible object of Category $\mathcal{O}^{+}$
occurs finitely many times.
\end{remark}

\section{Representation theory: concrete examples}

\subsection{Representations of $\operatorname*{Vir}$ on $F_{\mu}$}

From Lemma \ref{lem.WtoDerA}, we know a Lie algebra action of $W$ on
$\mathcal{A}$. Thus, we get a semidirect product $W\ltimes\mathcal{A}$. On the
other hand, recall that $\mathcal{A}$ acts on the $\mathcal{A}_{0}$-module
$F_{\mu}$.

Can we extend this representation $F_{\mu}$ of $\mathcal{A}$ to a
representation of the semidirect product $W\ltimes\mathcal{A}$ ?

This question splits into two questions:

\textbf{1)} Can we find operators $L_{n}:F_{\mu}\rightarrow F_{\mu}$ such that
$\left[  L_{n},a_{m}\right]  =-ma_{n+m}$ ? (This is abuse for $\left[
L_{n},a_{m}\mid_{F_{\mu}}\right]  =-ma_{n+m}\mid_{F_{\mu}}$.)

\textbf{2)} Do they satisfy $\left[  L_{n},L_{m}\right]  =\left(  n-m\right)
L_{n+m}$.

Answers:

\textbf{1)} Yes, and moreover, these operators are unique up to adding a
constant. (For uniqueness: if $L_{n}^{\prime}$ and $L_{n}^{\prime\prime}$,
then $L_{n}^{\prime}-L_{n}^{\prime\prime}$ commutes with all $a_{m}$, and thus
is constant by Dixmier.)

\textbf{2)} No, but almost.

So the $\mathcal{A}$-module $F_{\mu}$ does not extend to a $W\ltimes
\mathcal{A}$-module, but extends to a $\operatorname*{Vir}\ltimes\mathcal{A}$-module.

\textit{Proof of the answers:} "Formally", one could write
\[
L_{n}=\dfrac{1}{2}\sum\limits_{m\in\mathbb{Z}}a_{-m}a_{n+m},
\]
and this would "formally" work. But this sum does not make much sense: it is
an infinite sum, and infinitely many of its terms yield nonzero values when
applied to a given vector.\footnote{For example, $L_{0}=\dfrac{1}{2}%
\sum\limits_{m\in\mathbb{Z}}a_{-m}a_{m}$. Applied to the vector $1\in F_{0}$,
this would give $L_{0}1=\dfrac{1}{2}\sum\limits_{m\in\mathbb{Z}}a_{-m}a_{m}1$.
The terms for $m>0$ will get killed, but the terms for $m<0$ will survive. The
sum would become
\begin{align*}
L_{0}1  &  =\dfrac{1}{2}\left(  a_{1}a_{-1}1+a_{2}a_{-2}1+a_{3}a_{-3}%
1+...\right) \\
&  =\dfrac{1}{2}\left(  1\dfrac{\partial}{\partial x_{1}}x_{1}+2\dfrac
{\partial}{\partial x_{2}}x_{2}+3\dfrac{\partial}{\partial x_{3}}%
x_{3}+...\right)  =\dfrac{1}{2}\left(  1+2+3+...\right)  .
\end{align*}
Unless we interpret $1+2+3+...$ as $-\dfrac{1}{12}$ (which we are going to do
in some sense: the modified formulae further below include $-\dfrac{1}{12}$
factors), this makes no sense.} We thus must modify this form slightly.

In order to modify it, we define the so-called \textit{normal ordering}:
Define%
\[
:a_{m}a_{n}:\ =\ \left\{
\begin{array}
[c]{c}%
a_{m}a_{n},\ \ \ \ \ \ \ \ \ \ \text{if }m\leq n;\\
a_{n}a_{m},\ \ \ \ \ \ \ \ \ \ \text{if }m>n
\end{array}
\right.  .
\]
Note that $:a_{m}a_{n}:\ =a_{m}a_{n}$ unless $m=-n$.

More generally, set%
\[
:a_{n_{1}}a_{n_{2}}...a_{n_{k}}:\ =\left(  \text{product with subscripts put
in increasing order}\right)  .
\]


Now, the true definition of $L_{n}$ will be%
\[
L_{n}=\dfrac{1}{2}\sum\limits_{m\in\mathbb{Z}}:a_{-m}a_{n+m}:.
\]
This sum is still infinite, but it becomes finite when applied to any vector
$v\in F_{\mu}$, because both very small negative $m$ and very large positive
$m$ satisfy $:a_{-m}a_{n+m}:v=0$. We could even make sense of $\dfrac{1}%
{2}\sum\limits_{m\in\mathbb{Z}}:a_{-m}a_{n+m}:$ in a suitable completion of
the universal enveloping algebra of $\mathcal{A}$ (although not in $U\left(
\mathcal{A}\right)  $ itself).

Note that if $n\neq0$, the old definition $L_{n}=\dfrac{1}{2}\sum
\limits_{m\in\mathbb{Z}}a_{-m}a_{n+m}$ is still correct. But if $n=0$, our new
definition differs from the old one in making sense.

It can be checked (e. g. homework problem set 2 exercise 1) that question
\textbf{1)} is now satisfied.

Now let us check \textbf{2)}. We have%
\[
\left[  \left[  L_{n},L_{m}\right]  -\left(  n-m\right)  L_{n+m},a_{k}\right]
=0
\]
since $W$ acts on $\mathcal{A}$. Thus, $\left[  L_{n},L_{m}\right]  -\left(
n-m\right)  L_{n+m}$ is a constant (by Dixmier). It is in fact $0$ if
$m+n\neq0$ (since a homogeneous constant of degree $\neq0$ must be $=0$). So
we have%
\[
\left[  L_{n},L_{m}\right]  -\left(  n-m\right)  L_{n+m}=\gamma_{n}%
\delta_{n,-m}\ \ \ \ \ \ \ \ \ \ \text{for some }\gamma_{n}\in\mathbb{C}.
\]
These $\gamma_{n}$ define a central extension, etc., thus cocycle. We have%
\[
\left(  \left[  L_{1},L_{-1}\right]  -2L_{0}\right)  1=\left(  L_{1}%
L_{-1}-2L_{0}\right)  1=0\ \ \ \ \ \ \ \ \ \ \left(  \text{after some
computation}\right)  .
\]
Thus, $\gamma_{n}=c\dfrac{n^{3}-n}{12}$ for some global constant
$c\in\mathbb{C}$. To compute $c$, we calculate%
\[
\left(  \left[  L_{2},L_{-2}\right]  -4L_{0}\right)  1=\left(  L_{2}%
L_{-2}-4L_{0}\right)  1=\dfrac{1}{4}\left(  a_{1}^{2}.............\right)
\]
[...] $c=1$.

We thus have proven:

\begin{proposition}
The $\mathcal{A}$-action on $F_{\mu}$ extends (essentially uniquely) to an
action of $\operatorname*{Vir}\ltimes\mathcal{A}$ on $F_{\mu}$ with $C$ acting
as $1$.
\end{proposition}

This is the reason for the normalization with $-\dfrac{1}{12}$.

\textbf{Generalization (homework problem set 2 exercise 1):} If $\lambda
\in\mathbb{C}$, then we can define%
\begin{align*}
\widetilde{L}_{n}  &  =\dfrac{1}{2}\sum\limits_{m\in\mathbb{Z}}:a_{-m}%
a_{m+n}:+i\lambda na_{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{for }i=\sqrt
{-1}\right)  \ \ \ \ \ \ \ \ \ \ \text{for }n\neq0;\\
\widetilde{L}_{0}  &  =\dfrac{\mu^{2}}{2}+\dfrac{\lambda^{2}}{2}%
+\sum\limits_{j>0}a_{-j}a_{j}.
\end{align*}
This defines an action of $\operatorname*{Vir}$ on $F_{\mu}$ with
$c=1+12\lambda^{2}$.

\begin{proposition}
If $\mu\in\mathbb{R}$, then $F_{\mu}$ is a unitary representation of
$\mathcal{A}$.
\end{proposition}

\textit{Proof.} Let $n_{1}+...+n_{k}=m_{1}+...+m_{k}$. Then,%
\[
\left\langle x_{1}^{n_{1}}...x_{k}^{n_{k}},x_{1}^{m_{1}}...x_{k}^{m_{k}%
}\right\rangle =\left(  k\dfrac{\partial}{\partial x_{k}}\right)  ^{m_{k}%
}...\left(  1\dfrac{\partial}{\partial x_{1}}\right)  ^{m_{1}}x_{1}^{n_{1}%
}...x_{k}^{n_{k}}=\delta_{\overrightarrow{n},-\overrightarrow{m}}\cdot
\prod\limits_{j=1}^{k}j^{m_{j}}\prod\limits_{j=1}^{k}m_{j}!>0.
\]
Thus, the matrix of the form is diagonal with positive diagonal entries.

\begin{corollary}
If $\mu,\lambda\in\mathbb{R}$, then the $\operatorname*{Vir}$-representation
on $F_{\mu}$ given by $\widetilde{L}_{n}$ is unitary.
\end{corollary}

\textit{Proof.}
\begin{align*}
\widetilde{L}_{n}^{\dag}  &  =\dfrac{1}{2}\sum\limits_{m}:a_{-m}a_{n+m}%
:^{\dag}+\left(  i\lambda na_{n}\right)  ^{\dag}\\
&  =\dfrac{1}{2}\sum\limits_{m}:a_{-m}a_{-n-m}:-i\lambda na_{-n}%
=\widetilde{L}_{-n}.
\end{align*}


\begin{coro}
The $\operatorname*{Vir}$-representation $F_{\mu}$ is completely reducible for
$\mu\in\mathbb{R}$.
\end{coro}

Now, $L_{0}1=\dfrac{\mu^{2}+\lambda^{2}}{2}1$ and $C1=\left(  1+12\lambda
^{2}\right)  1$. Thus, the Verma module $M_{h,c}:=M_{h,c}^{+}$ for
$h=\dfrac{\mu^{2}+\lambda^{2}}{2}$ and $c=1+12\lambda^{2}$ maps to $F_{\mu}$
with $v_{h,c}\mapsto1$.

\begin{proposition}
For Weil generic $\mu$ and $\lambda$, this is an isomorphism.
\end{proposition}

\textit{Proof.} The dimension of the degree-$n$ part of both modules is
$p\left(  n\right)  $. The map has degree $0$. Hence, if it is injective, it
is surjective. But for Weil generic $\mu$ and $\lambda$, the module $M_{h,c}$
is irreducible, so the map is injective.

\begin{corollary}
For Weil generic $\mu$ and $\lambda$ in $\mathbb{R}$, the representation
$M_{\dfrac{\mu^{2}+\lambda^{2}}{2},1+12\lambda^{2}}$ is unitary.

For any $\mu$ and $\lambda$ in $\mathbb{R}$, the representation $L_{\dfrac
{\mu^{2}+\lambda^{2}}{2},1+12\lambda^{2}}$ is unitary.

In other words, $L_{h,c}$ is unitary if $c\geq1$ and $h\geq\dfrac{c-1}{24}$.
\end{corollary}

\subsection{Quantum fields}

For us, the $a_{n}$ etc. (vectors in Lie algebras) were primary objects. For
physicists, instead, certain generating functions built of these objects are
primary objects, since they are closer to what they observe. They are called
\textit{quantum fields}.

For examples, in $\mathcal{A}$, we set $a\left(  z\right)  =\sum
\limits_{n\in\mathbb{Z}}a_{n}z^{-n-1}$ (formal sum infinite in both
directions). Note that if we apply $a\left(  z\right)  $ to some vector in
$F_{\mu}$, we get a sum infinite in one direction only.

Physicists call $a\left(  z\right)  $ a quantum field (more precisely, a free
bosonic field).

We have $\left[  a\left(  z\right)  ,a\left(  w\right)  \right]
=\sum\limits_{n\in\mathbb{Z}}nz^{-n-1}w^{n-1}$ in $F_{\mu}$.

We can obtain this series by differentiating a more basic series:%
\[
\delta\left(  w-z\right)  :=\sum_{n\in\mathbb{Z}}z^{-n-1}w^{n}.
\]
This is just a formal series. Why do we call it $\delta\left(  w-z\right)  $ ?
Because in analysis, $\int\delta\left(  x-y\right)  f\left(  y\right)
dy=f\left(  x\right)  $; this series satisfies a similar property (namely,
$\dfrac{1}{2\pi i}\oint\limits_{\left\vert z\right\vert =1}\delta\left(
w-z\right)  f\left(  z\right)  dz=f\left(  y\right)  $ formally by using the
rule $\dfrac{1}{2\pi i}\oint\limits_{\left\vert z\right\vert =1}%
z^{-n-1}f\left(  z\right)  dz=f_{n}$ where $f=\sum\limits_{n\in\mathbb{Z}%
}f_{n}z^{n}$). And now, $\left[  a\left(  z\right)  ,a\left(  w\right)
\right]  =\sum\limits_{n\in\mathbb{Z}}nz^{-n-1}w^{n-1}$ becomes $\left[
a\left(  z\right)  ,a\left(  w\right)  \right]  =\partial_{w}\delta\left(
w-z\right)  =:\delta^{\prime}\left(  w-z\right)  $.

Something more interesting comes out for the Virasoro algebra: Set $T\left(
z\right)  =\sum\limits_{n\in\mathbb{Z}}L_{n}z^{-n-2}$. Then, \textit{in the
Witt algebra}, we have%
\begin{align*}
\left[  T\left(  z\right)  ,T\left(  w\right)  \right]   &  =\sum
\limits_{n,m}\left(  n-m\right)  L_{n+m}z^{-n-2}w^{-m-2}\\
&  =\sum_{k,m}L_{k}\underbrace{\left(  k-2m\right)  }_{=\left(  k+2\right)
-\left(  2m+2\right)  }z^{m-k-2}w^{-m-2}\\
&  =\left(  \sum_{k}L_{k}\left(  k+2\right)  z^{-k-3}\right)  \left(  \sum
_{m}z^{m+1}w^{-m-2}\right) \\
&  \ \ \ \ \ \ \ \ \ \ +\left(  \sum_{k}L^{k}z^{-k-2}\right)  \left(  \sum
_{m}\left(  -2m-2\right)  z^{m}w^{-m-2}\right) \\
&  =2T\left(  z\right)  \delta^{\prime}\left(  w-z\right)  -T^{\prime}\left(
z\right)  \delta\left(  w-z\right)  .
\end{align*}
Note that this formula defines the Lie bracket of the Witt algebra. This is
how physicists would define the Witt algebra.

For the Virasoro algebra: add%
\[
\sum_{n}\dfrac{n^{3}-n}{12}Cz^{-n-2}w^{n-2}=\dfrac{c}{12}\delta^{\prime
\prime\prime}\left(  w-z\right)  .
\]
Together:%
\[
\left[  T\left(  z\right)  ,T\left(  w\right)  \right]  =-T^{\prime}\left(
z\right)  \delta\left(  w-z\right)  +2T\left(  z\right)  \delta^{\prime
}\left(  w-z\right)  +\dfrac{c}{12}\delta^{\prime\prime\prime}\left(
w-z\right)  .
\]


\textbf{Exercise:} For $\operatorname*{Vir}\ltimes\mathcal{A}$, we have in
$F_{\mu}$:%
\[
\left[  T\left(  z\right)  ,a\left(  w\right)  \right]  =a\left(  z\right)
\delta^{\prime}\left(  w-z\right)  .
\]


Recall%
\[
:a_{m}a_{n}:\ =\ \left\{
\begin{array}
[c]{c}%
a_{m}a_{n},\ \ \ \ \ \ \ \ \ \ \text{if }m\leq n;\\
a_{n}a_{m},\ \ \ \ \ \ \ \ \ \ \text{if }m>n
\end{array}
\right.  .
\]
So we can write $:a\left(  z\right)  a\left(  w\right)  :$. This is equivalent
to the homework sheet.

Also, more importantly, we can write $:a\left(  z\right)  ^{2}:$ (defined as
$:a\left(  z\right)  a\left(  z\right)  :$), but not $a\left(  z\right)  ^{2}$.

[...] [homework sheet definition switches if $m<0$

Now we can write $T\left(  z\right)  =\dfrac{1}{2}:a\left(  z\right)  ^{2}:$.

[...] [IMPORTANT!\ THE\ DEFINITION\ IN\ THIS\ TEXT\ PERTAINS\ ONLY\ TO\ THE\ HEISENBERG\ ALGEBRA.\ THE\ DEFINITION\ ON\ THE\ EXERCISE\ SHEET\ IS\ GENERAL.]

\textbf{Exercise 1.} For any $\beta\in\mathbb{C}$, the formula $T\left(
v\right)  =\dfrac{1}{2}:a\left(  z\right)  ^{2}:+\beta a^{\prime}\left(
z\right)  $ defines a representation of $\operatorname*{Vir}$ on $F_{\mu}$
with $c=1-12\beta^{2}$.

\textbf{Exercise 2.} For any $\beta\in\mathbb{C}$, there is a homomorphism
$\varphi_{\beta}:\operatorname*{Vir}\rightarrow\operatorname*{Vir}%
\ltimes\mathcal{A}$ (a splitting of the projection $\operatorname*{Vir}%
\ltimes\mathcal{A}\rightarrow\operatorname*{Vir}$) given by%
\begin{align*}
\varphi_{\beta}\left(  L_{n}\right)   &  =L_{n}+\beta a_{n}%
,\ \ \ \ \ \ \ \ \ \ n\neq0;\\
\varphi_{\beta}\left(  L_{0}\right)   &  =L_{0}+\beta a_{0}+\dfrac{\beta^{2}%
}{2}K.
\end{align*}


\textbf{Exercise 3.} If we twist the action of Exercise 1 by this map, we
recover the action of problem 1 of Homework 2 for $\beta=i\lambda$.

\subsection{More on unitary representations}

\textbf{Last time:} $L_{\dfrac{\mu^{2}+\lambda^{2}}{2},1+12\lambda^{2}}$ is
unitary (for $\lambda,\mu\in\mathbb{R}$), so $L_{h,c}$ is unitary if $c\geq1$
and $h\geq\dfrac{c-1}{24}$.

We can extend this as follows: $L_{0,1}^{\otimes m-1}\otimes L_{h,c}$ is
unitary and has a highest weight vector $v_{0,1}^{\otimes m-1}\otimes v_{h,c}$
which has weight $\left(  h,c+m-1\right)  $. Hence, the representation
$L_{h,c+m-1}$ is unitary [why? use irreducibility of unitary modules and stuff].

Hence, $L_{h,c}$ is unitary if $c\geq m$ and $h\geq\dfrac{c-m}{24}$.

\begin{theorem}
In fact, $L_{h,c}$ is unitary if $c\geq1$ and $h\geq0$.
\end{theorem}

But this is harder to show.

This is still not an only-if. For example, $L_{0,0}$ is unitary (and $1$-dimensional).

\begin{proposition}
\label{prop.Lhc.unitary.triv}If $L_{h,c}$ is unitary, then $h\geq0$ and
$c\geq0$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.Lhc.unitary.triv}.} We have $\left(
L_{-n}v_{h,c},L_{-n}v_{h,c}\right)  \geq0$. But $\left(  L_{-n}v_{h,c}%
,L_{-n}v_{h,c}\right)  =\left(  \underbrace{L_{n}L_{-n}}_{=2nL_{0}%
+\dfrac{n^{3}-n}{12}C}v_{h,c},v_{h,c}\right)  =2nh+\dfrac{n^{3}-n}{12}c$. By
taking $n\rightarrow\infty$, we show $c\geq0$. By taking $n=1$, we get
$h\geq0$.

Let $\delta\in\left\{  0,\dfrac{1}{2}\right\}  $. Let $C_{\delta}$ be the
algebra of free fermions (for $\delta=0$ it is called Ramond sector; for
$\delta=\dfrac{1}{2}$ it is called Neveu-Schwarz sector). It is defined as%
\[
C_{\delta}=\left\langle
\begin{array}
[c]{c}%
\psi_{j}\ \mid\ j\in\delta+\mathbb{Z}\\
\mid\ \psi_{j}\psi_{k}+\psi_{k}\psi_{j}=\delta_{k,-j}%
\end{array}
\right\rangle .
\]
This is an infinite-dimensional Clifford algebra.

We have a representation $V_{\delta}$ of $C_{\delta}$: Namely, $V_{\delta
}=\wedge\left(  \xi_{n}\ \mid\ n\in\left(  \delta+\mathbb{Z}\right)  _{\geq
0}\right)  $. This is an infinite-dimensional spinor representation of the
above Clifford algebra. The action is given by%
\begin{align*}
\psi_{-n}  &  \mapsto\xi_{n}\ \ \ \ \ \ \ \ \ \ \text{for }n<0;\\
\psi_{n}  &  \mapsto\dfrac{\partial}{\partial\xi_{n}}%
\ \ \ \ \ \ \ \ \ \ \text{for }n>0;\\
\psi_{0}  &  \mapsto\dfrac{1}{\sqrt{2}}\left(  \dfrac{\partial}{\partial
\xi_{0}}+\xi_{0}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{this is only
relevant if }\delta=0\right)  .
\end{align*}
Here, $\dfrac{\partial}{\partial\xi_{i}}$ follows the Koszul sign rule. This
indeed defines a representation (exercise!). From Homework Set 2 problem 2, we know:

\begin{proposition}
Let%
\[
L_{k}=\delta_{k,0}\dfrac{1-2\delta}{16}+\dfrac{1}{2}\sum\limits_{j\in
\mathbb{Z}+\delta}j:\psi_{-j}\psi_{j+k}:,
\]
where the normal ordering is defined as follows:%
\[
:\psi_{n}\psi_{m}:\ =\ \left\{
\begin{array}
[c]{c}%
-\psi_{m}\psi_{n},\ \ \ \ \ \ \ \ \ \ \text{if }m\leq n;\\
\psi_{n}\psi_{m},\ \ \ \ \ \ \ \ \ \ \text{if }m>n
\end{array}
\right.  .
\]
Then:

\textbf{(a)} $\left[  \psi_{m},L_{k}\right]  =\left(  m+\dfrac{k}{2}\right)
\psi_{m+k}$.

\textbf{(b)} $\left[  L_{n},L_{m}\right]  =\left(  n-m\right)  L_{n+m}%
+\delta_{n,-m}\dfrac{m^{3}-m}{24}$ (so $c=\dfrac{1}{2}$).
\end{proposition}

Now this representation $V_{\delta}$ of $\operatorname*{Vir}$ is unitary. In
fact, consider the Hermitian form under which all monomials in $\psi_{i}$ are
orthonormal (positive definite). Then it is easy to see that $\psi_{j}^{\dag
}=\psi_{-j}$. Thus, $L_{n}^{\dag}=L_{-n}$.

But these $V_{\delta}$ are reducible, since the $L_{n}$ preserve parity:
$V_{\delta}=V_{\delta}^{+}\oplus V_{\delta}^{-}$.

\begin{theorem}
$V_{\delta}^{+}$ and $V_{\delta}^{-}$ are irreducible Virasoro modules.
\end{theorem}

We will not prove this.

What are the highest weights?

First consider the case $\delta=0$. The highest-weight vector of $V_{\delta
}^{+}$ is $1$, with weight $\left(  \dfrac{1}{16},\dfrac{1}{2}\right)  $. That
of $V_{\delta}^{-}$ is $\xi_{0}$, with weight $\left(  \dfrac{1}{16},\dfrac
{1}{2}\right)  $. Thus, $V_{\delta}^{+}\cong V_{\delta}^{-}$ by action of
$\psi_{0}$ (since $\psi_{0}^{2}=\dfrac{1}{2}$).

Now consider the case $\delta=\dfrac{1}{2}$. The highest-weight vector of
$V_{\delta}^{+}$ is $1$, with weight $\left(  0,\dfrac{1}{2}\right)  $. That
of $V_{\delta}^{-}$ is $\xi_{1/2}$, with weight $\left(  \dfrac{1}{2}%
,\dfrac{1}{2}\right)  $.

\begin{corollary}
The representation $L_{h,\dfrac{1}{2}}$ is unitary if $h=0$, $h=\dfrac{1}{16}$
or $h=\dfrac{1}{2}$. (In physics: Ising model.)
\end{corollary}

We will not prove:

\begin{proposition}
This is an only-if as well.
\end{proposition}

General answer for $c<1$: for $c=1-\dfrac{6}{\left(  m+2\right)  \left(
m+3\right)  }$ for $m\in\mathbb{N}$, there are finitely many $h$ where
$L_{h,c}$ is unitary. For other values of $c$, there are no such values.

\begin{definition}
The \textit{character }$\operatorname*{ch}\nolimits_{V}\left(  q\right)  $ of
a $\operatorname*{Vir}$-module $V$ from category $\mathcal{O}^{+}$ is
$\operatorname*{Tr}\nolimits_{V}\left(  q^{L_{0}}\right)  =\sum\left(  \dim
V_{\lambda}\right)  q^{\lambda}$ for $V_{\lambda}=$generalized eigenspace of
$L_{0}$ with eigenvalue $\lambda$.
\end{definition}

This is related to the old definition of character [how?]

What are the characters of the above modules? Since $V_{\delta}^{+}%
=\wedge\left(  \xi_{1},\xi_{2},\xi_{3},...\right)  ^{+}$, we have%
\[
\operatorname*{ch}\nolimits_{L_{\dfrac{1}{16},\dfrac{1}{2}}}\left(  q\right)
=q^{1/16}\left(  1+q\right)  \left(  1+q^{2}\right)  \left(  1+q^{3}\right)
...=q^{1/16}\prod\limits_{n\geq1}\left(  1+q^{n}\right)
\]
(because
\begin{align*}
2\operatorname*{ch}\nolimits_{L_{\dfrac{1}{16},\dfrac{1}{2}}}\left(  q\right)
&  =\operatorname*{ch}\nolimits_{V_{0}}\left(  q\right)  =q^{1/16}\left(
1+1\right)  \left(  1+q\right)  \left(  1+q^{2}\right)  \left(  1+q^{3}%
\right)  ...\\
&  =2q^{1/16}\left(  1+q\right)  \left(  1+q^{2}\right)  \left(
1+q^{3}\right)  ...
\end{align*}
).

Now%
\begin{align*}
\operatorname*{ch}\nolimits_{L_{0,\dfrac{1}{2}}}\left(  q\right)
+\operatorname*{ch}\nolimits_{L_{\dfrac{1}{2},\dfrac{1}{2}}}\left(  q\right)
&  =\operatorname*{ch}\nolimits_{V_{\dfrac{1}{2}}}\left(  q\right)  =\left(
1+q^{1/2}\right)  \left(  1+q^{3/2}\right)  \left(  1+q^{5/2}\right)  ...\\
&  =\prod\limits_{n\in\dfrac{1}{2}+\mathbb{N}}\left(  1+q^{n}\right)  .
\end{align*}
Thus, $\operatorname*{ch}\nolimits_{L_{0,\dfrac{1}{2}}}\left(  q\right)  $ is
the integer part of the product $\prod\limits_{n\in\dfrac{1}{2}+\mathbb{N}%
}\left(  1+q^{n}\right)  $, and $\operatorname*{ch}\nolimits_{L_{\dfrac{1}%
{2},\dfrac{1}{2}}}\left(  q\right)  $ is the half-integer part of the product
$\prod\limits_{n\in\dfrac{1}{2}+\mathbb{N}}\left(  1+q^{n}\right)  $.

\subsection{Representations of $\mathfrak{gl}_{\infty}$}

What is $\mathfrak{gl}_{\infty}$? Here is a first version of $\mathfrak{gl}%
_{\infty}$ (there will be different ones):

\begin{definition}
We define $\mathfrak{gl}_{\infty}$ to be the vector space of infinite matrices
with rows and columns labeled by integers (not only positive integers) such
that only finitely many entries are nonzero. This vector space $\mathfrak{gl}%
_{\infty}$ is an associative algebra \textit{without unit} (by matrix
multiplication); we can thus make $\mathfrak{gl}_{\infty}$ into a Lie algebra
by the commutator in this associative algebra.
\end{definition}

We will study the representations of this $\mathfrak{gl}_{\infty}$. The theory
of these representations will extend the well-known (Schur-Weyl) theory of
representations of $\mathfrak{gl}_{n}$.

\begin{definition}
The \textit{vector representation} $V$ of $\mathfrak{gl}_{\infty}$ is defined
as the vector space $\mathbb{C}^{\left(  \mathbb{Z}\right)  }=\left\{  \left(
x_{i}\right)  _{i\in\mathbb{Z}}\text{\ }\mid\ x_{i}\in\mathbb{C}\text{; only
finitely many }x_{i}\text{ are nonzero}\right\}  $.

For every $j\in\mathbb{Z}$, let $v_{j}$ be the vector $\left(  \delta
_{i,j}\right)  _{i\in\mathbb{Z}}\in V$. Then, $\left(  v_{j}\right)
_{j\in\mathbb{Z}}$ is a basis of $V$.
\end{definition}

\begin{Convention}
When we draw infinite matrices with rows and columns are labeled by integers,
the index of the rows is supposed to increase as we go from left to right, and
the index of the columns is supposed to increase as we go from top to bottom.
\end{Convention}

We can consider $\wedge^{i}V$ for every $i\in\mathbb{N}$. More generally, we
have the so-called \textit{Schur modules}:

\begin{definition}
If $\pi\in\operatorname*{Irr}S_{n}$, then we can define a representation
$S_{\pi}\left(  V\right)  $ of $\mathfrak{gl}_{\infty}$ by $S_{\pi}\left(
V\right)  =\operatorname*{Hom}\nolimits_{S_{n}}\left(  \pi,V^{\otimes
n}\right)  $. This $S_{\pi}\left(  V\right)  $ is called the $\pi$\textit{-th
Schur module} of $V$.
\end{definition}

\begin{proposition}
For every $\pi\in\operatorname*{Irr}S_{n}$, the representation $S_{\pi}\left(
V\right)  $ of $\mathfrak{gl}_{\infty}$ is irreducible.
\end{proposition}

On the other hand, we can define so-called \textit{highest weight
representations}. Before we do so, let us make $\mathfrak{gl}_{\infty}$ into a
graded Lie algebra:

\begin{definition}
For every $i\in\mathbb{Z}$, let $\mathfrak{gl}_{\infty}^{i}$ be the subspace
of $\mathfrak{gl}_{\infty}$ which consists of matrices which have nonzero
entries only the $i$-th diagonal. (The $i$\textit{-th diagonal} consists of
the entries in the $\left(  \alpha,\beta\right)  $-th places with
$\beta-\alpha=i$.)

Then, $\mathfrak{gl}_{\infty}=\bigoplus\limits_{i\in\mathbb{Z}}\mathfrak{gl}%
_{\infty}^{i}$, and this makes $\mathfrak{gl}_{\infty}$ into a $\mathbb{Z}%
$-graded Lie algebra. Note that $\mathfrak{gl}_{0}$ is abelian. Let
$\mathfrak{gl}_{\infty}=\mathfrak{n}_{-}\oplus\mathfrak{h}\oplus
\mathfrak{n}_{+}$ be the triangular decomposition of $\mathfrak{gl}_{\infty}$,
so that $\mathfrak{n}_{-}=\bigoplus\limits_{i<0}\mathfrak{gl}_{\infty}^{i}$ is
the space of lower-triangular [...]
\end{definition}

\begin{definition}
For every $i,j\in\mathbb{Z}$, let $E_{i,j}$ be the matrix (with rows and
columns labeled by integers) whose $\left(  i,j\right)  $-th entry is $1$ and
whose all other entries are $0$. Then, $\left(  E_{i,j}\right)  _{\left(
i,j\right)  \in\mathbb{Z}^{2}}$ is a basis of $\mathfrak{gl}_{\infty}$.
\end{definition}

\begin{definition}
For every $\lambda\in\mathfrak{h}^{\ast}$, let $M_{\lambda}$ be the
highest-weight Verma module $M_{\lambda}^{+}$ (as defined in Definition
\ref{def.verma}). Let $J_{\lambda}=\operatorname*{Ker}\left(  \cdot
,\cdot\right)  \subseteq M_{\lambda}$ be the maximal proper submodule. Let
$L_{\lambda}$ be the quotient module $M_{\lambda}\diagup J_{\lambda
}=M_{\lambda}^{+}\diagup J_{\lambda}^{+}=L_{\lambda}^{+}$; then, $L_{\lambda}$
is irreducible (as we know).
\end{definition}

\begin{definition}
Unitary structure: $E_{i,j}^{\dag}=E_{j,i}$ (thus, $\dag$ is transposition of
matrix $\circ$ complex conjugation).
\end{definition}

Very important: For usual $\mathfrak{gl}_{n}$, Schur modules = highest weight
modules up to det:

For $\mathfrak{gl}_{n}$, every finite-dimensional irreducible representation
and any unitary representation is of the form $S_{\pi}\left(  V_{n}\right)
\otimes\left(  \wedge^{n}\left(  V_{n}^{\ast}\right)  \right)  ^{\otimes j}$
for some $j\in\mathbb{N}$, where $V_{n}$ is the $\mathfrak{gl}_{n}$-module
$\mathbb{C}^{n}$.

Nothing like this is true for $\mathfrak{gl}_{\infty}$. Instead, exterior
powers of $V$ and highest-weight representations live in different worlds.
This is because $V$ is composed of infinite-dimensional vectors which have "no
top or bottom"; $V$ has no highest or lowest weight and does not lie in
category $\mathcal{O}^{+}$ or $\mathcal{O}^{-}$.

This is important, because many beautiful properties of representations of
$\mathfrak{gl}_{n}$ come from the equality of the highest-weight and Schur
module representations.

A way to marry these two worlds is by considering so-called
\textit{semiinfinite wedges}.

\begin{definition}
The space $\wedge^{\dfrac{\infty}{2}}V$ is the free vector space with basis
given by formal infinite wedge products $v_{i_{0}}\wedge v_{i_{1}}\wedge
v_{i_{2}}\wedge...$ where $i_{0}>i_{1}>i_{2}>...$ and $i_{k+1}=i_{k}-1$ for
all sufficiently large $k$. (Such wedge products are said to be
\textit{semiinfinite}.)
\end{definition}

This definition can be replaced by a somewhat more functorial one, which
doesn't use the basis $\left(  v_{i}\right)  _{i\in\mathbb{Z}}$ of $V$
anymore. But it still needs a topology on $V$ (which makes $V$ locally
linearly compact), and some working with formal Laurent series. It proceeds
through the semiinfinite Grassmannian, and will not be done in these lectures.

$\mathbb{C}\left(  \left(  t\right)  \right)  $ field of formal Laurent series

$\operatorname*{Gr}=\left\{  U\subseteq\mathbb{C}\left(  \left(  t\right)
\right)  \ \mid\ \left(  U\supseteq t^{n}\mathbb{C}\left[  \left[  t\right]
\right]  \text{ and }\dim\left(  U\diagup\left(  t^{n}\mathbb{C}\left[
\left[  n\right]  \right]  \right)  \right)  <\infty\right)  \text{ for some
sufficiently high }n\right\}  $.

Call $\operatorname*{sdim}U=\dim\left(  U\diagup\left(  t^{n}\mathbb{C}\left[
\left[  n\right]  \right]  \right)  \right)  -n$ (independent of $n$ !)

This Grassmannian is the disjoint union $\coprod\operatorname*{Gr}%
\nolimits_{n}$.

There is something called a determinant line bundle on $\operatorname*{Gr}$.
The space of semiinfinite wedges is then defined as the space of regular
sections of this line bundle (in the sense of algebraic geometry).

Back to topic. [Book by Pressley and Segal about loop groups for explanations.]

The space $\wedge^{\dfrac{\infty}{2}}V$ is countably dimensional. More
precisely:%
\begin{align*}
\wedge^{\dfrac{\infty}{2}}V  &  =\bigoplus\limits_{n\in\mathbb{Z}}%
\wedge^{\dfrac{\infty}{2},m}V,\ \ \ \ \ \ \ \ \ \ \text{where}\\
\wedge^{\dfrac{\infty}{2},m}V  &  =\operatorname*{span}\left\{  v_{i_{0}%
}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\ \mid\ i_{k}+k=m\text{ for
sufficiently large }m\right\}  .
\end{align*}
The space $\wedge^{\dfrac{\infty}{2},m}V$ has basis $\left\{  v_{i_{0}}\wedge
v_{i_{1}}\wedge v_{i_{2}}\wedge...\ \mid\ i_{k}+k=m\text{ for sufficiently
large }m\right\}  $, which is easily seen to be countable. We will see later
that this basis can be naturally labeled by partitions (of all integers, not
just of $m$).

The Lie algebra $\mathfrak{gl}_{\infty}$ acts on the space $\wedge
^{\dfrac{\infty}{2}}V$ by the usual Leibniz rule:%
\[
a\rightharpoonup\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  =\sum\limits_{k\geq1}v_{i_{0}}\wedge v_{i_{1}}%
\wedge...\wedge v_{i_{k-1}}\wedge\left(  a\rightharpoonup v_{i_{k}}\right)
\wedge v_{i_{k+1}}\wedge v_{i_{k+2}}\wedge....
\]
The elements on the right have to be interprested in a way such that $\wedge$
is antisymmetric and multilinear. Explicitly:%
\[
E_{i,j}\rightharpoonup\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}%
\wedge...\right)  =\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }j\notin\left\{  i_{0},i_{1},i_{2},...\right\}
;\\
v_{i_{0}}\wedge v_{i_{1}}\wedge...\wedge v_{i}\text{ instead of }v_{j}%
\wedge...,\ \ \ \ \ \ \ \ \ \ \text{if }j=i_{k}%
\end{array}
\right.  ,
\]
and use antisymmetry.

\begin{proposition}
\label{prop.Lomegam}The $\mathfrak{gl}_{\infty}$-module $\wedge^{\dfrac
{\infty}{2},m}V$ is the irreducible highest-weight representation
$L_{\omega_{m}}$ of $\mathfrak{gl}_{\infty}$ with highest weight $\omega
_{m}=\left(  ...,1,1,0,0,...\right)  $, where the last $1$ is on place $m$ and
the first $0$ is on place $m+1$. Moreover, $L_{\omega_{m}}$ is unitary.
\end{proposition}

\textit{Proof of Proposition \ref{prop.Lomegam}.} Define a $w_{m}\in
\wedge^{\dfrac{\infty}{2},m}V$ by $w_{m}=v_{m}\wedge v_{m-1}\wedge
v_{m-2}\wedge...$. Then, $\mathfrak{n}_{+}\cdot w_{m}=0$. (In fact, if
$E_{i,j}\in\mathfrak{n}_{+}$ then $i<j$ and thus indiced are replaced by
smaller indices...) Moreover, every $h\in\mathfrak{h}$ satisfies
$hw_{m}=\omega_{m}\left(  h\right)  w_{m}$ (in fact, test at $h=E_{i,i}$).
Also, $w_{m}$ generates the $\mathfrak{gl}_{\infty}$-module $\wedge
^{\dfrac{\infty}{2},m}V$. Thus, $\wedge^{\dfrac{\infty}{2},m}V$ is a
highest-weight representation with highest weight $\omega_{m}$.

Next let us prove that it is unitary. This will yield that it is
irreducible.\footnote{We could also show the irreducibility more directly, by
showing that every sum of wedges can be used to get back $w_{m}$.}

Note that we can grade $\wedge^{\dfrac{\infty}{2},m}V$ by%
\[
\deg\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\right)
=-\sum\limits_{k}\left(  i_{k}+k-m\right)  .
\]
(Note that $\left(  i_{k}+k-m\right)  _{k}$ will be our partition.)

The unitarity is because the form in which the wedges are orthonormal is
$\dag$-invariant. Thus, irreducible. (We used Lemma \ref{lem.unitrick}.)
Proposition \ref{prop.Lomegam} is proven.

\begin{corollary}
For every finite sum $\sum\limits_{i}k_{i}\omega_{i}$ with $k_{i}\in
\mathbb{N}$, the representation $L_{\sum\limits_{i}k_{i}\omega_{i}}$ is unitary.
\end{corollary}

\textit{Proof.} Take the module $\bigotimes\limits_{i}L_{\omega_{i}}^{\otimes
k_{i}}$, and let $v$ be the tensor product of their respective highest weight
vectors. Let $L$ be the submodule generated by $v$. Then, $L$ is a
highest-weight module, and is unitary since it is a submodule of a unitary
module. Hence it is irreducible, and thus $L\cong L_{\sum\limits_{i}%
k_{i}\omega_{i}}$, qed.

\subsection{$\overline{\mathfrak{gl}_{\infty}}$}

Now we want to enlarge $\mathfrak{gl}_{\infty}$. (Remember that $\mathfrak{gl}%
_{\infty}$ is too small - it doesn't even contain the identity matrix.)

\begin{definition}
We define $\overline{\mathfrak{a}_{\infty}}$ to be the vector space of
infinite matrices with rows and columns labeled by integers (not only positive
integers) such that only finitely many \textbf{diagonals} are nonzero. This is
an associative algebra with $1$, and thus, by the commutator, a Lie algebra.
\end{definition}

We can think of the elements of $\overline{\mathfrak{a}_{\infty}}$ as
difference operators:

Consider $V$ as the space of sequences\footnote{In the following, "sequences"
means "sequences labeled by integers".} with finitely many nonzero entries,
and let $T:V\rightarrow V$ be the linear map given by $\left(  Tx\right)
_{n}=x_{n+1}$ for all $n\in\mathbb{Z}$. This map $T$ is called the
\textit{shift operator}. A \textit{difference operator} is an operator of the
form $A=\sum\limits_{i=p}^{q}a_{i}\left(  n\right)  T^{i}$, where $p$ and $q$
are some integers, and $a_{i}:\mathbb{Z}\rightarrow\mathbb{C}$ are some
functions. Then, $\overline{\mathfrak{a}_{\infty}}$ is the algebra of all such
operators. (These operators also act on the space of \textit{all} sequences,
not only on the space of sequence with finitely many nonzero entries.)

Note that $\overline{\mathfrak{a}_{\infty}}$ is no longer countably
dimensional. The family $\left(  E_{i,j}\right)  _{\left(  i,j\right)
\in\mathbb{N}^{2}}$ is no longer a vector space basis, but it is a topological
basis in an appropriately defined topology.

Note on topologies:

\begin{itemize}
\item Topology on $\overline{\mathfrak{a}_{\infty}}$: A sequence $\left(
A_{n}\right)  $ goes to a limit $A$ if for any vector $v\in\wedge
^{\dfrac{\infty}{2},m}V$, we have $A_{n}v=Av$ for sufficiently large $n$.

\item Topology on $\mathfrak{gl}_{\infty}$: Subspace of $\overline
{\mathfrak{a}_{\infty}}$. It is dense.

\item Topology on $\wedge^{\dfrac{\infty}{2},m}V$: discrete.
\end{itemize}

Let $\rho$ be the representation of $\mathfrak{gl}_{\infty}$ on $\wedge
^{\dfrac{\infty}{2},m}V$. Can we extend $\rho$ by continuity to a
representation of $\overline{\mathfrak{a}_{\infty}}$?

What this means in elementary terms: We have $\overline{\mathfrak{a}_{\infty}%
}=\bigoplus\limits_{i\in\mathbb{Z}}\mathfrak{a}_{\infty}^{i}$, where
$\mathfrak{a}_{\infty}^{i}$ are the matrices with nonzero entries only on the
$i$-th diagonal. Each $\mathfrak{a}_{\infty}^{i}$ has weak topology (i. e.,
stabilization on every term). Then, $\mathfrak{gl}_{\infty}^{i}$ in dense in
$\mathfrak{a}_{\infty}^{i}$. Can we extend $\rho$ by continuity to a
representation of $\overline{\mathfrak{a}_{\infty}}$?

Answer: Almost, but no (usually). We need a central extension.

For $i\neq0$, a typical element $X\in\mathfrak{a}_{\infty}^{i}$ is of the form
$X=\sum\limits_{j\in\mathbb{Z}}a_{j}E_{j,j+i}$ with $a_{j}\in\mathbb{C}$. Now
define $\rho\left(  x\right)  v=\sum\limits_{j\in\mathbb{Z}}a_{j}\rho\left(
E_{j,j+i}\right)  v$ for every $v\in\wedge^{\dfrac{\infty}{2},m}V$; this is a
finite sum (prove [...]) and thus makes sense.

But when $i=0$, we run into a problem: $\rho\left(  \sum\limits_{j\in
\mathbb{Z}}a_{j}E_{j,j}\right)  v=\sum\limits_{j\in\mathbb{Z}}a_{j}\rho\left(
E_{j,j}\right)  v$ is an infinite sum and thus makes no sense.

We modify:%
\[
\widehat{\rho}\left(  E_{i,j}\right)  =\left\{
\begin{array}
[c]{c}%
\rho\left(  E_{i,j}\right)  ,\ \ \ \ \ \ \ \ \ \ \text{unless }i=j\text{ and
}i\leq0;\\
\rho\left(  E_{i,j}\right)  -1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j\text{ and
}i\leq0
\end{array}
\right.  .
\]
Then it is easy to see that $\widehat{\rho}$ extends to $\overline
{\mathfrak{a}_{\infty}}$ continuously as a linear map.

The following theorem will be a homework problem:

\begin{theorem}
\label{thm.japan}For any $A\in\overline{\mathfrak{a}_{\infty}}$ and
$B\in\overline{\mathfrak{a}_{\infty}}$, we have $\widehat{\rho}\left(  \left[
A,B\right]  \right)  -\left[  \widehat{\rho}\left(  A\right)  ,\widehat{\rho
}\left(  B\right)  \right]  =\alpha\left(  A,B\right)  $ where $\alpha\left(
A,B\right)  $ is a scalar depending on $A$ and $B$ (thus a $2$-cocycle). This
$\alpha\left(  A,B\right)  $ is obtained as follows: Write $A=\left(
\begin{array}
[c]{cc}%
A_{11} & A_{12}\\
A_{21} & A_{22}%
\end{array}
\right)  $ and $B=\left(
\begin{array}
[c]{cc}%
B_{11} & B_{12}\\
B_{21} & B_{22}%
\end{array}
\right)  $ block matrices with $i\leq0$, $i>0$, $j\leq0$ and $j>0$ being the
separators. Then, $\alpha\left(  A,B\right)  =\operatorname*{Tr}\left(
-B_{12}A_{21}+A_{12}B_{21}\right)  $. (This trace makes sense because $A_{12}%
$, $B_{21}$, $A_{21}$, $B_{12}$ have only finitely many nonzero entries.)
\end{theorem}

We are going to prove next lecture that $\alpha$ is a nontrivial $2$-cocycle,
but its restriction to $\mathfrak{gl}_{\infty}$ is trivial. This is a strange
situation for a dense Lie subalgebra!

\begin{corollary}
The $\alpha$ defined in Theorem \ref{thm.japan} is a $2$-cocycle on
$\overline{\mathfrak{a}_{\infty}}$.

We define $\mathfrak{a}_{\infty}$ as the $1$-dimensional central extension
$\widehat{\overline{\mathfrak{a}_{\infty}}}_{\alpha}$ of $\overline
{\mathfrak{a}_{\infty}}$ by $\mathbb{C}$ using this cocycle $\alpha$ (see
Definition \ref{def.centex} for what this means).
\end{corollary}

\begin{corollary}
\label{cor.japan.triv}The restriction of $\alpha$ to $\mathfrak{gl}_{\infty
}\times\mathfrak{gl}_{\infty}$ is a $2$-coboundary.
\end{corollary}

\textit{Proof of Corollary \ref{cor.japan.triv}.} Let $J=\left(
\begin{array}
[c]{cc}%
0 & 0\\
0 & -I_{\infty}%
\end{array}
\right)  \in\overline{\mathfrak{a}_{\infty}}$. Define a linear map
$f:\mathfrak{gl}_{\infty}\rightarrow\mathbb{C}$ by $f\left(  A\right)
=\operatorname*{Tr}\left(  JA\right)  $. Then, any $A\in\mathfrak{gl}_{\infty
}$ and $B\in\mathfrak{gl}_{\infty}$ satisfy $\alpha\left(  A,B\right)
=f\left(  \left[  A,B\right]  \right)  $, because:

$\left[  A,B\right]  =\left(
\begin{array}
[c]{cc}%
\ast & \ast\\
\ast & \left[  A_{22},B_{22}\right]  +A_{21}B_{12}-B_{21}A_{12}%
\end{array}
\right)  $, so that
\[
\operatorname*{Tr}\left(  J\left[  A,B\right]  \right)  =-\operatorname*{Tr}%
\left(  \left[  A_{22},B_{22}\right]  +A_{21}B_{12}-B_{21}A_{12}\right)
=\operatorname*{Tr}\left(  -A_{21}B_{12}+B_{21}A_{12}\right)  =\alpha\left(
A,B\right)  .
\]
Proof of Corollary \ref{cor.japan.triv}.

But note that this proof does not extend to $\overline{\mathfrak{a}_{\infty}}%
$, because $f$ does not continuously extend to $\overline{\mathfrak{a}%
_{\infty}}$.

\begin{proposition}
\label{prop.japan.nontr}The $2$-cocycle $\alpha$ itself is not a $2$-coboundary.
\end{proposition}

\textit{Proof of Proposition \ref{prop.japan.nontr}.} Let $T$ be the shift
operator defined above. The span $\left\langle T^{j}\ \mid\ j\in
\mathbb{Z}\right\rangle $ is an abelian Lie subalgebra of $\overline
{\mathfrak{a}_{\infty}}$ (isomorphic to the quotient $\overline{\mathcal{A}}$
of the Heisenberg algebra $\mathcal{A}$ by its center). Any $2$-coboundary
must become zero when restricted onto an abelian Lie subalgebra. But $\alpha$,
restricted onto the span $\left\langle T^{j}\ \mid\ j\in\mathbb{Z}%
\right\rangle $, does not become $0$, since%
\[
\alpha\left(  T^{i},T^{j}\right)  =\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }i\neq-j;\\
i,\ \ \ \ \ \ \ \ \ \ \text{if }i=-j
\end{array}
\right.  .
\]
Proposition \ref{prop.japan.nontr} is thus proven.

From this proof, we get an embedding $\mathcal{A}\rightarrow\mathfrak{a}%
_{\infty}$ which lifts $\overline{\mathcal{A}}\rightarrow\overline
{\mathfrak{a}_{\infty}}$ and sends $K$ to $K$.

Now we can extend the theory for $\mathfrak{gl}_{\infty}$ that we discussed
last time to $\mathfrak{a}_{\infty}$. Namely, $\wedge^{\dfrac{\infty}{2}%
,m}V=L_{\omega_{m}}$ is unitary. Also, if $k_{1},k_{2},...,k_{n}\in\mathbb{N}%
$, then the representation $L_{k_{1}\omega_{1}+k_{2}\omega_{2}+...+k_{n}%
\omega_{n}}$ of $\mathfrak{a}_{\infty}$ is unitary.

We can also embed $\operatorname*{Vir}$ into $\mathfrak{a}_{\infty}$, and not
just in one way, but in infinitely many ways depending on two parameters:

\begin{proposition}
Let $\alpha,\beta\in\mathbb{C}$. Let $V_{\alpha,\beta}$ be the space of formal
expressions $gz^{\alpha}\left(  dz\right)  ^{\beta}$, where $g$ is a Laurent
polynomial in the variable $z$. (Such formal expressions can be seen as
"tensor fields" of rank $\beta$ and branching $\alpha$ on the punctured
complex plane.) According to Homework Set 1 exercise 1, the formula
\begin{equation}
f\partial\circ\left(  gz^{\alpha}\left(  dz\right)  ^{\beta}\right)  =\left(
fg^{\prime}+\alpha z^{-1}fg+\beta f^{\prime}g\right)  z^{\alpha}\left(
dz\right)  ^{\beta} \label{ex1.1.1}%
\end{equation}
defines an action of $W$ on $V_{\alpha,\beta}$. Thus, $V_{\alpha,\beta}$
becomes a $\operatorname*{Vir}$-module with $C$ acting as $0$.

For every $k\in\mathbb{Z}$, let $v_{k}=z^{-k+\alpha}\left(  dz\right)
^{\beta}\in V_{\alpha,\beta}$. (This is a different convention than the one
used in the homework!)

According to the homework (but with our notiations),%
\[
L_{m}v_{k}=\left(  k-\alpha-\beta\left(  n+1\right)  \right)  v_{k-m}%
\ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{Z}.
\]
Thus, if we write $L_{m}$ as a matrix with respect to the basis $\left(
v_{k}\right)  _{k\in\mathbb{Z}}$ of $V_{\alpha,\beta}$, then this matrix lies
in $\overline{\mathfrak{a}_{\infty}}$ (in fact, its only nonzero diagonal is
the $m$-th one).

This defines an inclusion $\overline{\varphi_{\alpha,\beta}}:W\rightarrow
\overline{\mathfrak{a}_{\infty}}$. This lifts to a map $\widehat{W}%
\rightarrow\mathfrak{a}_{\infty}$, where $\widehat{W}$ is the central
extension of $W$ defined by $\alpha$. But what is $\widehat{W}$ ? Exercise
(homework):%
\[
\alpha\left(  L_{m},L_{n}\right)  =\delta_{n,-m}\left(  \dfrac{n^{3}-n}%
{12}c_{\beta}+2nh_{\alpha,\beta}\right)  ,
\]
where
\[
c_{\beta}=-12\beta^{2}+12\beta-2\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ h_{\alpha,\beta}=\dfrac{1}{2}\alpha\left(  \alpha
+2\beta-1\right)  .
\]
So we redefine $L_{0}$ to $\widehat{L_{0}}=L_{0}+h_{\alpha,\beta}K$. Then,
$L_{n}$ for $n\neq0$ and $\widehat{L_{0}}$ satisfy the usual Virasoro
relations with $C=c_{\beta}$. Thus, the map%
\begin{align*}
L_{n}  &  \mapsto L_{n},\\
L_{0}  &  \mapsto\widehat{L_{0}},\\
C  &  \mapsto c_{\beta}K
\end{align*}
is a homomorphism $\varphi_{\alpha,\beta}:\operatorname*{Vir}\rightarrow
\mathfrak{a}_{\infty}$, and $\wedge^{\dfrac{\infty}{2},m}V_{\alpha,\beta}$ is
a Virasoro module with central charge $c=c_{\beta}$ (via the map
$\varphi_{\alpha,\beta}$). This $\wedge^{\dfrac{\infty}{2},m}V_{\alpha,\beta}$
is called the \textit{module of semiinfinite forms}. The vector $\psi
_{m}=v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...$ has highest degree (namely,
$0$).

We have $L_{i}\psi_{m}=0$ for $i>0$, and we have $L_{0}\psi_{m}=\dfrac{1}%
{2}\left(  \alpha-m\right)  \left(  \alpha+2\beta-1-m\right)  \psi_{m}$.
(Proof: Homework exercise.)
\end{proposition}

\begin{corollary}
We have a homomorphism%
\begin{align*}
M_{\lambda}  &  \rightarrow\wedge^{\dfrac{\infty}{2},m}V_{\alpha,\beta},\\
v_{\lambda}  &  \mapsto\psi_{m}%
\end{align*}
of Virasoro modules, where%
\[
\lambda=\left(  \dfrac{1}{2}\left(  \alpha-m\right)  \left(  \alpha
+2\beta-1-m\right)  ,-12\beta^{2}+12\beta-2\right)  .
\]

\end{corollary}

We will see that this is an isomorphism for generic $\lambda$. For concrete
$\lambda$ it is not always one, and can have a rather complicated kernel.

What is the character of $\wedge^{\dfrac{\infty}{2},m}V$ ? For $d\geq0$, we
have%
\[
\left(  \wedge^{\dfrac{\infty}{2},m}V\right)  \left[  -d\right]  =\left\langle
v_{i_{0}}\wedge v_{i_{1}}\wedge...\ \mid\ d=\sum\limits_{k\geq0}\left(
i_{k}+k-m\right)  \right\rangle .
\]
This defines a grading on $\wedge^{\dfrac{\infty}{2},m}V$ by%
\[
\wedge^{\dfrac{\infty}{2},m}V=\bigoplus\limits_{d\geq0}\left(  \wedge
^{\dfrac{\infty}{2},m}V\right)  \left[  -d\right]  .
\]


If we set $\lambda_{k}=i_{k}+k-m$, then $\lambda=\left(  \lambda_{0}%
,\lambda_{1},\lambda_{2},...\right)  $ is a partition of $d$ (that is,
$\lambda_{0}\geq\lambda_{1}\geq\lambda_{2}\geq...$ and $\sum\limits_{k\geq
0}\lambda_{k}=d$).

Conversely, given a partition $\lambda$, set $i_{k}=\lambda_{k}-k+m$ and
obtain the monomial $v_{i_{0}}\wedge v_{i_{1}}\wedge...$.

This is a bijection between monomials and partitions. Hence:

\begin{proposition}
We have $\dim\left(  \left(  \wedge^{\dfrac{\infty}{2},m}V\right)  \left[
-d\right]  \right)  =p\left(  d\right)  $, so that%
\begin{align*}
\operatorname*{ch}\nolimits_{\wedge^{\dfrac{\infty}{2},m}V}:  &  =\sum_{d}%
\dim\left(  \left(  \wedge^{\dfrac{\infty}{2},m}V\right)  \left[  -d\right]
\right)  q^{d}\\
&  =\sum_{d}p\left(  d\right)  q^{d}=\dfrac{1}{\left(  1-q\right)  \left(
1-q^{2}\right)  \left(  1-q^{3}\right)  \cdots}.
\end{align*}

\end{proposition}

\begin{proposition}
\label{prop.wedge.fock}As an $\mathcal{A}$-module, $\wedge^{\dfrac{\infty}%
{2},m}V$ is isomorphic to the Fock module $F_{m}$.
\end{proposition}

\textit{Proof of Proposition \ref{prop.wedge.fock}.} We have $a_{i}\psi_{m}=0$
for all $i>0$ (by degree considerations). Also,%
\begin{align*}
a_{0}\psi_{m}  &  =\mathbf{1}\psi_{m}\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\mathbf{1}\text{ is the identity matrix in }\mathfrak{a}_{\infty}\text{, but
it does not have to}\\
\text{act by }1\text{ (since it is a Lie algebra representation)}%
\end{array}
\right) \\
&  =\mathbf{1}\cdot v_{m}\wedge v_{m-1}\wedge v_{m-2}\wedge...\wedge
v_{1}\wedge v_{0}\wedge v_{-1}\wedge...\\
&  =\sum\limits_{i\in\mathbb{Z}}E_{i,i}\cdot v_{m}\wedge v_{m-1}\wedge
v_{m-2}\wedge...\wedge v_{1}\wedge v_{0}\wedge v_{-1}\wedge....
\end{align*}
To this sum, the $E_{i,i}$ with $i>m$ and the $E_{i,i}$ with $i\leq0$ do not
contribute. The only contributions come from $E_{i,i}$ with $m\geq i>0$. All
these contributions equal $1$, so $a_{0}\psi_{m}=m\psi_{m}$.

So (by a lemma that we have used many times: the lemma about Sing) we have a
homomorphism $\sigma_{m}:F_{m}\rightarrow\wedge^{\dfrac{\infty}{2},m}V$ with
$\sigma_{m}\left(  1\right)  =\psi_{m}$. [We are using that $F_{m}$ is a Verma
module for $\mathcal{A}$.] This $\sigma_{m}$ is injective (since $F_{m}$ is
irreducible) and presevers grading. But $\operatorname*{ch}\nolimits_{F_{m}%
}\left(  q\right)  =\dfrac{1}{\left(  1-q\right)  \left(  1-q^{2}\right)
\left(  1-q^{3}\right)  \cdots}=\operatorname*{ch}\nolimits_{\wedge
^{\dfrac{\infty}{2},m}V}$, so $\sigma_{m}$ is a map between vector spaces of
the same dimension in each degree. Thus, $\sigma_{m}$ (being injective) must
be an isomorphism. Qed.

Note that Proposition \ref{prop.wedge.fock} is strange: it gives an
isomorphism between bosons (Fock module) and fermions (infinite wedge),
something unheard of in finite-dimensional contexts.

\begin{definition}
We write $\mathcal{B}^{\left(  m\right)  }=F_{m}$. We write $\mathcal{B}%
=\bigoplus\limits_{m}\mathcal{B}^{\left(  m\right)  }$. We write
$\mathcal{F}^{\left(  m\right)  }=\wedge^{\dfrac{\infty}{2},m}V$. We write
$\mathcal{F}=\bigoplus\limits_{m}\mathcal{F}^{\left(  m\right)  }$.

We write $\sigma_{m}:\mathcal{B}^{\left(  m\right)  }\rightarrow
\mathcal{F}^{\left(  m\right)  }$. We write $\sigma=\bigoplus\limits_{m}%
\mathcal{\sigma}_{m}:\mathcal{B}\rightarrow\mathcal{F}$ (isomorphism). This
$\sigma$ is called the \textit{Boson-Fermion Correspondence}.
\end{definition}

Note that we can do the same for the Virasoro algebra: If $M_{\lambda}$ is
irreducible, then the homomorphism $M_{\lambda}\rightarrow\wedge
^{\dfrac{\infty}{2},m}V_{\alpha,\beta}$ is an isomorphism. And we know that
$\operatorname*{Vir}$ is nondegenerate, so $M_{\lambda}$ is irreducible for
Weil-generic $\lambda$.

\begin{corollary}
For generic $\alpha$ and $\beta$, the $\operatorname*{Vir}$-module
$\wedge^{\dfrac{\infty}{2},m}V_{\alpha,\beta}$ is irreducible.
\end{corollary}

But now, back to Boson-Fermion Correspondence:

How to extend the action of $\mathcal{A}$ on $\mathcal{B}$ to an action of
$\mathfrak{a}_{\infty}$ explicitly? (We mean: How to describe the action of
$\mathcal{A}$ on $\mathcal{B}$ obtained by transporting the action of
$\mathcal{A}$ on $\mathcal{F}$ through $\sigma$ ?)

This question is answered using the so-called \textit{vertex operator
construction}.

But first, some easier things:

Wedging/contraction operators:

\textit{Wedging operators: }$\widehat{v_{i}}:\mathcal{F}^{\left(  m\right)
}\rightarrow\mathcal{F}^{\left(  m+1\right)  }$, $\widehat{v_{i}}\cdot
\psi=v_{i}\wedge\psi$. (We need to apply alternation to $v_{i}\wedge\psi$ to
make the indices decrease again.)

\textit{Contraction operators:} $\overset{\vee}{v_{i}}:\mathcal{F}^{\left(
m\right)  }\rightarrow\mathcal{F}^{\left(  m-1\right)  }$,%

\[
\overset{\vee}{v_{i}}\psi=\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }\psi\text{ has no }v_{i};\\
\psi\text{ with excised }v_{i}\text{ and appropriate sign,}%
\ \ \ \ \ \ \ \ \ \ \text{otherwise}%
\end{array}
\right.  .
\]
These operators satisfy the usual relations:%
\begin{align*}
\widehat{v_{i}}\widehat{v_{j}}+\widehat{v_{j}}\widehat{v_{i}}  &
=0,\ \ \ \ \ \ \ \ \ \ \overset{\vee}{v_{i}}\overset{\vee}{v_{j}%
}+\overset{\vee}{v_{j}}\overset{\vee}{v_{i}}=0,\\
\overset{\vee}{v_{i}}\widehat{v_{j}}+\widehat{v_{j}}\overset{\vee}{v_{i}}  &
=\delta_{i,j}.
\end{align*}


Let us call $\xi_{i}=\widehat{v_{i}}$ and $\xi_{i}^{\ast}=\overset{\vee
}{v_{i}}$. Then, $\rho\left(  E_{i,j}\right)  =\xi_{i}\xi_{j}^{\ast}$ and
\[
\widehat{\rho}\left(  E_{i,j}\right)  =\left\{
\begin{array}
[c]{c}%
\xi_{i}\xi_{j}^{\ast}-1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j\text{ and }i\leq0,\\
\xi_{i}\xi_{j}^{\ast},\ \ \ \ \ \ \ \ \ \ \text{unless }i=j\text{ and }i\leq0
\end{array}
\right.  .
\]


The $\xi_{i}$ and $\xi_{i}^{\ast}$ are called \textit{fermionic operators}.

So what are the $\xi_{i}$ in terms of $a_{j}$ ?

\subsection{The vertex operator construction}

We write $\mathbb{C}\left[  z,z^{-1},x_{1},x_{2},...\right]  =\bigoplus
\limits_{m}z^{m}\mathbb{C}\left[  x_{1},x_{2},...\right]  $ for $\mathcal{B}%
=\bigoplus\limits_{m}\mathcal{B}^{\left(  m\right)  }$, with $\mathcal{B}%
^{\left(  m\right)  }=z^{m}\mathbb{C}\left[  x_{1},x_{2},...\right]  $.

Note that we give the $x$'es degree $-1$.

Note also that $z$ is an iso of $\mathcal{A}_{0}$-modules, but not of
$\mathcal{A}$-modules.

The Boson-Fermion correspondence goes like this:%
\[
\mathcal{F}=\bigoplus\limits_{m}\mathcal{F}^{\left(  m\right)  }%
\overset{\sigma=\bigoplus\limits_{m}\sigma_{m}}{\leftarrow}\mathcal{B}%
=\bigoplus\limits_{m}\mathcal{B}^{\left(  m\right)  }.
\]
On $\mathcal{F}$ there are operators $\widehat{v_{i}}=\xi_{i}$, $\overset{\vee
}{v_{i}}=\xi_{i}^{\ast}$, $\rho\left(  E_{i,j}\right)  =\xi_{i}\xi_{j}^{\ast}%
$, $\widehat{\rho}\left(  E_{i,j}\right)  =\left\{
\begin{array}
[c]{c}%
\xi_{i}\xi_{j}^{\ast}-1,\ \ \ \ \ \ \ \ \ \ \text{if }i=j\text{ and }i\leq0,\\
\xi_{i}\xi_{j}^{\ast},\ \ \ \ \ \ \ \ \ \ \text{unless }i=j\text{ and }i\leq0
\end{array}
\right.  $. We must find the corresponding operators on $\mathcal{B}$.

Introduce the quantum fields%
\begin{align*}
X\left(  u\right)   &  =\sum\limits_{n\in\mathbb{Z}}\xi_{n}u^{n}%
,\ \ \ \ \ \ \ \ \ \ X^{\ast}\left(  u\right)  =\sum\limits_{n\in\mathbb{Z}%
}\xi_{n}^{\ast}u^{-n},\\
\Gamma\left(  u\right)   &  =\sigma^{-1}\circ X\left(  u\right)  \circ
\sigma,\ \ \ \ \ \ \ \ \ \ \Gamma^{\ast}\left(  u\right)  =\sigma^{-1}\circ
X^{\ast}\left(  u\right)  \circ\sigma.
\end{align*}
Note that $\Gamma\left(  u\right)  :\mathcal{B}^{\left(  m\right)
}\rightarrow\mathcal{B}^{\left(  m+1\right)  }$ and $\Gamma^{\ast}\left(
u\right)  :\mathcal{B}^{\left(  m\right)  }\rightarrow\mathcal{B}^{\left(
m-1\right)  }$, because this is how the $\xi_{n}$ and $\xi_{n}^{\ast}$ act.

\begin{theorem}
\label{thm.euler}We have%
\begin{align*}
\Gamma\left(  u\right)   &  =u^{m+1}z\exp\left(  \sum\limits_{j>0}%
\dfrac{a_{-j}}{j}u^{j}\right)  \cdot\exp\left(  -\sum\limits_{j>0}\dfrac
{a_{j}}{j}u^{-j}\right)  ;\\
\Gamma^{\ast}\left(  u\right)   &  =u^{-m}z^{-1}\exp\left(  -\sum
\limits_{j>0}\dfrac{a_{-j}}{j}u^{j}\right)  \cdot\exp\left(  \sum
\limits_{j>0}\dfrac{a_{j}}{j}u^{-j}\right)  .
\end{align*}
Here, $\exp A$ means $1+A+\dfrac{A^{2}}{2!}+\dfrac{A^{3}}{3!}+...$ for any $A$
for which this series makes any sense.
\end{theorem}

Why do these formulas make sense?

Claim: For any $v\in\mathcal{B}^{\left(  m\right)  }$, we have $RHS\cdot
v\in\mathcal{B}^{\left(  m+1\text{ resp. }m-1\right)  }\left(  \left(
u\right)  \right)  $.

Indeed, $\exp\left(  -\sum\limits_{j>0}\dfrac{a_{j}}{j}u^{-j}\right)  \left(
v\right)  \in B\left[  u^{-1}\right]  $ (since $v$ has degree $-d$ for some
$d$, and $a_{j}$ raise degree by $j$, so only finitely many terms remain), so
that $\exp\left(  \sum\limits_{j>0}\dfrac{a_{-j}}{j}u^{j}\right)  \cdot
\exp\left(  -\sum\limits_{j>0}\dfrac{a_{j}}{j}u^{-j}\right)  \left(  v\right)
\in B\left(  \left(  u\right)  \right)  $.

\begin{remark}
Morally speaking, $\Gamma\left(  u\right)  $ is $uz:\exp\left(  \int a\left(
u\right)  du\right)  :$, and $\Gamma^{\ast}\left(  u\right)  $ is $z^{-1}%
:\exp\left(  -\int a\left(  u\right)  du\right)  :$. What does this mean?
$a\left(  u\right)  =\sum\limits_{m}a_{m}u^{-m-1}$, thus $\int a\left(
u\right)  du=\sum\limits_{m\neq0}\dfrac{a_{m}}{m}u^{-m}+a_{0}\log u$.
Exponentiating this \textbf{in the normal ordering}, we get%
\begin{align*}
&  \underbrace{\exp\left(  a_{0}\log u\right)  }_{\substack{=u^{a_{0}}%
=u^{m}\\\text{(since }a_{0}\text{ acts by }0\text{ on }\mathcal{B}^{\left(
m\right)  }\text{)}}}\cdot\exp\left(  \sum\limits_{m<0}\dfrac{a_{m}}{m}%
u^{-m}\right)  \cdot\exp\left(  \sum\limits_{m>0}\dfrac{a_{m}}{m}u^{-m}\right)
\\
&  =u^{m}z\exp\left(  \sum\limits_{j>0}\dfrac{a_{-j}}{j}u^{j}\right)
\cdot\exp\left(  -\sum\limits_{j>0}\dfrac{a_{j}}{j}u^{-j}\right)  .
\end{align*}
This is reminiscent of Euler's formula $y=c\exp\left(  \int a\left(  u\right)
du\right)  $ for the solution $y$ of the differential equation $y^{\prime}=ay$.
\end{remark}

Before we can show Theorem \ref{thm.euler}, let us prove a lemma:

\begin{lemma}
We have $\left[  a_{j},\Gamma\left(  u\right)  \right]  =u^{j}\Gamma\left(
u\right)  $ and $\left[  a_{j},\Gamma^{\ast}\left(  u\right)  \right]
=u^{j}\Gamma^{\ast}\left(  u\right)  $ (or maybe $u^{-j}\Gamma^{\ast}\left(
u\right)  $).
\end{lemma}

\textit{Proof.} We will only prove the first formula (the second one is analogous).

Under the BFC, $a_{j}$ corresponds to $T^{j}=\sum\limits_{i}:\xi_{i}\xi
_{i+j}^{\ast}:$.

In the fermionic setting,%
\begin{align*}
\left[  T^{j},X\left(  u\right)  \right]   &  =\left[  \sum\limits_{i}:\xi
_{i}\xi_{i+j}^{\ast}:\ ,\ \sum\limits_{m}\xi_{m}u^{m}\right] \\
&  =\sum\limits_{m}\xi_{m-j}u^{m}=u^{j}\underbrace{\sum\limits_{m}\xi
_{m-j}u^{m-j}}_{=X\left(  u\right)  }=u^{j}X\left(  u\right)  .
\end{align*}
Now, conjugate by $\sigma$.

Lemma proven.

\textit{Proof of Theorem \ref{thm.euler}.} Define $\Gamma_{+}\left(  u\right)
=\exp\left(  -\sum\limits_{j>0}\dfrac{a_{j}}{j}u^{-j}\right)  $. Then,%
\begin{align*}
\left[  a_{i},\Gamma_{+}\left(  u\right)  \right]   &
=0\ \ \ \ \ \ \ \ \ \ \text{if }i\geq0;\\
\left[  a_{i},\Gamma_{+}\left(  u\right)  \right]   &  =u^{i}\Gamma_{+}\left(
u\right)  \ \ \ \ \ \ \ \ \ \ \text{if }i<0.
\end{align*}
To check the second of these two equalities (the first is trivial), notice
that
\begin{align*}
\left[  a_{i},\exp\left(  -\dfrac{a_{-i}}{-i}u^{i}\right)  \right]   &
=u^{i}\exp\left(  -\dfrac{a_{-i}}{-i}u^{i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{using }\left[  a_{i},a_{-i}\right]
=i\right)  .
\end{align*}
Now consider $\Delta\left(  u\right)  :=\Gamma\left(  u\right)  \Gamma
_{+}\left(  u\right)  ^{-1}z^{-1}$. Since $\left[  a_{0},z\right]  =z$ and
$\left[  a_{i},z\right]  =0$ for $i\neq0$, from the above we get%
\[
\left[  a_{i},\Delta\left(  u\right)  \right]  =\left\{
\begin{array}
[c]{c}%
0,\ \ \ \ \ \ \ \ \ \ \text{if }i\leq0;\\
u^{i}\Delta\left(  u\right)  ,\ \ \ \ \ \ \ \ \ \ \text{if }i>0
\end{array}
\right.
\]
(using the standard formula $\left[  a,b^{-1}\right]  =-b^{-1}\left[
a,b\right]  b^{-1}$). In particular, $\left[  a_{i},\Delta\left(  u\right)
\right]  =0$ if $i\leq0$. Thus, $\Delta\left(  u\right)  $ is completely
determined by $\Delta\left(  u\right)  v_{m}$. Let us compute $\Delta\left(
u\right)  v_{m}$. This is a series in $u$ whose coefficients are polynomials
in $x_{1},x_{2},x_{3},...$. Denote this series by $Q$.

We will use the representation%
\begin{align*}
a_{-i}  &  \mapsto ix_{i}\ \ \ \ \ \ \ \ \ \ \text{for }i>0;\\
a_{i}  &  \mapsto\dfrac{\partial}{\partial x_{i}}\ \ \ \ \ \ \ \ \ \ \text{for
}i>0,\\
K  &  \mapsto1
\end{align*}
of $\mathcal{A}_{0}$.

If $i>0$, then $a_{i}\Delta\left(  u\right)  v_{m}=u^{i}\Delta\left(
u\right)  v_{m}$. In other words, $\dfrac{\partial Q}{\partial x_{i}}=u^{i}Q$.
So we get $Q\left(  u,x_{1},x_{2},x_{3},...\right)  =f\left(  u\right)
\exp\left(  \sum\limits_{j>0}x_{j}u^{j}\right)  $ for some Laurent series
$f\left(  u\right)  \in\mathbb{C}\left(  \left(  u\right)  \right)  $. Thus,
$\Delta\left(  u\right)  =f\left(  u\right)  \exp\left(  \sum\limits_{j>0}%
\dfrac{a_{-j}}{j}u^{j}\right)  $. Thus, $\Gamma\left(  u\right)  =f\left(
u\right)  z\exp\left(  \sum\limits_{j>0}\dfrac{a_{-j}}{j}u^{j}\right)  $. It
remains to show that $f\left(  u\right)  =u^{m+1}$.

In the fermionic space, with $\psi_{m}=v_{m}\wedge v_{m-1}\wedge v_{m-2}%
\wedge...$, we have%
\[
\left\langle \psi_{m+1}^{\ast},X\left(  u\right)  \psi_{m}\right\rangle
=\left\langle \psi_{m+1}^{\ast},\sum\limits_{i}\widehat{v_{i}}u^{i}\psi
_{m}\right\rangle =u^{m+1}%
\]
but%
\[
\left\langle \psi_{m+1}^{\ast},X\left(  u\right)  \psi_{m}\right\rangle
=\left\langle v_{m+1}^{\ast},\Gamma\left(  u\right)  v_{m}\right\rangle
=f\left(  u\right)  .
\]


\begin{corollary}
We have%
\[
\rho\left(  \sum\limits_{i,j}u^{i}v^{-j}E_{i,j}\right)  =\sum\limits_{i}%
u^{i}v^{-j}\xi_{i}\xi_{j}^{\ast}=X\left(  u\right)  X^{\ast}\left(  v\right)
,
\]
thus%
\begin{align*}
\sigma^{-1}\circ\rho\left(  \sum\limits_{i,j}u^{i}v^{-j}E_{i,j}\right)
\circ\sigma &  =\sigma^{-1}\circ X\left(  u\right)  X^{\ast}\left(  v\right)
\circ\sigma=\Gamma\left(  u\right)  \Gamma^{\ast}\left(  v\right) \\
&  =\dfrac{1}{1-\dfrac{v}{u}}\cdot\left(  \dfrac{u}{v}\right)  ^{m}\exp\left(
\sum\limits_{j>0}\dfrac{u^{j}-v^{j}}{j}a_{-j}\right)  \exp\left(
-\sum\limits_{j>0}\dfrac{u^{-j}-v^{-j}}{j}a_{j}\right)  .
\end{align*}

\end{corollary}

\textit{Proof.}
\begin{align*}
\Gamma\left(  u\right)  \Gamma^{\ast}\left(  v\right)   &  =u^{m+1}%
v^{-m-1}\cdot\exp\left(  \sum\limits_{j>0}\dfrac{u^{j}}{j}a_{-j}\right)
\exp\left(  -\sum\limits_{j>0}\dfrac{u^{-j}}{j}a_{j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \cdot\exp\left(  -\sum\limits_{j>0}\dfrac{v^{j}}%
{j}a_{-j}\right)  \exp\left(  \sum\limits_{j>0}\dfrac{v^{-j}}{j}a_{j}\right)
.
\end{align*}
We need to reorder the second and the third exponential on the right hand side
of this. We can reorder them using the following fact: When $\left[
A,B\right]  =C$ and $\left[  C,A\right]  =0$ and $\left[  C,B\right]  =0$,
then $\exp A\cdot\exp B=\exp B\cdot\exp A\cdot\exp C$. (This is an exercise.)
Thus, this becomes%
\begin{align*}
\Gamma\left(  u\right)  \Gamma^{\ast}\left(  v\right)   &  =u^{m+1}v^{-m}%
\cdot\exp\left(  \sum\limits_{j>0}\dfrac{u^{j}}{j}a_{-j}\right)  \exp\left(
-\sum\limits_{j>0}\dfrac{v^{j}}{j}a_{-j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \cdot\exp\left(  -\sum\limits_{j>0}\dfrac{u^{-j}}%
{j}a_{j}\right)  \cdot\exp\left(  \left[  \sum\limits_{j>0}\dfrac{u^{-j}}%
{j}a_{j},\sum\limits_{j>0}\dfrac{v^{j}}{j}a_{-j}\right]  \right)  \exp\left(
\sum\limits_{j>0}\dfrac{v^{-j}}{j}a_{j}\right)  .
\end{align*}
But%
\begin{align*}
\exp\left(  \left[  \sum\limits_{j>0}\dfrac{u^{-j}}{j}a_{j},\sum
\limits_{j>0}\dfrac{v^{j}}{j}a_{-j}\right]  \right)   &  =\exp\left(
\sum\limits_{j>0}\dfrac{1}{j}\left(  \dfrac{v}{u}\right)  ^{j}\right)
=\exp\left(  -\log\left(  1-\dfrac{v}{u}\right)  \right) \\
&  =\dfrac{1}{1-\dfrac{v}{u}},
\end{align*}
which is what gives the $\dfrac{1}{1-\dfrac{v}{u}}$ term.

Next question: What is $\sigma^{-1}\left(  v_{i_{0}}\wedge v_{i_{1}}\wedge
v_{i_{2}}\wedge...\right)  $ ? This turns out to be a Schur polynomial.

We first define elementary Schur polynomials:

\begin{definition}
We define $S_{k}\in\mathbb{Q}\left[  x_{1},x_{2},x_{3},...\right]  $ by%
\[
\sum\limits_{k\geq0}S_{k}\left(  x\right)  z^{k}=\exp\left(  \sum
\limits_{j\geq1}x_{i}z^{i}\right)  .
\]

\end{definition}

For example, $S_{0}\left(  x\right)  =1$, $S_{1}\left(  x\right)  =x_{1}$,
$S_{2}\left(  x\right)  =\dfrac{x_{1}^{2}}{2}+x_{2}$, $...$.

Note that these are not symmetric polynomials. These are the representations
of complete symmetric functions in terms of the $\dfrac{p_{i}}{i}$.

Complete symmetric functions: $h_{k}\left(  y_{1},y_{2},...,y_{N}\right)
=\sum\limits_{\substack{p_{1},p_{2},...,p_{N}\in\mathbb{N};\\p_{1}%
+p_{2}+...+p_{N}=k}}y_{1}^{p_{1}}y_{2}^{p_{2}}...y_{N}^{p_{N}}$.

\begin{proposition}
We have%
\[
\sum\limits_{k\geq0}z^{k}h_{k}\left(  y\right)  =\prod\limits_{j=1}^{N}%
\dfrac{1}{1-zy_{j}}.
\]

\end{proposition}

\begin{proposition}
\label{prop.h_k.as.schur}If $x_{j}=\dfrac{y_{1}^{j}+y_{2}^{j}+...+y_{N}^{j}%
}{j}$, then $h_{k}\left(  y\right)  =S_{k}\left(  x\right)  $.
\end{proposition}

\textit{Proof.}
\begin{align*}
\sum\limits_{k\geq0}S_{k}\left(  x\right)  z^{k}  &  =\exp\left(
\sum\limits_{j\geq1}x_{i}z^{i}\right)  =\exp\left(  \sum\limits_{j\geq1}%
\dfrac{y_{1}^{i}+y_{2}^{i}+...+y_{N}^{i}}{i}z^{i}\right) \\
&  =\prod\limits_{j}\exp\left(  \sum\limits_{i\geq1}\dfrac{y_{j}^{i}z^{i}}%
{i}\right)  =\prod\limits_{j}\exp\left(  -\log\left(  1-y_{j}z\right)  \right)
\\
&  =\prod\limits_{j}\dfrac{1}{1-y_{j}z}=\sum\limits_{k\geq0}z^{k}h_{k}\left(
y\right)  .
\end{align*}


\begin{definition}
Let $\lambda=\left(  \lambda_{1},\lambda_{2},...,\lambda_{m}\right)  $ be a
partition, so that $\lambda_{1}\geq\lambda_{2}\geq...\geq\lambda_{m}\geq0$ are integers.

We define $S_{\lambda}\left(  x\right)  \in\mathbb{Q}\left[  x_{1},x_{2}%
,x_{3},...\right]  $ to be the polynomial%
\[
\det\left(
\begin{array}
[c]{ccccc}%
s_{\lambda_{1}}\left(  x\right)  & s_{\lambda_{1}+1}\left(  x\right)  &
s_{\lambda_{1}+2}\left(  x\right)  & ... & s_{\lambda_{1}+m-1}\left(  x\right)
\\
s_{\lambda_{2}-1}\left(  x\right)  & s_{\lambda_{2}}\left(  x\right)  &
s_{\lambda_{2}+1}\left(  x\right)  & ... & s_{\lambda_{2}+m-2}\left(  x\right)
\\
s_{\lambda_{3}-2}\left(  x\right)  & s_{\lambda_{3}-1}\left(  x\right)  &
s_{\lambda_{3}}\left(  x\right)  & ... & s_{\lambda_{3}+m-3}\left(  x\right)
\\
... & ... & ... & ... & ...\\
s_{\lambda_{m}-m+1}\left(  x\right)  & s_{\lambda_{m}-m+2}\left(  x\right)  &
s_{\lambda_{m}-m+3}\left(  x\right)  & ... & s_{\lambda_{m}}\left(  x\right)
\end{array}
\right)  ,
\]
where $s_{j}$ denotes $0$ if $j<0$. (Note that this does not depend on
trailing zeroes in the partition.)

If $N\geq m$, and we denote by $\Lambda$ the $N$-tuple $\left(  \lambda
_{1},\lambda_{2},...,\lambda_{m},0,0,...,0\right)  $, then we have an
irreducible representation $V_{\Lambda}$ of $\mathfrak{gl}\left(  N\right)  $
and of $\operatorname*{GL}\left(  N\right)  $. Then, a diagonal matrix
$Y=\operatorname*{diag}\left(  y_{1},y_{2},...,y_{N}\right)  \in
\operatorname*{GL}\left(  N\right)  $ has character $\chi_{\Lambda}\left(
y_{1},y_{2},...,y_{N}\right)  =\operatorname*{Tr}\mid_{V_{\lambda}}\left(
Y\right)  $.
\end{definition}

\begin{proposition}
We have $\chi_{\Lambda}\left(  y_{1},y_{2},...,y_{N}\right)  =S_{\lambda
}\left(  x\right)  $ where $x_{j}=\dfrac{y_{1}^{j}+y_{2}^{j}+...+y_{N}^{j}}%
{j}$.
\end{proposition}

This generalizes Proposition \ref{prop.h_k.as.schur} (in fact, set
$\lambda=\left(  k\right)  $ and notice that $V_{\lambda}=S^{k}\mathbb{C}^{N}$).

\begin{theorem}
Whenever $v_{i_{0}}\wedge v_{i_{1}}\wedge v_{i_{2}}\wedge...\in\mathcal{F}%
^{\left(  0\right)  }$, we have $\sigma^{-1}\left(  v_{i_{0}}\wedge v_{i_{1}%
}\wedge v_{i_{2}}\wedge...\right)  =S_{\lambda}\left(  x\right)  $ where
$\lambda=\left(  i_{0},i_{1}+1,i_{2}+2,...\right)  $.
\end{theorem}


\end{document}